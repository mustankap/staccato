{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neutral', 'angry', 'anxious', 'excited', 'apologetic', 'sad', 'happy'}\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.3\n",
    "x=np.load('loaded_data/jl_full_x.npy') \n",
    "y=np.load('loaded_data/jl_full_y.npy') \n",
    "print(set(y))\n",
    "x_train,x_test,temp_y_train,temp_y_test=train_test_split(np.array(x), y, test_size = test_size, random_state = 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn = np.expand_dims(x_train, axis=2)\n",
    "x_testcnn = np.expand_dims(x_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1176, 180, 1), (504, 180, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_traincnn.shape, x_testcnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test,y_train = [],[]\n",
    "d={'apologetic':0, 'excited':1, 'neutral':2, 'anxious':3, 'sad':4, 'angry':5, 'happy':6}\n",
    "for i in temp_y_test:\n",
    "    y_test.append(d[i])\n",
    "for i in temp_y_train:\n",
    "    y_train.append(d[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 14:08:23.137024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-10 14:08:23.193942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-10 14:08:23.194795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-10 14:08:23.197880: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-10 14:08:23.200340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-10 14:08:23.201223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-10 14:08:23.201951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-10 14:08:24.244360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-10 14:08:24.244642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-10 14:08:24.244877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-10 14:08:24.245094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2769 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "/home/vedant/miniconda3/lib/python3.9/site-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(RMSprop, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',\n",
    "                 input_shape=(180,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(10)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(7))\n",
    "model.add(Activation('softmax'))\n",
    "opt = tf.keras.optimizers.RMSprop(lr=0.00005, rho=0.9, epsilon=None, decay=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 180, 128)          768       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 180, 128)          0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 180, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 22, 128)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 22, 128)           82048     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 22, 128)           0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 22, 128)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2816)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7)                 19719     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 7)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,535\n",
      "Trainable params: 102,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 14:08:25.855232: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 5s 8ms/step - loss: 3.5684 - accuracy: 0.1514 - val_loss: 1.9398 - val_accuracy: 0.2361\n",
      "Epoch 2/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 3.0721 - accuracy: 0.1998 - val_loss: 1.7274 - val_accuracy: 0.2560\n",
      "Epoch 3/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 2.7578 - accuracy: 0.2194 - val_loss: 1.6462 - val_accuracy: 0.3571\n",
      "Epoch 4/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 2.4284 - accuracy: 0.2389 - val_loss: 1.6586 - val_accuracy: 0.2718\n",
      "Epoch 5/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 2.3195 - accuracy: 0.2560 - val_loss: 1.8029 - val_accuracy: 0.2282\n",
      "Epoch 6/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 2.0860 - accuracy: 0.2942 - val_loss: 1.5358 - val_accuracy: 0.3849\n",
      "Epoch 7/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.9195 - accuracy: 0.3180 - val_loss: 1.5482 - val_accuracy: 0.3413\n",
      "Epoch 8/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.9056 - accuracy: 0.2951 - val_loss: 1.3886 - val_accuracy: 0.4464\n",
      "Epoch 9/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.7316 - accuracy: 0.3444 - val_loss: 1.3639 - val_accuracy: 0.4345\n",
      "Epoch 10/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.5962 - accuracy: 0.3895 - val_loss: 1.3410 - val_accuracy: 0.4028\n",
      "Epoch 11/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.5888 - accuracy: 0.3699 - val_loss: 1.2559 - val_accuracy: 0.4464\n",
      "Epoch 12/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.5385 - accuracy: 0.3801 - val_loss: 1.3674 - val_accuracy: 0.4306\n",
      "Epoch 13/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.4524 - accuracy: 0.4124 - val_loss: 1.2126 - val_accuracy: 0.4881\n",
      "Epoch 14/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.3658 - accuracy: 0.4456 - val_loss: 1.2250 - val_accuracy: 0.4524\n",
      "Epoch 15/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.3266 - accuracy: 0.4396 - val_loss: 1.1641 - val_accuracy: 0.5198\n",
      "Epoch 16/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.3390 - accuracy: 0.4456 - val_loss: 1.1765 - val_accuracy: 0.4702\n",
      "Epoch 17/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.2542 - accuracy: 0.4677 - val_loss: 1.2289 - val_accuracy: 0.4603\n",
      "Epoch 18/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 1.1857 - accuracy: 0.5085 - val_loss: 1.1574 - val_accuracy: 0.5000\n",
      "Epoch 19/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.2087 - accuracy: 0.4889 - val_loss: 1.1452 - val_accuracy: 0.4782\n",
      "Epoch 20/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.1900 - accuracy: 0.5009 - val_loss: 1.1885 - val_accuracy: 0.4980\n",
      "Epoch 21/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 1.1651 - accuracy: 0.5094 - val_loss: 1.1350 - val_accuracy: 0.4782\n",
      "Epoch 22/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.1473 - accuracy: 0.5017 - val_loss: 1.1087 - val_accuracy: 0.5159\n",
      "Epoch 23/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.0923 - accuracy: 0.5281 - val_loss: 1.0813 - val_accuracy: 0.5456\n",
      "Epoch 24/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.0739 - accuracy: 0.5544 - val_loss: 1.1449 - val_accuracy: 0.4444\n",
      "Epoch 25/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.0622 - accuracy: 0.5587 - val_loss: 1.0694 - val_accuracy: 0.5357\n",
      "Epoch 26/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.0718 - accuracy: 0.5553 - val_loss: 1.0521 - val_accuracy: 0.5615\n",
      "Epoch 27/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.0371 - accuracy: 0.5655 - val_loss: 1.0503 - val_accuracy: 0.5337\n",
      "Epoch 28/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.0305 - accuracy: 0.5901 - val_loss: 1.0181 - val_accuracy: 0.5853\n",
      "Epoch 29/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.0237 - accuracy: 0.5646 - val_loss: 0.9992 - val_accuracy: 0.6091\n",
      "Epoch 30/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 1.0172 - accuracy: 0.5765 - val_loss: 1.0386 - val_accuracy: 0.5794\n",
      "Epoch 31/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.9988 - accuracy: 0.5978 - val_loss: 1.0127 - val_accuracy: 0.5952\n",
      "Epoch 32/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.9795 - accuracy: 0.5952 - val_loss: 1.0035 - val_accuracy: 0.6250\n",
      "Epoch 33/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.9732 - accuracy: 0.5952 - val_loss: 1.0153 - val_accuracy: 0.5794\n",
      "Epoch 34/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.9587 - accuracy: 0.6114 - val_loss: 0.9640 - val_accuracy: 0.6349\n",
      "Epoch 35/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.9402 - accuracy: 0.6233 - val_loss: 1.0273 - val_accuracy: 0.5595\n",
      "Epoch 36/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.9385 - accuracy: 0.6003 - val_loss: 1.0048 - val_accuracy: 0.5734\n",
      "Epoch 37/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.9528 - accuracy: 0.6122 - val_loss: 0.9768 - val_accuracy: 0.6111\n",
      "Epoch 38/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.9177 - accuracy: 0.6114 - val_loss: 0.9463 - val_accuracy: 0.6468\n",
      "Epoch 39/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.9209 - accuracy: 0.6241 - val_loss: 0.9605 - val_accuracy: 0.6052\n",
      "Epoch 40/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.9090 - accuracy: 0.6318 - val_loss: 0.9730 - val_accuracy: 0.5893\n",
      "Epoch 41/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.8977 - accuracy: 0.6429 - val_loss: 0.9514 - val_accuracy: 0.6210\n",
      "Epoch 42/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.8998 - accuracy: 0.6267 - val_loss: 0.9526 - val_accuracy: 0.6349\n",
      "Epoch 43/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.8976 - accuracy: 0.6071 - val_loss: 0.9302 - val_accuracy: 0.6290\n",
      "Epoch 44/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.8910 - accuracy: 0.6446 - val_loss: 0.9174 - val_accuracy: 0.6488\n",
      "Epoch 45/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.8563 - accuracy: 0.6607 - val_loss: 1.0291 - val_accuracy: 0.5794\n",
      "Epoch 46/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.8595 - accuracy: 0.6497 - val_loss: 0.9431 - val_accuracy: 0.6270\n",
      "Epoch 47/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.8884 - accuracy: 0.6276 - val_loss: 0.9474 - val_accuracy: 0.5972\n",
      "Epoch 48/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.8409 - accuracy: 0.6641 - val_loss: 0.9651 - val_accuracy: 0.5794\n",
      "Epoch 49/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.8321 - accuracy: 0.6633 - val_loss: 0.9362 - val_accuracy: 0.5992\n",
      "Epoch 50/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.8433 - accuracy: 0.6667 - val_loss: 0.9429 - val_accuracy: 0.5734\n",
      "Epoch 51/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.8285 - accuracy: 0.6692 - val_loss: 0.9302 - val_accuracy: 0.6250\n",
      "Epoch 52/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.8443 - accuracy: 0.6684 - val_loss: 0.8928 - val_accuracy: 0.6230\n",
      "Epoch 53/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.8288 - accuracy: 0.6633 - val_loss: 0.9024 - val_accuracy: 0.6448\n",
      "Epoch 54/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.8298 - accuracy: 0.6777 - val_loss: 0.8685 - val_accuracy: 0.6806\n",
      "Epoch 55/1000\n",
      "74/74 [==============================] - 0s 5ms/step - loss: 0.8157 - accuracy: 0.6684 - val_loss: 0.8611 - val_accuracy: 0.6687\n",
      "Epoch 56/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.8112 - accuracy: 0.6769 - val_loss: 0.9056 - val_accuracy: 0.6409\n",
      "Epoch 57/1000\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.8065 - accuracy: 0.6871 - val_loss: 0.8449 - val_accuracy: 0.6925\n",
      "Epoch 58/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7882 - accuracy: 0.6786 - val_loss: 0.8547 - val_accuracy: 0.6706\n",
      "Epoch 59/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7982 - accuracy: 0.6811 - val_loss: 0.8963 - val_accuracy: 0.6270\n",
      "Epoch 60/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7844 - accuracy: 0.6888 - val_loss: 0.8855 - val_accuracy: 0.6448\n",
      "Epoch 61/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7712 - accuracy: 0.6930 - val_loss: 0.8362 - val_accuracy: 0.6865\n",
      "Epoch 62/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7887 - accuracy: 0.6930 - val_loss: 0.9491 - val_accuracy: 0.6349\n",
      "Epoch 63/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7597 - accuracy: 0.6973 - val_loss: 0.8480 - val_accuracy: 0.6806\n",
      "Epoch 64/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7756 - accuracy: 0.6981 - val_loss: 0.8861 - val_accuracy: 0.6290\n",
      "Epoch 65/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7484 - accuracy: 0.7024 - val_loss: 0.8220 - val_accuracy: 0.7024\n",
      "Epoch 66/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7503 - accuracy: 0.7007 - val_loss: 0.8591 - val_accuracy: 0.6448\n",
      "Epoch 67/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7370 - accuracy: 0.6990 - val_loss: 0.8186 - val_accuracy: 0.6825\n",
      "Epoch 68/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7364 - accuracy: 0.7007 - val_loss: 0.8178 - val_accuracy: 0.7024\n",
      "Epoch 69/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7653 - accuracy: 0.6828 - val_loss: 0.8441 - val_accuracy: 0.6488\n",
      "Epoch 70/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7228 - accuracy: 0.7228 - val_loss: 0.8430 - val_accuracy: 0.6607\n",
      "Epoch 71/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7238 - accuracy: 0.7117 - val_loss: 0.8298 - val_accuracy: 0.6647\n",
      "Epoch 72/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7216 - accuracy: 0.7126 - val_loss: 0.9261 - val_accuracy: 0.5893\n",
      "Epoch 73/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7370 - accuracy: 0.7066 - val_loss: 0.8088 - val_accuracy: 0.6746\n",
      "Epoch 74/1000\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7227 - accuracy: 0.7245 - val_loss: 0.8400 - val_accuracy: 0.6429\n",
      "Epoch 75/1000\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.7177 - accuracy: 0.7143 - val_loss: 0.8376 - val_accuracy: 0.6587\n",
      "Epoch 76/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.7132 - accuracy: 0.7058 - val_loss: 0.8406 - val_accuracy: 0.6865\n",
      "Epoch 77/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7071 - accuracy: 0.7270 - val_loss: 0.7960 - val_accuracy: 0.6845\n",
      "Epoch 78/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7031 - accuracy: 0.7253 - val_loss: 0.8685 - val_accuracy: 0.6865\n",
      "Epoch 79/1000\n",
      "74/74 [==============================] - 0s 7ms/step - loss: 0.6875 - accuracy: 0.7457 - val_loss: 0.8141 - val_accuracy: 0.6865\n",
      "Epoch 80/1000\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6763 - accuracy: 0.7500 - val_loss: 0.8579 - val_accuracy: 0.6250\n",
      "Epoch 81/1000\n",
      "74/74 [==============================] - 0s 7ms/step - loss: 0.6815 - accuracy: 0.7466 - val_loss: 0.8240 - val_accuracy: 0.6607\n",
      "Epoch 82/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.7037 - accuracy: 0.7202 - val_loss: 0.8082 - val_accuracy: 0.7004\n",
      "Epoch 83/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.6920 - accuracy: 0.7491 - val_loss: 0.7666 - val_accuracy: 0.6964\n",
      "Epoch 84/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.6801 - accuracy: 0.7219 - val_loss: 0.7573 - val_accuracy: 0.7183\n",
      "Epoch 85/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.6757 - accuracy: 0.7381 - val_loss: 0.7821 - val_accuracy: 0.6786\n",
      "Epoch 86/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.6617 - accuracy: 0.7577 - val_loss: 0.8273 - val_accuracy: 0.6429\n",
      "Epoch 87/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.6738 - accuracy: 0.7449 - val_loss: 0.7483 - val_accuracy: 0.7302\n",
      "Epoch 88/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.6616 - accuracy: 0.7474 - val_loss: 0.7830 - val_accuracy: 0.7262\n",
      "Epoch 89/1000\n",
      "74/74 [==============================] - 0s 7ms/step - loss: 0.6360 - accuracy: 0.7653 - val_loss: 0.8343 - val_accuracy: 0.6409\n",
      "Epoch 90/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.6525 - accuracy: 0.7406 - val_loss: 0.7493 - val_accuracy: 0.7421\n",
      "Epoch 91/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.6404 - accuracy: 0.7526 - val_loss: 0.8117 - val_accuracy: 0.6746\n",
      "Epoch 92/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.6505 - accuracy: 0.7594 - val_loss: 0.7751 - val_accuracy: 0.6726\n",
      "Epoch 93/1000\n",
      "74/74 [==============================] - 0s 7ms/step - loss: 0.6208 - accuracy: 0.7662 - val_loss: 0.7512 - val_accuracy: 0.7063\n",
      "Epoch 94/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.6590 - accuracy: 0.7526 - val_loss: 0.7358 - val_accuracy: 0.7222\n",
      "Epoch 95/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.6247 - accuracy: 0.7704 - val_loss: 0.7987 - val_accuracy: 0.6865\n",
      "Epoch 96/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.6141 - accuracy: 0.7568 - val_loss: 0.7641 - val_accuracy: 0.6786\n",
      "Epoch 97/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.6208 - accuracy: 0.7662 - val_loss: 0.7811 - val_accuracy: 0.6825\n",
      "Epoch 98/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.6297 - accuracy: 0.7645 - val_loss: 0.7326 - val_accuracy: 0.7460\n",
      "Epoch 99/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.6326 - accuracy: 0.7466 - val_loss: 0.7413 - val_accuracy: 0.7103\n",
      "Epoch 100/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.6269 - accuracy: 0.7594 - val_loss: 0.7099 - val_accuracy: 0.7540\n",
      "Epoch 101/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.6091 - accuracy: 0.7653 - val_loss: 0.7375 - val_accuracy: 0.7063\n",
      "Epoch 102/1000\n",
      "74/74 [==============================] - 0s 6ms/step - loss: 0.6065 - accuracy: 0.7738 - val_loss: 0.7698 - val_accuracy: 0.7202\n",
      "Epoch 103/1000\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.6101 - accuracy: 0.7594 - val_loss: 0.7406 - val_accuracy: 0.7381\n",
      "Epoch 104/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.6126 - accuracy: 0.7687 - val_loss: 0.7249 - val_accuracy: 0.7302\n",
      "Epoch 105/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5966 - accuracy: 0.7798 - val_loss: 0.7388 - val_accuracy: 0.7024\n",
      "Epoch 106/1000\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5894 - accuracy: 0.7815 - val_loss: 0.7477 - val_accuracy: 0.7282\n",
      "Epoch 107/1000\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5797 - accuracy: 0.7781 - val_loss: 0.7210 - val_accuracy: 0.7242\n",
      "Epoch 108/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5654 - accuracy: 0.7925 - val_loss: 0.7080 - val_accuracy: 0.7381\n",
      "Epoch 109/1000\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5989 - accuracy: 0.7866 - val_loss: 0.7321 - val_accuracy: 0.7103\n",
      "Epoch 110/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5912 - accuracy: 0.7772 - val_loss: 0.7194 - val_accuracy: 0.7282\n",
      "Epoch 111/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5869 - accuracy: 0.7857 - val_loss: 0.7513 - val_accuracy: 0.7063\n",
      "Epoch 112/1000\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5844 - accuracy: 0.7755 - val_loss: 0.7520 - val_accuracy: 0.6845\n",
      "Epoch 113/1000\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5668 - accuracy: 0.7891 - val_loss: 0.7140 - val_accuracy: 0.7401\n",
      "Epoch 114/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5817 - accuracy: 0.7781 - val_loss: 0.6827 - val_accuracy: 0.7778\n",
      "Epoch 115/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5534 - accuracy: 0.8087 - val_loss: 0.6821 - val_accuracy: 0.7480\n",
      "Epoch 116/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5638 - accuracy: 0.7925 - val_loss: 0.6932 - val_accuracy: 0.7659\n",
      "Epoch 117/1000\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5810 - accuracy: 0.7781 - val_loss: 0.6899 - val_accuracy: 0.7778\n",
      "Epoch 118/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5598 - accuracy: 0.7874 - val_loss: 0.7243 - val_accuracy: 0.7262\n",
      "Epoch 119/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5589 - accuracy: 0.7891 - val_loss: 0.6987 - val_accuracy: 0.7262\n",
      "Epoch 120/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5592 - accuracy: 0.7883 - val_loss: 0.7368 - val_accuracy: 0.7163\n",
      "Epoch 121/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5540 - accuracy: 0.7934 - val_loss: 0.6764 - val_accuracy: 0.7758\n",
      "Epoch 122/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.5361 - accuracy: 0.8044 - val_loss: 0.6866 - val_accuracy: 0.7401\n",
      "Epoch 123/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.5382 - accuracy: 0.8061 - val_loss: 0.7576 - val_accuracy: 0.6905\n",
      "Epoch 124/1000\n",
      "74/74 [==============================] - 1s 7ms/step - loss: 0.5349 - accuracy: 0.7985 - val_loss: 0.6954 - val_accuracy: 0.7619\n",
      "Epoch 125/1000\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5348 - accuracy: 0.8010 - val_loss: 0.6964 - val_accuracy: 0.7202\n",
      "Epoch 126/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.5423 - accuracy: 0.8044 - val_loss: 0.6843 - val_accuracy: 0.7401\n",
      "Epoch 127/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.5299 - accuracy: 0.8027 - val_loss: 0.7129 - val_accuracy: 0.7123\n",
      "Epoch 128/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.5303 - accuracy: 0.8172 - val_loss: 0.6707 - val_accuracy: 0.7778\n",
      "Epoch 129/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.5145 - accuracy: 0.8095 - val_loss: 0.6773 - val_accuracy: 0.7837\n",
      "Epoch 130/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.5344 - accuracy: 0.7925 - val_loss: 0.6818 - val_accuracy: 0.7282\n",
      "Epoch 131/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.5174 - accuracy: 0.7993 - val_loss: 0.6653 - val_accuracy: 0.7798\n",
      "Epoch 132/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.5076 - accuracy: 0.8214 - val_loss: 0.6755 - val_accuracy: 0.7639\n",
      "Epoch 133/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.5036 - accuracy: 0.8095 - val_loss: 0.6854 - val_accuracy: 0.7718\n",
      "Epoch 134/1000\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.5160 - accuracy: 0.7993 - val_loss: 0.6580 - val_accuracy: 0.7639\n",
      "Epoch 135/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5083 - accuracy: 0.8146 - val_loss: 0.6679 - val_accuracy: 0.7639\n",
      "Epoch 136/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.5105 - accuracy: 0.8146 - val_loss: 0.6477 - val_accuracy: 0.7659\n",
      "Epoch 137/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.5300 - accuracy: 0.8036 - val_loss: 0.6740 - val_accuracy: 0.7440\n",
      "Epoch 138/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.5082 - accuracy: 0.8019 - val_loss: 0.6688 - val_accuracy: 0.7599\n",
      "Epoch 139/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4946 - accuracy: 0.8248 - val_loss: 0.6765 - val_accuracy: 0.7599\n",
      "Epoch 140/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.5080 - accuracy: 0.8163 - val_loss: 0.6825 - val_accuracy: 0.7341\n",
      "Epoch 141/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4944 - accuracy: 0.8189 - val_loss: 0.6380 - val_accuracy: 0.7639\n",
      "Epoch 142/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4955 - accuracy: 0.8189 - val_loss: 0.6579 - val_accuracy: 0.7758\n",
      "Epoch 143/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.4988 - accuracy: 0.8138 - val_loss: 0.6617 - val_accuracy: 0.7421\n",
      "Epoch 144/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.4967 - accuracy: 0.7976 - val_loss: 0.6667 - val_accuracy: 0.7500\n",
      "Epoch 145/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.4831 - accuracy: 0.8376 - val_loss: 0.6758 - val_accuracy: 0.7540\n",
      "Epoch 146/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.4760 - accuracy: 0.8359 - val_loss: 0.6561 - val_accuracy: 0.7738\n",
      "Epoch 147/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.4839 - accuracy: 0.8282 - val_loss: 0.6404 - val_accuracy: 0.7639\n",
      "Epoch 148/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.4717 - accuracy: 0.8291 - val_loss: 0.6281 - val_accuracy: 0.7837\n",
      "Epoch 149/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.4880 - accuracy: 0.8180 - val_loss: 0.6652 - val_accuracy: 0.7758\n",
      "Epoch 150/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.4897 - accuracy: 0.8197 - val_loss: 0.6380 - val_accuracy: 0.7837\n",
      "Epoch 151/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4692 - accuracy: 0.8138 - val_loss: 0.6375 - val_accuracy: 0.7798\n",
      "Epoch 152/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.4591 - accuracy: 0.8359 - val_loss: 0.6224 - val_accuracy: 0.7996\n",
      "Epoch 153/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4633 - accuracy: 0.8291 - val_loss: 0.6945 - val_accuracy: 0.7679\n",
      "Epoch 154/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4628 - accuracy: 0.8350 - val_loss: 0.6332 - val_accuracy: 0.7639\n",
      "Epoch 155/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4589 - accuracy: 0.8325 - val_loss: 0.6215 - val_accuracy: 0.7976\n",
      "Epoch 156/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4840 - accuracy: 0.8180 - val_loss: 0.6316 - val_accuracy: 0.7679\n",
      "Epoch 157/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4387 - accuracy: 0.8435 - val_loss: 0.6191 - val_accuracy: 0.7817\n",
      "Epoch 158/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.4668 - accuracy: 0.8265 - val_loss: 0.6188 - val_accuracy: 0.7857\n",
      "Epoch 159/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4536 - accuracy: 0.8359 - val_loss: 0.6318 - val_accuracy: 0.7599\n",
      "Epoch 160/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4414 - accuracy: 0.8376 - val_loss: 0.6399 - val_accuracy: 0.7659\n",
      "Epoch 161/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.4508 - accuracy: 0.8359 - val_loss: 0.6167 - val_accuracy: 0.7798\n",
      "Epoch 162/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.4551 - accuracy: 0.8452 - val_loss: 0.6249 - val_accuracy: 0.8075\n",
      "Epoch 163/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.4376 - accuracy: 0.8393 - val_loss: 0.6315 - val_accuracy: 0.7778\n",
      "Epoch 164/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.4531 - accuracy: 0.8299 - val_loss: 0.6240 - val_accuracy: 0.7758\n",
      "Epoch 165/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4416 - accuracy: 0.8529 - val_loss: 0.6327 - val_accuracy: 0.7599\n",
      "Epoch 166/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4191 - accuracy: 0.8571 - val_loss: 0.6276 - val_accuracy: 0.7956\n",
      "Epoch 167/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4392 - accuracy: 0.8248 - val_loss: 0.5963 - val_accuracy: 0.8016\n",
      "Epoch 168/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.4535 - accuracy: 0.8376 - val_loss: 0.6177 - val_accuracy: 0.8016\n",
      "Epoch 169/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.4483 - accuracy: 0.8291 - val_loss: 0.6487 - val_accuracy: 0.7857\n",
      "Epoch 170/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.4290 - accuracy: 0.8520 - val_loss: 0.6013 - val_accuracy: 0.7917\n",
      "Epoch 171/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4338 - accuracy: 0.8435 - val_loss: 0.6148 - val_accuracy: 0.8075\n",
      "Epoch 172/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4378 - accuracy: 0.8291 - val_loss: 0.5972 - val_accuracy: 0.7996\n",
      "Epoch 173/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4093 - accuracy: 0.8529 - val_loss: 0.5907 - val_accuracy: 0.8095\n",
      "Epoch 174/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4160 - accuracy: 0.8605 - val_loss: 0.5916 - val_accuracy: 0.8135\n",
      "Epoch 175/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.4224 - accuracy: 0.8520 - val_loss: 0.5973 - val_accuracy: 0.8036\n",
      "Epoch 176/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.4043 - accuracy: 0.8537 - val_loss: 0.5964 - val_accuracy: 0.7976\n",
      "Epoch 177/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4237 - accuracy: 0.8563 - val_loss: 0.6360 - val_accuracy: 0.7976\n",
      "Epoch 178/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.3998 - accuracy: 0.8563 - val_loss: 0.6138 - val_accuracy: 0.7778\n",
      "Epoch 179/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.4037 - accuracy: 0.8546 - val_loss: 0.5992 - val_accuracy: 0.8056\n",
      "Epoch 180/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.4079 - accuracy: 0.8605 - val_loss: 0.6202 - val_accuracy: 0.7837\n",
      "Epoch 181/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.4090 - accuracy: 0.8580 - val_loss: 0.5805 - val_accuracy: 0.8115\n",
      "Epoch 182/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.3953 - accuracy: 0.8673 - val_loss: 0.5924 - val_accuracy: 0.7837\n",
      "Epoch 183/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.3972 - accuracy: 0.8707 - val_loss: 0.6357 - val_accuracy: 0.7996\n",
      "Epoch 184/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.4113 - accuracy: 0.8580 - val_loss: 0.6211 - val_accuracy: 0.8016\n",
      "Epoch 185/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.4040 - accuracy: 0.8563 - val_loss: 0.5756 - val_accuracy: 0.8194\n",
      "Epoch 186/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.4145 - accuracy: 0.8580 - val_loss: 0.6117 - val_accuracy: 0.7817\n",
      "Epoch 187/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.3964 - accuracy: 0.8563 - val_loss: 0.6063 - val_accuracy: 0.8115\n",
      "Epoch 188/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.3961 - accuracy: 0.8622 - val_loss: 0.6733 - val_accuracy: 0.7440\n",
      "Epoch 189/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.4099 - accuracy: 0.8512 - val_loss: 0.5865 - val_accuracy: 0.7937\n",
      "Epoch 190/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.3861 - accuracy: 0.8605 - val_loss: 0.5886 - val_accuracy: 0.7817\n",
      "Epoch 191/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.3726 - accuracy: 0.8665 - val_loss: 0.6035 - val_accuracy: 0.7738\n",
      "Epoch 192/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.3792 - accuracy: 0.8699 - val_loss: 0.5649 - val_accuracy: 0.8175\n",
      "Epoch 193/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.3773 - accuracy: 0.8741 - val_loss: 0.5872 - val_accuracy: 0.8056\n",
      "Epoch 194/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.3945 - accuracy: 0.8622 - val_loss: 0.5768 - val_accuracy: 0.8155\n",
      "Epoch 195/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.3729 - accuracy: 0.8656 - val_loss: 0.5681 - val_accuracy: 0.7976\n",
      "Epoch 196/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.3987 - accuracy: 0.8554 - val_loss: 0.6558 - val_accuracy: 0.7440\n",
      "Epoch 197/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.3970 - accuracy: 0.8537 - val_loss: 0.5993 - val_accuracy: 0.8095\n",
      "Epoch 198/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.3804 - accuracy: 0.8733 - val_loss: 0.6321 - val_accuracy: 0.7897\n",
      "Epoch 199/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.3839 - accuracy: 0.8665 - val_loss: 0.5815 - val_accuracy: 0.8194\n",
      "Epoch 200/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.3660 - accuracy: 0.8741 - val_loss: 0.6332 - val_accuracy: 0.7679\n",
      "Epoch 201/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.3854 - accuracy: 0.8614 - val_loss: 0.5840 - val_accuracy: 0.8155\n",
      "Epoch 202/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.3670 - accuracy: 0.8724 - val_loss: 0.5925 - val_accuracy: 0.8075\n",
      "Epoch 203/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.3714 - accuracy: 0.8639 - val_loss: 0.5694 - val_accuracy: 0.8135\n",
      "Epoch 204/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.3635 - accuracy: 0.8597 - val_loss: 0.5691 - val_accuracy: 0.8175\n",
      "Epoch 205/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.3719 - accuracy: 0.8622 - val_loss: 0.6436 - val_accuracy: 0.7560\n",
      "Epoch 206/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.3598 - accuracy: 0.8724 - val_loss: 0.5683 - val_accuracy: 0.8135\n",
      "Epoch 207/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.3566 - accuracy: 0.8665 - val_loss: 0.6049 - val_accuracy: 0.7937\n",
      "Epoch 208/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.3675 - accuracy: 0.8682 - val_loss: 0.5800 - val_accuracy: 0.8115\n",
      "Epoch 209/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.3696 - accuracy: 0.8767 - val_loss: 0.5812 - val_accuracy: 0.8036\n",
      "Epoch 210/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.3626 - accuracy: 0.8793 - val_loss: 0.6227 - val_accuracy: 0.8095\n",
      "Epoch 211/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.3509 - accuracy: 0.8827 - val_loss: 0.6167 - val_accuracy: 0.7619\n",
      "Epoch 212/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.3752 - accuracy: 0.8580 - val_loss: 0.5503 - val_accuracy: 0.8294\n",
      "Epoch 213/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.3466 - accuracy: 0.8810 - val_loss: 0.5937 - val_accuracy: 0.8175\n",
      "Epoch 214/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.3435 - accuracy: 0.8818 - val_loss: 0.5557 - val_accuracy: 0.8214\n",
      "Epoch 215/1000\n",
      "74/74 [==============================] - 2s 28ms/step - loss: 0.3419 - accuracy: 0.8759 - val_loss: 0.5655 - val_accuracy: 0.8056\n",
      "Epoch 216/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.3455 - accuracy: 0.8759 - val_loss: 0.5650 - val_accuracy: 0.8274\n",
      "Epoch 217/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.3444 - accuracy: 0.8716 - val_loss: 0.5536 - val_accuracy: 0.8155\n",
      "Epoch 218/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.3297 - accuracy: 0.8895 - val_loss: 0.5781 - val_accuracy: 0.7956\n",
      "Epoch 219/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.3395 - accuracy: 0.8861 - val_loss: 0.5803 - val_accuracy: 0.8016\n",
      "Epoch 220/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.3541 - accuracy: 0.8716 - val_loss: 0.5597 - val_accuracy: 0.8194\n",
      "Epoch 221/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.3347 - accuracy: 0.8861 - val_loss: 0.5409 - val_accuracy: 0.8294\n",
      "Epoch 222/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.3593 - accuracy: 0.8699 - val_loss: 0.5480 - val_accuracy: 0.8194\n",
      "Epoch 223/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.3345 - accuracy: 0.8835 - val_loss: 0.5685 - val_accuracy: 0.8175\n",
      "Epoch 224/1000\n",
      "74/74 [==============================] - 2s 23ms/step - loss: 0.3448 - accuracy: 0.8852 - val_loss: 0.5545 - val_accuracy: 0.8175\n",
      "Epoch 225/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.3381 - accuracy: 0.8861 - val_loss: 0.5507 - val_accuracy: 0.8254\n",
      "Epoch 226/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.3356 - accuracy: 0.8793 - val_loss: 0.5554 - val_accuracy: 0.8115\n",
      "Epoch 227/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.3357 - accuracy: 0.8852 - val_loss: 0.5877 - val_accuracy: 0.8016\n",
      "Epoch 228/1000\n",
      "74/74 [==============================] - 2s 20ms/step - loss: 0.3318 - accuracy: 0.8844 - val_loss: 0.5638 - val_accuracy: 0.7956\n",
      "Epoch 229/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.3364 - accuracy: 0.8886 - val_loss: 0.5583 - val_accuracy: 0.8234\n",
      "Epoch 230/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.3165 - accuracy: 0.8920 - val_loss: 0.5463 - val_accuracy: 0.8254\n",
      "Epoch 231/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.3107 - accuracy: 0.8988 - val_loss: 0.5744 - val_accuracy: 0.8155\n",
      "Epoch 232/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.3217 - accuracy: 0.8980 - val_loss: 0.5562 - val_accuracy: 0.8214\n",
      "Epoch 233/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.3216 - accuracy: 0.8861 - val_loss: 0.5731 - val_accuracy: 0.8194\n",
      "Epoch 234/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.3177 - accuracy: 0.8852 - val_loss: 0.5341 - val_accuracy: 0.8194\n",
      "Epoch 235/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.3129 - accuracy: 0.8844 - val_loss: 0.5586 - val_accuracy: 0.8214\n",
      "Epoch 236/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.3108 - accuracy: 0.8971 - val_loss: 0.5361 - val_accuracy: 0.8214\n",
      "Epoch 237/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.3117 - accuracy: 0.8937 - val_loss: 0.5647 - val_accuracy: 0.8194\n",
      "Epoch 238/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.3137 - accuracy: 0.8878 - val_loss: 0.5448 - val_accuracy: 0.8274\n",
      "Epoch 239/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.3235 - accuracy: 0.8759 - val_loss: 0.5624 - val_accuracy: 0.8036\n",
      "Epoch 240/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.3076 - accuracy: 0.8946 - val_loss: 0.5477 - val_accuracy: 0.8294\n",
      "Epoch 241/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.2975 - accuracy: 0.9031 - val_loss: 0.5616 - val_accuracy: 0.8135\n",
      "Epoch 242/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.2947 - accuracy: 0.8937 - val_loss: 0.5504 - val_accuracy: 0.8234\n",
      "Epoch 243/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.3104 - accuracy: 0.9014 - val_loss: 0.5370 - val_accuracy: 0.8234\n",
      "Epoch 244/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.3063 - accuracy: 0.8980 - val_loss: 0.5351 - val_accuracy: 0.8313\n",
      "Epoch 245/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.3046 - accuracy: 0.8954 - val_loss: 0.5375 - val_accuracy: 0.8194\n",
      "Epoch 246/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.2990 - accuracy: 0.9014 - val_loss: 0.5491 - val_accuracy: 0.8016\n",
      "Epoch 247/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.3088 - accuracy: 0.8886 - val_loss: 0.5297 - val_accuracy: 0.8393\n",
      "Epoch 248/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.3041 - accuracy: 0.8946 - val_loss: 0.5606 - val_accuracy: 0.8115\n",
      "Epoch 249/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2948 - accuracy: 0.9014 - val_loss: 0.5612 - val_accuracy: 0.7976\n",
      "Epoch 250/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.2983 - accuracy: 0.9073 - val_loss: 0.5666 - val_accuracy: 0.8036\n",
      "Epoch 251/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.2981 - accuracy: 0.9022 - val_loss: 0.5515 - val_accuracy: 0.8115\n",
      "Epoch 252/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.3016 - accuracy: 0.8946 - val_loss: 0.5496 - val_accuracy: 0.8135\n",
      "Epoch 253/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.3003 - accuracy: 0.8946 - val_loss: 0.5370 - val_accuracy: 0.8313\n",
      "Epoch 254/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.2892 - accuracy: 0.9048 - val_loss: 0.5444 - val_accuracy: 0.8234\n",
      "Epoch 255/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2964 - accuracy: 0.9005 - val_loss: 0.5278 - val_accuracy: 0.8175\n",
      "Epoch 256/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.3006 - accuracy: 0.8954 - val_loss: 0.5382 - val_accuracy: 0.8274\n",
      "Epoch 257/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2971 - accuracy: 0.8920 - val_loss: 0.5594 - val_accuracy: 0.7937\n",
      "Epoch 258/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2894 - accuracy: 0.9031 - val_loss: 0.5711 - val_accuracy: 0.8155\n",
      "Epoch 259/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.2987 - accuracy: 0.8929 - val_loss: 0.5794 - val_accuracy: 0.7976\n",
      "Epoch 260/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.3002 - accuracy: 0.8869 - val_loss: 0.5401 - val_accuracy: 0.8075\n",
      "Epoch 261/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2835 - accuracy: 0.9039 - val_loss: 0.5383 - val_accuracy: 0.8274\n",
      "Epoch 262/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2702 - accuracy: 0.9099 - val_loss: 0.5636 - val_accuracy: 0.7917\n",
      "Epoch 263/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.2751 - accuracy: 0.9141 - val_loss: 0.5451 - val_accuracy: 0.8175\n",
      "Epoch 264/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2746 - accuracy: 0.9090 - val_loss: 0.5614 - val_accuracy: 0.8155\n",
      "Epoch 265/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2716 - accuracy: 0.9107 - val_loss: 0.5238 - val_accuracy: 0.8393\n",
      "Epoch 266/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.2740 - accuracy: 0.9124 - val_loss: 0.5371 - val_accuracy: 0.8194\n",
      "Epoch 267/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2744 - accuracy: 0.9073 - val_loss: 0.5324 - val_accuracy: 0.8373\n",
      "Epoch 268/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2675 - accuracy: 0.9099 - val_loss: 0.5107 - val_accuracy: 0.8353\n",
      "Epoch 269/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2638 - accuracy: 0.9141 - val_loss: 0.5434 - val_accuracy: 0.8333\n",
      "Epoch 270/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2755 - accuracy: 0.9065 - val_loss: 0.5237 - val_accuracy: 0.8333\n",
      "Epoch 271/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.2875 - accuracy: 0.8997 - val_loss: 0.5549 - val_accuracy: 0.8214\n",
      "Epoch 272/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.2586 - accuracy: 0.9133 - val_loss: 0.5142 - val_accuracy: 0.8294\n",
      "Epoch 273/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2725 - accuracy: 0.8997 - val_loss: 0.6008 - val_accuracy: 0.7877\n",
      "Epoch 274/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.2778 - accuracy: 0.9048 - val_loss: 0.5435 - val_accuracy: 0.8294\n",
      "Epoch 275/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2633 - accuracy: 0.9099 - val_loss: 0.5181 - val_accuracy: 0.8373\n",
      "Epoch 276/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2572 - accuracy: 0.9048 - val_loss: 0.5454 - val_accuracy: 0.8016\n",
      "Epoch 277/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.2553 - accuracy: 0.9158 - val_loss: 0.4943 - val_accuracy: 0.8353\n",
      "Epoch 278/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2580 - accuracy: 0.9175 - val_loss: 0.5543 - val_accuracy: 0.8075\n",
      "Epoch 279/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.2645 - accuracy: 0.9082 - val_loss: 0.5113 - val_accuracy: 0.8333\n",
      "Epoch 280/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2597 - accuracy: 0.9175 - val_loss: 0.5308 - val_accuracy: 0.8373\n",
      "Epoch 281/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.2688 - accuracy: 0.9116 - val_loss: 0.5224 - val_accuracy: 0.8294\n",
      "Epoch 282/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.2512 - accuracy: 0.9116 - val_loss: 0.5846 - val_accuracy: 0.7956\n",
      "Epoch 283/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.2609 - accuracy: 0.9065 - val_loss: 0.4983 - val_accuracy: 0.8452\n",
      "Epoch 284/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.2677 - accuracy: 0.9031 - val_loss: 0.5130 - val_accuracy: 0.8194\n",
      "Epoch 285/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.2547 - accuracy: 0.9150 - val_loss: 0.5291 - val_accuracy: 0.8234\n",
      "Epoch 286/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.2441 - accuracy: 0.9201 - val_loss: 0.5852 - val_accuracy: 0.8135\n",
      "Epoch 287/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.2610 - accuracy: 0.9107 - val_loss: 0.5100 - val_accuracy: 0.8353\n",
      "Epoch 288/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2442 - accuracy: 0.9201 - val_loss: 0.5463 - val_accuracy: 0.8135\n",
      "Epoch 289/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.2421 - accuracy: 0.9158 - val_loss: 0.5305 - val_accuracy: 0.8175\n",
      "Epoch 290/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.2460 - accuracy: 0.9209 - val_loss: 0.5337 - val_accuracy: 0.8214\n",
      "Epoch 291/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.2471 - accuracy: 0.9082 - val_loss: 0.5029 - val_accuracy: 0.8452\n",
      "Epoch 292/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.2446 - accuracy: 0.9116 - val_loss: 0.5572 - val_accuracy: 0.8135\n",
      "Epoch 293/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.2475 - accuracy: 0.9167 - val_loss: 0.5194 - val_accuracy: 0.8294\n",
      "Epoch 294/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.2540 - accuracy: 0.9141 - val_loss: 0.5149 - val_accuracy: 0.8274\n",
      "Epoch 295/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.2436 - accuracy: 0.9235 - val_loss: 0.5164 - val_accuracy: 0.8413\n",
      "Epoch 296/1000\n",
      "74/74 [==============================] - 2s 23ms/step - loss: 0.2382 - accuracy: 0.9201 - val_loss: 0.5097 - val_accuracy: 0.8294\n",
      "Epoch 297/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.2517 - accuracy: 0.9133 - val_loss: 0.5331 - val_accuracy: 0.8294\n",
      "Epoch 298/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.2373 - accuracy: 0.9167 - val_loss: 0.5154 - val_accuracy: 0.8274\n",
      "Epoch 299/1000\n",
      "74/74 [==============================] - 2s 24ms/step - loss: 0.2392 - accuracy: 0.9226 - val_loss: 0.5262 - val_accuracy: 0.8313\n",
      "Epoch 300/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2346 - accuracy: 0.9218 - val_loss: 0.5968 - val_accuracy: 0.7917\n",
      "Epoch 301/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2407 - accuracy: 0.9099 - val_loss: 0.5198 - val_accuracy: 0.8234\n",
      "Epoch 302/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2396 - accuracy: 0.9116 - val_loss: 0.5065 - val_accuracy: 0.8333\n",
      "Epoch 303/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2334 - accuracy: 0.9243 - val_loss: 0.5159 - val_accuracy: 0.8294\n",
      "Epoch 304/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2288 - accuracy: 0.9184 - val_loss: 0.4993 - val_accuracy: 0.8353\n",
      "Epoch 305/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2355 - accuracy: 0.9158 - val_loss: 0.4916 - val_accuracy: 0.8433\n",
      "Epoch 306/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2293 - accuracy: 0.9303 - val_loss: 0.5077 - val_accuracy: 0.8373\n",
      "Epoch 307/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2244 - accuracy: 0.9277 - val_loss: 0.5127 - val_accuracy: 0.8214\n",
      "Epoch 308/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.2261 - accuracy: 0.9303 - val_loss: 0.5029 - val_accuracy: 0.8532\n",
      "Epoch 309/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2312 - accuracy: 0.9252 - val_loss: 0.5002 - val_accuracy: 0.8353\n",
      "Epoch 310/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2364 - accuracy: 0.9226 - val_loss: 0.5090 - val_accuracy: 0.8413\n",
      "Epoch 311/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2242 - accuracy: 0.9226 - val_loss: 0.5219 - val_accuracy: 0.8194\n",
      "Epoch 312/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2300 - accuracy: 0.9209 - val_loss: 0.5387 - val_accuracy: 0.8175\n",
      "Epoch 313/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2402 - accuracy: 0.9124 - val_loss: 0.5240 - val_accuracy: 0.8472\n",
      "Epoch 314/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2390 - accuracy: 0.9158 - val_loss: 0.5169 - val_accuracy: 0.8294\n",
      "Epoch 315/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2165 - accuracy: 0.9252 - val_loss: 0.5175 - val_accuracy: 0.8274\n",
      "Epoch 316/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.2264 - accuracy: 0.9277 - val_loss: 0.5028 - val_accuracy: 0.8333\n",
      "Epoch 317/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.2305 - accuracy: 0.9175 - val_loss: 0.5307 - val_accuracy: 0.8433\n",
      "Epoch 318/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.2138 - accuracy: 0.9337 - val_loss: 0.5384 - val_accuracy: 0.8393\n",
      "Epoch 319/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2203 - accuracy: 0.9269 - val_loss: 0.5030 - val_accuracy: 0.8393\n",
      "Epoch 320/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2266 - accuracy: 0.9175 - val_loss: 0.5198 - val_accuracy: 0.8313\n",
      "Epoch 321/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2245 - accuracy: 0.9269 - val_loss: 0.5317 - val_accuracy: 0.8214\n",
      "Epoch 322/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2154 - accuracy: 0.9286 - val_loss: 0.5022 - val_accuracy: 0.8333\n",
      "Epoch 323/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2105 - accuracy: 0.9294 - val_loss: 0.4927 - val_accuracy: 0.8373\n",
      "Epoch 324/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2144 - accuracy: 0.9269 - val_loss: 0.4940 - val_accuracy: 0.8472\n",
      "Epoch 325/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2050 - accuracy: 0.9328 - val_loss: 0.5560 - val_accuracy: 0.8353\n",
      "Epoch 326/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2109 - accuracy: 0.9277 - val_loss: 0.5166 - val_accuracy: 0.8333\n",
      "Epoch 327/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.2195 - accuracy: 0.9192 - val_loss: 0.5165 - val_accuracy: 0.8313\n",
      "Epoch 328/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.2138 - accuracy: 0.9226 - val_loss: 0.5242 - val_accuracy: 0.8373\n",
      "Epoch 329/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2205 - accuracy: 0.9184 - val_loss: 0.4789 - val_accuracy: 0.8591\n",
      "Epoch 330/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.1913 - accuracy: 0.9362 - val_loss: 0.5384 - val_accuracy: 0.8274\n",
      "Epoch 331/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.2055 - accuracy: 0.9303 - val_loss: 0.5068 - val_accuracy: 0.8373\n",
      "Epoch 332/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.2180 - accuracy: 0.9320 - val_loss: 0.5229 - val_accuracy: 0.8214\n",
      "Epoch 333/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1973 - accuracy: 0.9405 - val_loss: 0.4961 - val_accuracy: 0.8373\n",
      "Epoch 334/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2062 - accuracy: 0.9320 - val_loss: 0.5399 - val_accuracy: 0.8313\n",
      "Epoch 335/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.2066 - accuracy: 0.9303 - val_loss: 0.4905 - val_accuracy: 0.8294\n",
      "Epoch 336/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2022 - accuracy: 0.9320 - val_loss: 0.5096 - val_accuracy: 0.8373\n",
      "Epoch 337/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2132 - accuracy: 0.9269 - val_loss: 0.5114 - val_accuracy: 0.8353\n",
      "Epoch 338/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.2011 - accuracy: 0.9345 - val_loss: 0.4959 - val_accuracy: 0.8353\n",
      "Epoch 339/1000\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.1962 - accuracy: 0.9396 - val_loss: 0.5331 - val_accuracy: 0.8333\n",
      "Epoch 340/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2044 - accuracy: 0.9269 - val_loss: 0.4894 - val_accuracy: 0.8393\n",
      "Epoch 341/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.2018 - accuracy: 0.9303 - val_loss: 0.5134 - val_accuracy: 0.8313\n",
      "Epoch 342/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.2134 - accuracy: 0.9252 - val_loss: 0.4909 - val_accuracy: 0.8413\n",
      "Epoch 343/1000\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.2197 - accuracy: 0.9286 - val_loss: 0.5110 - val_accuracy: 0.8214\n",
      "Epoch 344/1000\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.1966 - accuracy: 0.9422 - val_loss: 0.5153 - val_accuracy: 0.8353\n",
      "Epoch 345/1000\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.1935 - accuracy: 0.9303 - val_loss: 0.4981 - val_accuracy: 0.8313\n",
      "Epoch 346/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.1966 - accuracy: 0.9294 - val_loss: 0.5522 - val_accuracy: 0.8135\n",
      "Epoch 347/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.1978 - accuracy: 0.9354 - val_loss: 0.5227 - val_accuracy: 0.8234\n",
      "Epoch 348/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.1852 - accuracy: 0.9405 - val_loss: 0.5162 - val_accuracy: 0.8333\n",
      "Epoch 349/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.1914 - accuracy: 0.9371 - val_loss: 0.5111 - val_accuracy: 0.8512\n",
      "Epoch 350/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.2072 - accuracy: 0.9269 - val_loss: 0.5479 - val_accuracy: 0.8294\n",
      "Epoch 351/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.1892 - accuracy: 0.9354 - val_loss: 0.4961 - val_accuracy: 0.8472\n",
      "Epoch 352/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.1941 - accuracy: 0.9345 - val_loss: 0.5435 - val_accuracy: 0.8194\n",
      "Epoch 353/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.2015 - accuracy: 0.9345 - val_loss: 0.5103 - val_accuracy: 0.8333\n",
      "Epoch 354/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.2026 - accuracy: 0.9379 - val_loss: 0.5000 - val_accuracy: 0.8333\n",
      "Epoch 355/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.1945 - accuracy: 0.9320 - val_loss: 0.5022 - val_accuracy: 0.8452\n",
      "Epoch 356/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1846 - accuracy: 0.9473 - val_loss: 0.4964 - val_accuracy: 0.8512\n",
      "Epoch 357/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.1736 - accuracy: 0.9413 - val_loss: 0.5102 - val_accuracy: 0.8333\n",
      "Epoch 358/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1914 - accuracy: 0.9337 - val_loss: 0.5635 - val_accuracy: 0.8175\n",
      "Epoch 359/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.1956 - accuracy: 0.9311 - val_loss: 0.5266 - val_accuracy: 0.8294\n",
      "Epoch 360/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1894 - accuracy: 0.9328 - val_loss: 0.5078 - val_accuracy: 0.8274\n",
      "Epoch 361/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1870 - accuracy: 0.9405 - val_loss: 0.5831 - val_accuracy: 0.8056\n",
      "Epoch 362/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1854 - accuracy: 0.9379 - val_loss: 0.5053 - val_accuracy: 0.8393\n",
      "Epoch 363/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1667 - accuracy: 0.9498 - val_loss: 0.5185 - val_accuracy: 0.8214\n",
      "Epoch 364/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1871 - accuracy: 0.9439 - val_loss: 0.5297 - val_accuracy: 0.8373\n",
      "Epoch 365/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.1710 - accuracy: 0.9507 - val_loss: 0.5657 - val_accuracy: 0.8036\n",
      "Epoch 366/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.1703 - accuracy: 0.9541 - val_loss: 0.5389 - val_accuracy: 0.8333\n",
      "Epoch 367/1000\n",
      "74/74 [==============================] - 2s 27ms/step - loss: 0.1881 - accuracy: 0.9345 - val_loss: 0.5184 - val_accuracy: 0.8393\n",
      "Epoch 368/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.1855 - accuracy: 0.9405 - val_loss: 0.5308 - val_accuracy: 0.8353\n",
      "Epoch 369/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.1797 - accuracy: 0.9345 - val_loss: 0.5317 - val_accuracy: 0.8254\n",
      "Epoch 370/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.1848 - accuracy: 0.9464 - val_loss: 0.4802 - val_accuracy: 0.8373\n",
      "Epoch 371/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.1735 - accuracy: 0.9515 - val_loss: 0.5227 - val_accuracy: 0.8234\n",
      "Epoch 372/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.1841 - accuracy: 0.9354 - val_loss: 0.4977 - val_accuracy: 0.8452\n",
      "Epoch 373/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.1658 - accuracy: 0.9473 - val_loss: 0.5088 - val_accuracy: 0.8393\n",
      "Epoch 374/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1728 - accuracy: 0.9447 - val_loss: 0.5193 - val_accuracy: 0.8611\n",
      "Epoch 375/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.1805 - accuracy: 0.9379 - val_loss: 0.4961 - val_accuracy: 0.8333\n",
      "Epoch 376/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.1750 - accuracy: 0.9464 - val_loss: 0.4844 - val_accuracy: 0.8611\n",
      "Epoch 377/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.1726 - accuracy: 0.9447 - val_loss: 0.5486 - val_accuracy: 0.8333\n",
      "Epoch 378/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.1735 - accuracy: 0.9481 - val_loss: 0.5513 - val_accuracy: 0.8274\n",
      "Epoch 379/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.1660 - accuracy: 0.9413 - val_loss: 0.5089 - val_accuracy: 0.8353\n",
      "Epoch 380/1000\n",
      "74/74 [==============================] - 2s 25ms/step - loss: 0.1726 - accuracy: 0.9447 - val_loss: 0.4959 - val_accuracy: 0.8452\n",
      "Epoch 381/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.1874 - accuracy: 0.9345 - val_loss: 0.5349 - val_accuracy: 0.8155\n",
      "Epoch 382/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1618 - accuracy: 0.9541 - val_loss: 0.5470 - val_accuracy: 0.8353\n",
      "Epoch 383/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.1570 - accuracy: 0.9456 - val_loss: 0.5136 - val_accuracy: 0.8452\n",
      "Epoch 384/1000\n",
      "74/74 [==============================] - 3s 36ms/step - loss: 0.1549 - accuracy: 0.9532 - val_loss: 0.4971 - val_accuracy: 0.8333\n",
      "Epoch 385/1000\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 0.1708 - accuracy: 0.9464 - val_loss: 0.5039 - val_accuracy: 0.8175\n",
      "Epoch 386/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.1680 - accuracy: 0.9456 - val_loss: 0.5007 - val_accuracy: 0.8452\n",
      "Epoch 387/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.1620 - accuracy: 0.9524 - val_loss: 0.5575 - val_accuracy: 0.8333\n",
      "Epoch 388/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1758 - accuracy: 0.9405 - val_loss: 0.5160 - val_accuracy: 0.8234\n",
      "Epoch 389/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1550 - accuracy: 0.9481 - val_loss: 0.5223 - val_accuracy: 0.8313\n",
      "Epoch 390/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1591 - accuracy: 0.9490 - val_loss: 0.5142 - val_accuracy: 0.8512\n",
      "Epoch 391/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.1628 - accuracy: 0.9447 - val_loss: 0.5555 - val_accuracy: 0.8155\n",
      "Epoch 392/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1546 - accuracy: 0.9558 - val_loss: 0.4970 - val_accuracy: 0.8452\n",
      "Epoch 393/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.1572 - accuracy: 0.9481 - val_loss: 0.5362 - val_accuracy: 0.8234\n",
      "Epoch 394/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.1630 - accuracy: 0.9532 - val_loss: 0.4857 - val_accuracy: 0.8373\n",
      "Epoch 395/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1601 - accuracy: 0.9447 - val_loss: 0.5211 - val_accuracy: 0.8472\n",
      "Epoch 396/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1599 - accuracy: 0.9464 - val_loss: 0.4668 - val_accuracy: 0.8433\n",
      "Epoch 397/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1603 - accuracy: 0.9422 - val_loss: 0.4820 - val_accuracy: 0.8492\n",
      "Epoch 398/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1614 - accuracy: 0.9439 - val_loss: 0.5079 - val_accuracy: 0.8373\n",
      "Epoch 399/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1573 - accuracy: 0.9515 - val_loss: 0.5124 - val_accuracy: 0.8274\n",
      "Epoch 400/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1511 - accuracy: 0.9626 - val_loss: 0.5233 - val_accuracy: 0.8393\n",
      "Epoch 401/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1486 - accuracy: 0.9515 - val_loss: 0.5021 - val_accuracy: 0.8413\n",
      "Epoch 402/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1637 - accuracy: 0.9498 - val_loss: 0.5140 - val_accuracy: 0.8433\n",
      "Epoch 403/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.1453 - accuracy: 0.9583 - val_loss: 0.5063 - val_accuracy: 0.8373\n",
      "Epoch 404/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1505 - accuracy: 0.9566 - val_loss: 0.5121 - val_accuracy: 0.8333\n",
      "Epoch 405/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1526 - accuracy: 0.9490 - val_loss: 0.4753 - val_accuracy: 0.8571\n",
      "Epoch 406/1000\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 0.1480 - accuracy: 0.9490 - val_loss: 0.5182 - val_accuracy: 0.8433\n",
      "Epoch 407/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.1443 - accuracy: 0.9481 - val_loss: 0.5141 - val_accuracy: 0.8512\n",
      "Epoch 408/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1570 - accuracy: 0.9439 - val_loss: 0.5175 - val_accuracy: 0.8571\n",
      "Epoch 409/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1421 - accuracy: 0.9558 - val_loss: 0.5050 - val_accuracy: 0.8452\n",
      "Epoch 410/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1529 - accuracy: 0.9507 - val_loss: 0.5076 - val_accuracy: 0.8452\n",
      "Epoch 411/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.1539 - accuracy: 0.9490 - val_loss: 0.5212 - val_accuracy: 0.8472\n",
      "Epoch 412/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.1484 - accuracy: 0.9524 - val_loss: 0.5447 - val_accuracy: 0.8333\n",
      "Epoch 413/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1516 - accuracy: 0.9430 - val_loss: 0.4948 - val_accuracy: 0.8512\n",
      "Epoch 414/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.1416 - accuracy: 0.9515 - val_loss: 0.4887 - val_accuracy: 0.8552\n",
      "Epoch 415/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1504 - accuracy: 0.9507 - val_loss: 0.5166 - val_accuracy: 0.8373\n",
      "Epoch 416/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1418 - accuracy: 0.9558 - val_loss: 0.5210 - val_accuracy: 0.8512\n",
      "Epoch 417/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1433 - accuracy: 0.9524 - val_loss: 0.5401 - val_accuracy: 0.8492\n",
      "Epoch 418/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.1392 - accuracy: 0.9575 - val_loss: 0.4940 - val_accuracy: 0.8631\n",
      "Epoch 419/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.1485 - accuracy: 0.9566 - val_loss: 0.5169 - val_accuracy: 0.8373\n",
      "Epoch 420/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1470 - accuracy: 0.9524 - val_loss: 0.5184 - val_accuracy: 0.8571\n",
      "Epoch 421/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1394 - accuracy: 0.9600 - val_loss: 0.4956 - val_accuracy: 0.8552\n",
      "Epoch 422/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.1414 - accuracy: 0.9558 - val_loss: 0.5361 - val_accuracy: 0.8373\n",
      "Epoch 423/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1351 - accuracy: 0.9600 - val_loss: 0.4901 - val_accuracy: 0.8611\n",
      "Epoch 424/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1451 - accuracy: 0.9541 - val_loss: 0.5308 - val_accuracy: 0.8313\n",
      "Epoch 425/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1366 - accuracy: 0.9592 - val_loss: 0.5384 - val_accuracy: 0.8492\n",
      "Epoch 426/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1431 - accuracy: 0.9600 - val_loss: 0.4777 - val_accuracy: 0.8532\n",
      "Epoch 427/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1507 - accuracy: 0.9490 - val_loss: 0.4823 - val_accuracy: 0.8552\n",
      "Epoch 428/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1399 - accuracy: 0.9549 - val_loss: 0.4845 - val_accuracy: 0.8532\n",
      "Epoch 429/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1325 - accuracy: 0.9617 - val_loss: 0.4963 - val_accuracy: 0.8433\n",
      "Epoch 430/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.1350 - accuracy: 0.9609 - val_loss: 0.4852 - val_accuracy: 0.8472\n",
      "Epoch 431/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1307 - accuracy: 0.9626 - val_loss: 0.5065 - val_accuracy: 0.8452\n",
      "Epoch 432/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1360 - accuracy: 0.9515 - val_loss: 0.4607 - val_accuracy: 0.8571\n",
      "Epoch 433/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1408 - accuracy: 0.9541 - val_loss: 0.4897 - val_accuracy: 0.8512\n",
      "Epoch 434/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1399 - accuracy: 0.9600 - val_loss: 0.5174 - val_accuracy: 0.8472\n",
      "Epoch 435/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1351 - accuracy: 0.9592 - val_loss: 0.5364 - val_accuracy: 0.8373\n",
      "Epoch 436/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.1257 - accuracy: 0.9626 - val_loss: 0.5045 - val_accuracy: 0.8433\n",
      "Epoch 437/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.1433 - accuracy: 0.9524 - val_loss: 0.4928 - val_accuracy: 0.8492\n",
      "Epoch 438/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1319 - accuracy: 0.9558 - val_loss: 0.5102 - val_accuracy: 0.8552\n",
      "Epoch 439/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1297 - accuracy: 0.9575 - val_loss: 0.4979 - val_accuracy: 0.8492\n",
      "Epoch 440/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1344 - accuracy: 0.9532 - val_loss: 0.4879 - val_accuracy: 0.8452\n",
      "Epoch 441/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1218 - accuracy: 0.9626 - val_loss: 0.4761 - val_accuracy: 0.8571\n",
      "Epoch 442/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1328 - accuracy: 0.9558 - val_loss: 0.5042 - val_accuracy: 0.8492\n",
      "Epoch 443/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1253 - accuracy: 0.9626 - val_loss: 0.5373 - val_accuracy: 0.8492\n",
      "Epoch 444/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.1351 - accuracy: 0.9592 - val_loss: 0.5370 - val_accuracy: 0.8393\n",
      "Epoch 445/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1242 - accuracy: 0.9617 - val_loss: 0.5182 - val_accuracy: 0.8512\n",
      "Epoch 446/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1279 - accuracy: 0.9600 - val_loss: 0.5392 - val_accuracy: 0.8115\n",
      "Epoch 447/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.1400 - accuracy: 0.9541 - val_loss: 0.5273 - val_accuracy: 0.8254\n",
      "Epoch 448/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1179 - accuracy: 0.9677 - val_loss: 0.4915 - val_accuracy: 0.8552\n",
      "Epoch 449/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.1302 - accuracy: 0.9592 - val_loss: 0.5144 - val_accuracy: 0.8393\n",
      "Epoch 450/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1201 - accuracy: 0.9651 - val_loss: 0.4765 - val_accuracy: 0.8591\n",
      "Epoch 451/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1191 - accuracy: 0.9651 - val_loss: 0.4921 - val_accuracy: 0.8512\n",
      "Epoch 452/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1323 - accuracy: 0.9592 - val_loss: 0.4762 - val_accuracy: 0.8611\n",
      "Epoch 453/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.1214 - accuracy: 0.9634 - val_loss: 0.4904 - val_accuracy: 0.8532\n",
      "Epoch 454/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.1352 - accuracy: 0.9566 - val_loss: 0.5354 - val_accuracy: 0.8433\n",
      "Epoch 455/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.1370 - accuracy: 0.9558 - val_loss: 0.5414 - val_accuracy: 0.8353\n",
      "Epoch 456/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1238 - accuracy: 0.9660 - val_loss: 0.4876 - val_accuracy: 0.8472\n",
      "Epoch 457/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1184 - accuracy: 0.9617 - val_loss: 0.5092 - val_accuracy: 0.8373\n",
      "Epoch 458/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1237 - accuracy: 0.9668 - val_loss: 0.4939 - val_accuracy: 0.8532\n",
      "Epoch 459/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.1185 - accuracy: 0.9583 - val_loss: 0.5094 - val_accuracy: 0.8651\n",
      "Epoch 460/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.1257 - accuracy: 0.9626 - val_loss: 0.5038 - val_accuracy: 0.8671\n",
      "Epoch 461/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.1082 - accuracy: 0.9668 - val_loss: 0.5190 - val_accuracy: 0.8532\n",
      "Epoch 462/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1249 - accuracy: 0.9558 - val_loss: 0.4972 - val_accuracy: 0.8552\n",
      "Epoch 463/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1128 - accuracy: 0.9719 - val_loss: 0.4961 - val_accuracy: 0.8532\n",
      "Epoch 464/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.1138 - accuracy: 0.9643 - val_loss: 0.5550 - val_accuracy: 0.8413\n",
      "Epoch 465/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1219 - accuracy: 0.9634 - val_loss: 0.5365 - val_accuracy: 0.8353\n",
      "Epoch 466/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1195 - accuracy: 0.9660 - val_loss: 0.5145 - val_accuracy: 0.8492\n",
      "Epoch 467/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.1233 - accuracy: 0.9541 - val_loss: 0.4865 - val_accuracy: 0.8571\n",
      "Epoch 468/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1291 - accuracy: 0.9609 - val_loss: 0.6235 - val_accuracy: 0.8155\n",
      "Epoch 469/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1211 - accuracy: 0.9609 - val_loss: 0.5021 - val_accuracy: 0.8571\n",
      "Epoch 470/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1111 - accuracy: 0.9694 - val_loss: 0.5263 - val_accuracy: 0.8452\n",
      "Epoch 471/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1210 - accuracy: 0.9617 - val_loss: 0.4720 - val_accuracy: 0.8611\n",
      "Epoch 472/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1044 - accuracy: 0.9719 - val_loss: 0.4999 - val_accuracy: 0.8452\n",
      "Epoch 473/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1203 - accuracy: 0.9609 - val_loss: 0.5384 - val_accuracy: 0.8393\n",
      "Epoch 474/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.1086 - accuracy: 0.9660 - val_loss: 0.5387 - val_accuracy: 0.8353\n",
      "Epoch 475/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1167 - accuracy: 0.9541 - val_loss: 0.4646 - val_accuracy: 0.8571\n",
      "Epoch 476/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1068 - accuracy: 0.9651 - val_loss: 0.4945 - val_accuracy: 0.8472\n",
      "Epoch 477/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1122 - accuracy: 0.9643 - val_loss: 0.4997 - val_accuracy: 0.8631\n",
      "Epoch 478/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1230 - accuracy: 0.9583 - val_loss: 0.4770 - val_accuracy: 0.8591\n",
      "Epoch 479/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1075 - accuracy: 0.9677 - val_loss: 0.5497 - val_accuracy: 0.8433\n",
      "Epoch 480/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.1095 - accuracy: 0.9643 - val_loss: 0.5212 - val_accuracy: 0.8452\n",
      "Epoch 481/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1014 - accuracy: 0.9643 - val_loss: 0.5372 - val_accuracy: 0.8313\n",
      "Epoch 482/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1139 - accuracy: 0.9617 - val_loss: 0.4924 - val_accuracy: 0.8591\n",
      "Epoch 483/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1069 - accuracy: 0.9736 - val_loss: 0.5350 - val_accuracy: 0.8333\n",
      "Epoch 484/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1075 - accuracy: 0.9677 - val_loss: 0.4809 - val_accuracy: 0.8532\n",
      "Epoch 485/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.1187 - accuracy: 0.9660 - val_loss: 0.5018 - val_accuracy: 0.8472\n",
      "Epoch 486/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1061 - accuracy: 0.9617 - val_loss: 0.4928 - val_accuracy: 0.8611\n",
      "Epoch 487/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1176 - accuracy: 0.9634 - val_loss: 0.5003 - val_accuracy: 0.8532\n",
      "Epoch 488/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.1099 - accuracy: 0.9651 - val_loss: 0.5070 - val_accuracy: 0.8571\n",
      "Epoch 489/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1058 - accuracy: 0.9719 - val_loss: 0.4768 - val_accuracy: 0.8631\n",
      "Epoch 490/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1099 - accuracy: 0.9634 - val_loss: 0.5134 - val_accuracy: 0.8472\n",
      "Epoch 491/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.1089 - accuracy: 0.9651 - val_loss: 0.4995 - val_accuracy: 0.8512\n",
      "Epoch 492/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1113 - accuracy: 0.9626 - val_loss: 0.5036 - val_accuracy: 0.8552\n",
      "Epoch 493/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1065 - accuracy: 0.9660 - val_loss: 0.5128 - val_accuracy: 0.8373\n",
      "Epoch 494/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.0969 - accuracy: 0.9736 - val_loss: 0.5160 - val_accuracy: 0.8591\n",
      "Epoch 495/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1100 - accuracy: 0.9626 - val_loss: 0.5215 - val_accuracy: 0.8472\n",
      "Epoch 496/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0986 - accuracy: 0.9736 - val_loss: 0.5146 - val_accuracy: 0.8492\n",
      "Epoch 497/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.1105 - accuracy: 0.9660 - val_loss: 0.5460 - val_accuracy: 0.8274\n",
      "Epoch 498/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1021 - accuracy: 0.9728 - val_loss: 0.5127 - val_accuracy: 0.8571\n",
      "Epoch 499/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1055 - accuracy: 0.9651 - val_loss: 0.4866 - val_accuracy: 0.8552\n",
      "Epoch 500/1000\n",
      "74/74 [==============================] - 2s 20ms/step - loss: 0.0855 - accuracy: 0.9762 - val_loss: 0.5630 - val_accuracy: 0.8413\n",
      "Epoch 501/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.0905 - accuracy: 0.9787 - val_loss: 0.5184 - val_accuracy: 0.8452\n",
      "Epoch 502/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1013 - accuracy: 0.9719 - val_loss: 0.5124 - val_accuracy: 0.8591\n",
      "Epoch 503/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1045 - accuracy: 0.9762 - val_loss: 0.5033 - val_accuracy: 0.8472\n",
      "Epoch 504/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.1039 - accuracy: 0.9677 - val_loss: 0.5187 - val_accuracy: 0.8532\n",
      "Epoch 505/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0964 - accuracy: 0.9702 - val_loss: 0.4991 - val_accuracy: 0.8571\n",
      "Epoch 506/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1088 - accuracy: 0.9677 - val_loss: 0.5098 - val_accuracy: 0.8552\n",
      "Epoch 507/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.0980 - accuracy: 0.9651 - val_loss: 0.5205 - val_accuracy: 0.8552\n",
      "Epoch 508/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1016 - accuracy: 0.9694 - val_loss: 0.5164 - val_accuracy: 0.8452\n",
      "Epoch 509/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.1017 - accuracy: 0.9634 - val_loss: 0.4829 - val_accuracy: 0.8631\n",
      "Epoch 510/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.0948 - accuracy: 0.9745 - val_loss: 0.5330 - val_accuracy: 0.8294\n",
      "Epoch 511/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0981 - accuracy: 0.9694 - val_loss: 0.5054 - val_accuracy: 0.8690\n",
      "Epoch 512/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0986 - accuracy: 0.9702 - val_loss: 0.5226 - val_accuracy: 0.8512\n",
      "Epoch 513/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.0995 - accuracy: 0.9668 - val_loss: 0.4963 - val_accuracy: 0.8472\n",
      "Epoch 514/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0958 - accuracy: 0.9668 - val_loss: 0.5226 - val_accuracy: 0.8552\n",
      "Epoch 515/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0920 - accuracy: 0.9728 - val_loss: 0.5346 - val_accuracy: 0.8571\n",
      "Epoch 516/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1082 - accuracy: 0.9600 - val_loss: 0.4888 - val_accuracy: 0.8651\n",
      "Epoch 517/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.0798 - accuracy: 0.9753 - val_loss: 0.5043 - val_accuracy: 0.8631\n",
      "Epoch 518/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1000 - accuracy: 0.9719 - val_loss: 0.5525 - val_accuracy: 0.8472\n",
      "Epoch 519/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1062 - accuracy: 0.9643 - val_loss: 0.5142 - val_accuracy: 0.8571\n",
      "Epoch 520/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0969 - accuracy: 0.9651 - val_loss: 0.5197 - val_accuracy: 0.8611\n",
      "Epoch 521/1000\n",
      "74/74 [==============================] - 2s 20ms/step - loss: 0.0946 - accuracy: 0.9668 - val_loss: 0.5104 - val_accuracy: 0.8373\n",
      "Epoch 522/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0922 - accuracy: 0.9668 - val_loss: 0.5418 - val_accuracy: 0.8452\n",
      "Epoch 523/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0908 - accuracy: 0.9719 - val_loss: 0.5421 - val_accuracy: 0.8433\n",
      "Epoch 524/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.1027 - accuracy: 0.9609 - val_loss: 0.5111 - val_accuracy: 0.8492\n",
      "Epoch 525/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0918 - accuracy: 0.9702 - val_loss: 0.5373 - val_accuracy: 0.8413\n",
      "Epoch 526/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0971 - accuracy: 0.9677 - val_loss: 0.5139 - val_accuracy: 0.8591\n",
      "Epoch 527/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0840 - accuracy: 0.9796 - val_loss: 0.5332 - val_accuracy: 0.8472\n",
      "Epoch 528/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0916 - accuracy: 0.9753 - val_loss: 0.5073 - val_accuracy: 0.8472\n",
      "Epoch 529/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0827 - accuracy: 0.9728 - val_loss: 0.5566 - val_accuracy: 0.8393\n",
      "Epoch 530/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0966 - accuracy: 0.9685 - val_loss: 0.5260 - val_accuracy: 0.8571\n",
      "Epoch 531/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0892 - accuracy: 0.9702 - val_loss: 0.4891 - val_accuracy: 0.8671\n",
      "Epoch 532/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.1012 - accuracy: 0.9677 - val_loss: 0.5416 - val_accuracy: 0.8552\n",
      "Epoch 533/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0830 - accuracy: 0.9762 - val_loss: 0.5479 - val_accuracy: 0.8571\n",
      "Epoch 534/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0874 - accuracy: 0.9736 - val_loss: 0.5021 - val_accuracy: 0.8552\n",
      "Epoch 535/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0895 - accuracy: 0.9719 - val_loss: 0.5127 - val_accuracy: 0.8611\n",
      "Epoch 536/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0833 - accuracy: 0.9719 - val_loss: 0.5128 - val_accuracy: 0.8591\n",
      "Epoch 537/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0851 - accuracy: 0.9728 - val_loss: 0.5150 - val_accuracy: 0.8591\n",
      "Epoch 538/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.0942 - accuracy: 0.9694 - val_loss: 0.5044 - val_accuracy: 0.8571\n",
      "Epoch 539/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0935 - accuracy: 0.9753 - val_loss: 0.4995 - val_accuracy: 0.8433\n",
      "Epoch 540/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0988 - accuracy: 0.9694 - val_loss: 0.5581 - val_accuracy: 0.8512\n",
      "Epoch 541/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.0887 - accuracy: 0.9694 - val_loss: 0.5128 - val_accuracy: 0.8552\n",
      "Epoch 542/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0858 - accuracy: 0.9762 - val_loss: 0.4928 - val_accuracy: 0.8671\n",
      "Epoch 543/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.0887 - accuracy: 0.9736 - val_loss: 0.4935 - val_accuracy: 0.8651\n",
      "Epoch 544/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0913 - accuracy: 0.9728 - val_loss: 0.5133 - val_accuracy: 0.8631\n",
      "Epoch 545/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.0782 - accuracy: 0.9762 - val_loss: 0.4894 - val_accuracy: 0.8651\n",
      "Epoch 546/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.1027 - accuracy: 0.9668 - val_loss: 0.5311 - val_accuracy: 0.8532\n",
      "Epoch 547/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.0842 - accuracy: 0.9770 - val_loss: 0.4972 - val_accuracy: 0.8591\n",
      "Epoch 548/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.0888 - accuracy: 0.9796 - val_loss: 0.4836 - val_accuracy: 0.8611\n",
      "Epoch 549/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.0885 - accuracy: 0.9702 - val_loss: 0.5554 - val_accuracy: 0.8194\n",
      "Epoch 550/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.0845 - accuracy: 0.9719 - val_loss: 0.4947 - val_accuracy: 0.8671\n",
      "Epoch 551/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.0845 - accuracy: 0.9728 - val_loss: 0.5600 - val_accuracy: 0.8433\n",
      "Epoch 552/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0837 - accuracy: 0.9813 - val_loss: 0.5096 - val_accuracy: 0.8492\n",
      "Epoch 553/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0782 - accuracy: 0.9847 - val_loss: 0.5466 - val_accuracy: 0.8492\n",
      "Epoch 554/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.0845 - accuracy: 0.9770 - val_loss: 0.5322 - val_accuracy: 0.8472\n",
      "Epoch 555/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.0868 - accuracy: 0.9685 - val_loss: 0.4806 - val_accuracy: 0.8611\n",
      "Epoch 556/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0794 - accuracy: 0.9804 - val_loss: 0.5117 - val_accuracy: 0.8492\n",
      "Epoch 557/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.0806 - accuracy: 0.9753 - val_loss: 0.5040 - val_accuracy: 0.8611\n",
      "Epoch 558/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.0772 - accuracy: 0.9728 - val_loss: 0.5368 - val_accuracy: 0.8690\n",
      "Epoch 559/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.0802 - accuracy: 0.9753 - val_loss: 0.5440 - val_accuracy: 0.8433\n",
      "Epoch 560/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0896 - accuracy: 0.9736 - val_loss: 0.5244 - val_accuracy: 0.8571\n",
      "Epoch 561/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.0813 - accuracy: 0.9702 - val_loss: 0.5537 - val_accuracy: 0.8433\n",
      "Epoch 562/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.0781 - accuracy: 0.9804 - val_loss: 0.5302 - val_accuracy: 0.8571\n",
      "Epoch 563/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.0790 - accuracy: 0.9796 - val_loss: 0.5505 - val_accuracy: 0.8512\n",
      "Epoch 564/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.0841 - accuracy: 0.9745 - val_loss: 0.5202 - val_accuracy: 0.8571\n",
      "Epoch 565/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.0687 - accuracy: 0.9855 - val_loss: 0.5277 - val_accuracy: 0.8472\n",
      "Epoch 566/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0825 - accuracy: 0.9762 - val_loss: 0.5575 - val_accuracy: 0.8512\n",
      "Epoch 567/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0827 - accuracy: 0.9736 - val_loss: 0.5774 - val_accuracy: 0.8393\n",
      "Epoch 568/1000\n",
      "74/74 [==============================] - 2s 34ms/step - loss: 0.0839 - accuracy: 0.9728 - val_loss: 0.4975 - val_accuracy: 0.8651\n",
      "Epoch 569/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0815 - accuracy: 0.9728 - val_loss: 0.5309 - val_accuracy: 0.8571\n",
      "Epoch 570/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.0822 - accuracy: 0.9796 - val_loss: 0.5273 - val_accuracy: 0.8512\n",
      "Epoch 571/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.0772 - accuracy: 0.9804 - val_loss: 0.5402 - val_accuracy: 0.8472\n",
      "Epoch 572/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.0658 - accuracy: 0.9838 - val_loss: 0.5417 - val_accuracy: 0.8730\n",
      "Epoch 573/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0812 - accuracy: 0.9762 - val_loss: 0.5595 - val_accuracy: 0.8651\n",
      "Epoch 574/1000\n",
      "74/74 [==============================] - 1s 11ms/step - loss: 0.0748 - accuracy: 0.9736 - val_loss: 0.4970 - val_accuracy: 0.8770\n",
      "Epoch 575/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0818 - accuracy: 0.9736 - val_loss: 0.5340 - val_accuracy: 0.8631\n",
      "Epoch 576/1000\n",
      "74/74 [==============================] - 1s 8ms/step - loss: 0.0808 - accuracy: 0.9736 - val_loss: 0.5280 - val_accuracy: 0.8651\n",
      "Epoch 577/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0868 - accuracy: 0.9745 - val_loss: 0.5089 - val_accuracy: 0.8512\n",
      "Epoch 578/1000\n",
      "74/74 [==============================] - 1s 10ms/step - loss: 0.0819 - accuracy: 0.9736 - val_loss: 0.4994 - val_accuracy: 0.8552\n",
      "Epoch 579/1000\n",
      "74/74 [==============================] - 2s 27ms/step - loss: 0.0803 - accuracy: 0.9753 - val_loss: 0.5471 - val_accuracy: 0.8532\n",
      "Epoch 580/1000\n",
      "74/74 [==============================] - 2s 26ms/step - loss: 0.0764 - accuracy: 0.9762 - val_loss: 0.5434 - val_accuracy: 0.8472\n",
      "Epoch 581/1000\n",
      "74/74 [==============================] - 2s 25ms/step - loss: 0.0787 - accuracy: 0.9779 - val_loss: 0.5662 - val_accuracy: 0.8413\n",
      "Epoch 582/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0747 - accuracy: 0.9787 - val_loss: 0.5109 - val_accuracy: 0.8671\n",
      "Epoch 583/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0751 - accuracy: 0.9787 - val_loss: 0.4977 - val_accuracy: 0.8631\n",
      "Epoch 584/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0716 - accuracy: 0.9728 - val_loss: 0.5088 - val_accuracy: 0.8611\n",
      "Epoch 585/1000\n",
      "74/74 [==============================] - 1s 9ms/step - loss: 0.0784 - accuracy: 0.9736 - val_loss: 0.4822 - val_accuracy: 0.8730\n",
      "Epoch 586/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0726 - accuracy: 0.9762 - val_loss: 0.5098 - val_accuracy: 0.8631\n",
      "Epoch 587/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0746 - accuracy: 0.9796 - val_loss: 0.5425 - val_accuracy: 0.8333\n",
      "Epoch 588/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0800 - accuracy: 0.9736 - val_loss: 0.5364 - val_accuracy: 0.8611\n",
      "Epoch 589/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0674 - accuracy: 0.9813 - val_loss: 0.5025 - val_accuracy: 0.8651\n",
      "Epoch 590/1000\n",
      "74/74 [==============================] - 2s 24ms/step - loss: 0.0803 - accuracy: 0.9728 - val_loss: 0.5337 - val_accuracy: 0.8611\n",
      "Epoch 591/1000\n",
      "74/74 [==============================] - 2s 27ms/step - loss: 0.0789 - accuracy: 0.9753 - val_loss: 0.5490 - val_accuracy: 0.8532\n",
      "Epoch 592/1000\n",
      "74/74 [==============================] - 2s 24ms/step - loss: 0.0677 - accuracy: 0.9796 - val_loss: 0.5385 - val_accuracy: 0.8532\n",
      "Epoch 593/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0725 - accuracy: 0.9779 - val_loss: 0.5139 - val_accuracy: 0.8393\n",
      "Epoch 594/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0613 - accuracy: 0.9847 - val_loss: 0.4981 - val_accuracy: 0.8671\n",
      "Epoch 595/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0746 - accuracy: 0.9796 - val_loss: 0.5168 - val_accuracy: 0.8512\n",
      "Epoch 596/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0761 - accuracy: 0.9770 - val_loss: 0.4937 - val_accuracy: 0.8671\n",
      "Epoch 597/1000\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0688 - accuracy: 0.9821 - val_loss: 0.5518 - val_accuracy: 0.8472\n",
      "Epoch 598/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0701 - accuracy: 0.9830 - val_loss: 0.5185 - val_accuracy: 0.8591\n",
      "Epoch 599/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0667 - accuracy: 0.9838 - val_loss: 0.5150 - val_accuracy: 0.8730\n",
      "Epoch 600/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0731 - accuracy: 0.9813 - val_loss: 0.5567 - val_accuracy: 0.8611\n",
      "Epoch 601/1000\n",
      "74/74 [==============================] - 2s 24ms/step - loss: 0.0657 - accuracy: 0.9855 - val_loss: 0.5184 - val_accuracy: 0.8671\n",
      "Epoch 602/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0694 - accuracy: 0.9804 - val_loss: 0.5642 - val_accuracy: 0.8393\n",
      "Epoch 603/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0769 - accuracy: 0.9762 - val_loss: 0.5574 - val_accuracy: 0.8492\n",
      "Epoch 604/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0805 - accuracy: 0.9711 - val_loss: 0.4998 - val_accuracy: 0.8750\n",
      "Epoch 605/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0717 - accuracy: 0.9796 - val_loss: 0.5194 - val_accuracy: 0.8571\n",
      "Epoch 606/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0681 - accuracy: 0.9821 - val_loss: 0.5204 - val_accuracy: 0.8710\n",
      "Epoch 607/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0697 - accuracy: 0.9821 - val_loss: 0.5216 - val_accuracy: 0.8552\n",
      "Epoch 608/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0554 - accuracy: 0.9889 - val_loss: 0.4975 - val_accuracy: 0.8770\n",
      "Epoch 609/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0659 - accuracy: 0.9813 - val_loss: 0.5525 - val_accuracy: 0.8512\n",
      "Epoch 610/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0730 - accuracy: 0.9804 - val_loss: 0.5433 - val_accuracy: 0.8671\n",
      "Epoch 611/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0750 - accuracy: 0.9702 - val_loss: 0.5201 - val_accuracy: 0.8651\n",
      "Epoch 612/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0586 - accuracy: 0.9855 - val_loss: 0.5543 - val_accuracy: 0.8433\n",
      "Epoch 613/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0693 - accuracy: 0.9821 - val_loss: 0.5675 - val_accuracy: 0.8611\n",
      "Epoch 614/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0756 - accuracy: 0.9762 - val_loss: 0.5145 - val_accuracy: 0.8710\n",
      "Epoch 615/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0730 - accuracy: 0.9753 - val_loss: 0.5154 - val_accuracy: 0.8730\n",
      "Epoch 616/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0610 - accuracy: 0.9872 - val_loss: 0.5443 - val_accuracy: 0.8631\n",
      "Epoch 617/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0669 - accuracy: 0.9821 - val_loss: 0.5763 - val_accuracy: 0.8373\n",
      "Epoch 618/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0623 - accuracy: 0.9830 - val_loss: 0.5399 - val_accuracy: 0.8651\n",
      "Epoch 619/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0703 - accuracy: 0.9753 - val_loss: 0.5319 - val_accuracy: 0.8671\n",
      "Epoch 620/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0583 - accuracy: 0.9847 - val_loss: 0.5850 - val_accuracy: 0.8532\n",
      "Epoch 621/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0581 - accuracy: 0.9838 - val_loss: 0.5919 - val_accuracy: 0.8552\n",
      "Epoch 622/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0734 - accuracy: 0.9779 - val_loss: 0.5542 - val_accuracy: 0.8591\n",
      "Epoch 623/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0750 - accuracy: 0.9745 - val_loss: 0.5127 - val_accuracy: 0.8671\n",
      "Epoch 624/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0782 - accuracy: 0.9719 - val_loss: 0.5511 - val_accuracy: 0.8671\n",
      "Epoch 625/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0605 - accuracy: 0.9838 - val_loss: 0.5590 - val_accuracy: 0.8591\n",
      "Epoch 626/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0670 - accuracy: 0.9770 - val_loss: 0.6102 - val_accuracy: 0.8492\n",
      "Epoch 627/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0684 - accuracy: 0.9813 - val_loss: 0.5355 - val_accuracy: 0.8571\n",
      "Epoch 628/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0710 - accuracy: 0.9770 - val_loss: 0.5170 - val_accuracy: 0.8512\n",
      "Epoch 629/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0655 - accuracy: 0.9830 - val_loss: 0.5390 - val_accuracy: 0.8571\n",
      "Epoch 630/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0583 - accuracy: 0.9830 - val_loss: 0.6015 - val_accuracy: 0.8452\n",
      "Epoch 631/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0741 - accuracy: 0.9753 - val_loss: 0.5461 - val_accuracy: 0.8591\n",
      "Epoch 632/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0618 - accuracy: 0.9855 - val_loss: 0.5441 - val_accuracy: 0.8671\n",
      "Epoch 633/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0676 - accuracy: 0.9779 - val_loss: 0.5218 - val_accuracy: 0.8571\n",
      "Epoch 634/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0602 - accuracy: 0.9804 - val_loss: 0.5585 - val_accuracy: 0.8552\n",
      "Epoch 635/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0574 - accuracy: 0.9847 - val_loss: 0.5710 - val_accuracy: 0.8591\n",
      "Epoch 636/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0666 - accuracy: 0.9736 - val_loss: 0.5718 - val_accuracy: 0.8492\n",
      "Epoch 637/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0563 - accuracy: 0.9855 - val_loss: 0.5393 - val_accuracy: 0.8631\n",
      "Epoch 638/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0626 - accuracy: 0.9804 - val_loss: 0.6119 - val_accuracy: 0.8313\n",
      "Epoch 639/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0590 - accuracy: 0.9838 - val_loss: 0.5379 - val_accuracy: 0.8492\n",
      "Epoch 640/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0714 - accuracy: 0.9787 - val_loss: 0.5242 - val_accuracy: 0.8651\n",
      "Epoch 641/1000\n",
      "74/74 [==============================] - 2s 23ms/step - loss: 0.0807 - accuracy: 0.9745 - val_loss: 0.5579 - val_accuracy: 0.8393\n",
      "Epoch 642/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0586 - accuracy: 0.9821 - val_loss: 0.5507 - val_accuracy: 0.8571\n",
      "Epoch 643/1000\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 0.0602 - accuracy: 0.9813 - val_loss: 0.5707 - val_accuracy: 0.8671\n",
      "Epoch 644/1000\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 0.0626 - accuracy: 0.9830 - val_loss: 0.5849 - val_accuracy: 0.8413\n",
      "Epoch 645/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0615 - accuracy: 0.9821 - val_loss: 0.5142 - val_accuracy: 0.8611\n",
      "Epoch 646/1000\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0634 - accuracy: 0.9787 - val_loss: 0.4950 - val_accuracy: 0.8730\n",
      "Epoch 647/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0676 - accuracy: 0.9787 - val_loss: 0.5246 - val_accuracy: 0.8631\n",
      "Epoch 648/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0551 - accuracy: 0.9881 - val_loss: 0.5246 - val_accuracy: 0.8631\n",
      "Epoch 649/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0595 - accuracy: 0.9830 - val_loss: 0.5137 - val_accuracy: 0.8690\n",
      "Epoch 650/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0601 - accuracy: 0.9796 - val_loss: 0.5267 - val_accuracy: 0.8671\n",
      "Epoch 651/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0622 - accuracy: 0.9796 - val_loss: 0.6154 - val_accuracy: 0.8472\n",
      "Epoch 652/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0741 - accuracy: 0.9762 - val_loss: 0.5140 - val_accuracy: 0.8651\n",
      "Epoch 653/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0599 - accuracy: 0.9796 - val_loss: 0.5750 - val_accuracy: 0.8611\n",
      "Epoch 654/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0549 - accuracy: 0.9872 - val_loss: 0.5042 - val_accuracy: 0.8671\n",
      "Epoch 655/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0610 - accuracy: 0.9830 - val_loss: 0.5437 - val_accuracy: 0.8611\n",
      "Epoch 656/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0531 - accuracy: 0.9864 - val_loss: 0.6311 - val_accuracy: 0.8452\n",
      "Epoch 657/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0597 - accuracy: 0.9847 - val_loss: 0.5634 - val_accuracy: 0.8611\n",
      "Epoch 658/1000\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 0.0587 - accuracy: 0.9804 - val_loss: 0.5517 - val_accuracy: 0.8552\n",
      "Epoch 659/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0633 - accuracy: 0.9787 - val_loss: 0.5228 - val_accuracy: 0.8770\n",
      "Epoch 660/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0496 - accuracy: 0.9881 - val_loss: 0.5290 - val_accuracy: 0.8532\n",
      "Epoch 661/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0557 - accuracy: 0.9821 - val_loss: 0.5803 - val_accuracy: 0.8651\n",
      "Epoch 662/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0625 - accuracy: 0.9830 - val_loss: 0.5178 - val_accuracy: 0.8690\n",
      "Epoch 663/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0609 - accuracy: 0.9830 - val_loss: 0.5479 - val_accuracy: 0.8690\n",
      "Epoch 664/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0554 - accuracy: 0.9864 - val_loss: 0.5695 - val_accuracy: 0.8472\n",
      "Epoch 665/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0575 - accuracy: 0.9821 - val_loss: 0.5355 - val_accuracy: 0.8611\n",
      "Epoch 666/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0660 - accuracy: 0.9796 - val_loss: 0.5183 - val_accuracy: 0.8492\n",
      "Epoch 667/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0585 - accuracy: 0.9864 - val_loss: 0.5714 - val_accuracy: 0.8690\n",
      "Epoch 668/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0512 - accuracy: 0.9889 - val_loss: 0.5695 - val_accuracy: 0.8552\n",
      "Epoch 669/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0695 - accuracy: 0.9779 - val_loss: 0.5288 - val_accuracy: 0.8730\n",
      "Epoch 670/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0618 - accuracy: 0.9847 - val_loss: 0.5231 - val_accuracy: 0.8651\n",
      "Epoch 671/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0582 - accuracy: 0.9847 - val_loss: 0.5573 - val_accuracy: 0.8532\n",
      "Epoch 672/1000\n",
      "74/74 [==============================] - 2s 23ms/step - loss: 0.0655 - accuracy: 0.9787 - val_loss: 0.5354 - val_accuracy: 0.8631\n",
      "Epoch 673/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0558 - accuracy: 0.9821 - val_loss: 0.5487 - val_accuracy: 0.8611\n",
      "Epoch 674/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0559 - accuracy: 0.9864 - val_loss: 0.5853 - val_accuracy: 0.8591\n",
      "Epoch 675/1000\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 0.0558 - accuracy: 0.9838 - val_loss: 0.5728 - val_accuracy: 0.8730\n",
      "Epoch 676/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0553 - accuracy: 0.9855 - val_loss: 0.5490 - val_accuracy: 0.8690\n",
      "Epoch 677/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0588 - accuracy: 0.9830 - val_loss: 0.5332 - val_accuracy: 0.8790\n",
      "Epoch 678/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0571 - accuracy: 0.9855 - val_loss: 0.5377 - val_accuracy: 0.8492\n",
      "Epoch 679/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0555 - accuracy: 0.9855 - val_loss: 0.5636 - val_accuracy: 0.8591\n",
      "Epoch 680/1000\n",
      "74/74 [==============================] - 2s 23ms/step - loss: 0.0582 - accuracy: 0.9804 - val_loss: 0.6246 - val_accuracy: 0.8472\n",
      "Epoch 681/1000\n",
      "74/74 [==============================] - 2s 24ms/step - loss: 0.0554 - accuracy: 0.9855 - val_loss: 0.5639 - val_accuracy: 0.8591\n",
      "Epoch 682/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0606 - accuracy: 0.9838 - val_loss: 0.5677 - val_accuracy: 0.8651\n",
      "Epoch 683/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0459 - accuracy: 0.9872 - val_loss: 0.5497 - val_accuracy: 0.8770\n",
      "Epoch 684/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0521 - accuracy: 0.9847 - val_loss: 0.5387 - val_accuracy: 0.8671\n",
      "Epoch 685/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0519 - accuracy: 0.9855 - val_loss: 0.5714 - val_accuracy: 0.8730\n",
      "Epoch 686/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0566 - accuracy: 0.9804 - val_loss: 0.5531 - val_accuracy: 0.8730\n",
      "Epoch 687/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0562 - accuracy: 0.9847 - val_loss: 0.5181 - val_accuracy: 0.8671\n",
      "Epoch 688/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0531 - accuracy: 0.9872 - val_loss: 0.5425 - val_accuracy: 0.8810\n",
      "Epoch 689/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0513 - accuracy: 0.9864 - val_loss: 0.5010 - val_accuracy: 0.8909\n",
      "Epoch 690/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0480 - accuracy: 0.9881 - val_loss: 0.6052 - val_accuracy: 0.8532\n",
      "Epoch 691/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0680 - accuracy: 0.9787 - val_loss: 0.5547 - val_accuracy: 0.8750\n",
      "Epoch 692/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0533 - accuracy: 0.9881 - val_loss: 0.5622 - val_accuracy: 0.8770\n",
      "Epoch 693/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0578 - accuracy: 0.9847 - val_loss: 0.5520 - val_accuracy: 0.8611\n",
      "Epoch 694/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0480 - accuracy: 0.9889 - val_loss: 0.5835 - val_accuracy: 0.8552\n",
      "Epoch 695/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0511 - accuracy: 0.9847 - val_loss: 0.5364 - val_accuracy: 0.8750\n",
      "Epoch 696/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0551 - accuracy: 0.9838 - val_loss: 0.6329 - val_accuracy: 0.8532\n",
      "Epoch 697/1000\n",
      "74/74 [==============================] - 2s 23ms/step - loss: 0.0585 - accuracy: 0.9830 - val_loss: 0.6399 - val_accuracy: 0.8571\n",
      "Epoch 698/1000\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 0.0457 - accuracy: 0.9906 - val_loss: 0.5423 - val_accuracy: 0.8671\n",
      "Epoch 699/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0506 - accuracy: 0.9830 - val_loss: 0.5777 - val_accuracy: 0.8690\n",
      "Epoch 700/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0582 - accuracy: 0.9804 - val_loss: 0.5571 - val_accuracy: 0.8710\n",
      "Epoch 701/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0568 - accuracy: 0.9855 - val_loss: 0.5368 - val_accuracy: 0.8512\n",
      "Epoch 702/1000\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 0.0486 - accuracy: 0.9881 - val_loss: 0.5206 - val_accuracy: 0.8710\n",
      "Epoch 703/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0515 - accuracy: 0.9864 - val_loss: 0.6015 - val_accuracy: 0.8472\n",
      "Epoch 704/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0486 - accuracy: 0.9864 - val_loss: 0.5778 - val_accuracy: 0.8690\n",
      "Epoch 705/1000\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 0.0499 - accuracy: 0.9864 - val_loss: 0.6735 - val_accuracy: 0.8452\n",
      "Epoch 706/1000\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 0.0461 - accuracy: 0.9864 - val_loss: 0.5219 - val_accuracy: 0.8829\n",
      "Epoch 707/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0423 - accuracy: 0.9898 - val_loss: 0.5503 - val_accuracy: 0.8651\n",
      "Epoch 708/1000\n",
      "74/74 [==============================] - 2s 24ms/step - loss: 0.0455 - accuracy: 0.9881 - val_loss: 0.5913 - val_accuracy: 0.8671\n",
      "Epoch 709/1000\n",
      "74/74 [==============================] - 2s 23ms/step - loss: 0.0515 - accuracy: 0.9872 - val_loss: 0.5339 - val_accuracy: 0.8810\n",
      "Epoch 710/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0549 - accuracy: 0.9847 - val_loss: 0.5415 - val_accuracy: 0.8710\n",
      "Epoch 711/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0498 - accuracy: 0.9838 - val_loss: 0.5413 - val_accuracy: 0.8730\n",
      "Epoch 712/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0537 - accuracy: 0.9821 - val_loss: 0.5312 - val_accuracy: 0.8730\n",
      "Epoch 713/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0578 - accuracy: 0.9838 - val_loss: 0.5800 - val_accuracy: 0.8611\n",
      "Epoch 714/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0526 - accuracy: 0.9881 - val_loss: 0.5725 - val_accuracy: 0.8552\n",
      "Epoch 715/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0468 - accuracy: 0.9855 - val_loss: 0.5919 - val_accuracy: 0.8452\n",
      "Epoch 716/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0516 - accuracy: 0.9847 - val_loss: 0.6206 - val_accuracy: 0.8532\n",
      "Epoch 717/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0490 - accuracy: 0.9872 - val_loss: 0.5496 - val_accuracy: 0.8690\n",
      "Epoch 718/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0508 - accuracy: 0.9855 - val_loss: 0.6370 - val_accuracy: 0.8472\n",
      "Epoch 719/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0494 - accuracy: 0.9855 - val_loss: 0.6255 - val_accuracy: 0.8413\n",
      "Epoch 720/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0499 - accuracy: 0.9847 - val_loss: 0.5447 - val_accuracy: 0.8631\n",
      "Epoch 721/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0525 - accuracy: 0.9821 - val_loss: 0.5806 - val_accuracy: 0.8631\n",
      "Epoch 722/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0482 - accuracy: 0.9881 - val_loss: 0.5500 - val_accuracy: 0.8631\n",
      "Epoch 723/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0436 - accuracy: 0.9889 - val_loss: 0.6097 - val_accuracy: 0.8651\n",
      "Epoch 724/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0476 - accuracy: 0.9864 - val_loss: 0.5618 - val_accuracy: 0.8651\n",
      "Epoch 725/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0455 - accuracy: 0.9864 - val_loss: 0.5515 - val_accuracy: 0.8690\n",
      "Epoch 726/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0515 - accuracy: 0.9855 - val_loss: 0.5566 - val_accuracy: 0.8552\n",
      "Epoch 727/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0500 - accuracy: 0.9864 - val_loss: 0.6003 - val_accuracy: 0.8571\n",
      "Epoch 728/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0456 - accuracy: 0.9864 - val_loss: 0.5518 - val_accuracy: 0.8472\n",
      "Epoch 729/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0506 - accuracy: 0.9838 - val_loss: 0.5107 - val_accuracy: 0.8790\n",
      "Epoch 730/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0479 - accuracy: 0.9847 - val_loss: 0.5481 - val_accuracy: 0.8690\n",
      "Epoch 731/1000\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 0.0495 - accuracy: 0.9830 - val_loss: 0.5742 - val_accuracy: 0.8512\n",
      "Epoch 732/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0482 - accuracy: 0.9889 - val_loss: 0.5959 - val_accuracy: 0.8591\n",
      "Epoch 733/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0450 - accuracy: 0.9889 - val_loss: 0.5471 - val_accuracy: 0.8671\n",
      "Epoch 734/1000\n",
      "74/74 [==============================] - 2s 23ms/step - loss: 0.0417 - accuracy: 0.9881 - val_loss: 0.5725 - val_accuracy: 0.8770\n",
      "Epoch 735/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0390 - accuracy: 0.9915 - val_loss: 0.5497 - val_accuracy: 0.8552\n",
      "Epoch 736/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0473 - accuracy: 0.9847 - val_loss: 0.6903 - val_accuracy: 0.8393\n",
      "Epoch 737/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0538 - accuracy: 0.9838 - val_loss: 0.6319 - val_accuracy: 0.8591\n",
      "Epoch 738/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0430 - accuracy: 0.9898 - val_loss: 0.5572 - val_accuracy: 0.8750\n",
      "Epoch 739/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0415 - accuracy: 0.9881 - val_loss: 0.5849 - val_accuracy: 0.8571\n",
      "Epoch 740/1000\n",
      "74/74 [==============================] - 2s 25ms/step - loss: 0.0487 - accuracy: 0.9881 - val_loss: 0.6129 - val_accuracy: 0.8591\n",
      "Epoch 741/1000\n",
      "74/74 [==============================] - 2s 24ms/step - loss: 0.0433 - accuracy: 0.9906 - val_loss: 0.6092 - val_accuracy: 0.8333\n",
      "Epoch 742/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0448 - accuracy: 0.9864 - val_loss: 0.5510 - val_accuracy: 0.8730\n",
      "Epoch 743/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0511 - accuracy: 0.9855 - val_loss: 0.5388 - val_accuracy: 0.8571\n",
      "Epoch 744/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0406 - accuracy: 0.9881 - val_loss: 0.6084 - val_accuracy: 0.8571\n",
      "Epoch 745/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0467 - accuracy: 0.9906 - val_loss: 0.6107 - val_accuracy: 0.8611\n",
      "Epoch 746/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0501 - accuracy: 0.9813 - val_loss: 0.5809 - val_accuracy: 0.8472\n",
      "Epoch 747/1000\n",
      "74/74 [==============================] - 2s 25ms/step - loss: 0.0426 - accuracy: 0.9864 - val_loss: 0.5201 - val_accuracy: 0.8810\n",
      "Epoch 748/1000\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0474 - accuracy: 0.9864 - val_loss: 0.5554 - val_accuracy: 0.8869\n",
      "Epoch 749/1000\n",
      "74/74 [==============================] - 3s 42ms/step - loss: 0.0448 - accuracy: 0.9872 - val_loss: 0.5582 - val_accuracy: 0.8690\n",
      "Epoch 750/1000\n",
      "74/74 [==============================] - 5s 63ms/step - loss: 0.0472 - accuracy: 0.9855 - val_loss: 0.5684 - val_accuracy: 0.8750\n",
      "Epoch 751/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0432 - accuracy: 0.9864 - val_loss: 0.5931 - val_accuracy: 0.8591\n",
      "Epoch 752/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0472 - accuracy: 0.9864 - val_loss: 0.5445 - val_accuracy: 0.8631\n",
      "Epoch 753/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0392 - accuracy: 0.9881 - val_loss: 0.5925 - val_accuracy: 0.8631\n",
      "Epoch 754/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0437 - accuracy: 0.9864 - val_loss: 0.6113 - val_accuracy: 0.8671\n",
      "Epoch 755/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0416 - accuracy: 0.9855 - val_loss: 0.6102 - val_accuracy: 0.8651\n",
      "Epoch 756/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0463 - accuracy: 0.9838 - val_loss: 0.6050 - val_accuracy: 0.8631\n",
      "Epoch 757/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0405 - accuracy: 0.9881 - val_loss: 0.5795 - val_accuracy: 0.8611\n",
      "Epoch 758/1000\n",
      "74/74 [==============================] - 2s 24ms/step - loss: 0.0384 - accuracy: 0.9923 - val_loss: 0.5933 - val_accuracy: 0.8591\n",
      "Epoch 759/1000\n",
      "74/74 [==============================] - 2s 25ms/step - loss: 0.0422 - accuracy: 0.9881 - val_loss: 0.5586 - val_accuracy: 0.8591\n",
      "Epoch 760/1000\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0435 - accuracy: 0.9855 - val_loss: 0.5586 - val_accuracy: 0.8690\n",
      "Epoch 761/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0425 - accuracy: 0.9898 - val_loss: 0.5629 - val_accuracy: 0.8611\n",
      "Epoch 762/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0398 - accuracy: 0.9872 - val_loss: 0.5499 - val_accuracy: 0.8611\n",
      "Epoch 763/1000\n",
      "74/74 [==============================] - 2s 26ms/step - loss: 0.0439 - accuracy: 0.9898 - val_loss: 0.5741 - val_accuracy: 0.8671\n",
      "Epoch 764/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0470 - accuracy: 0.9855 - val_loss: 0.6034 - val_accuracy: 0.8512\n",
      "Epoch 765/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0487 - accuracy: 0.9838 - val_loss: 0.6122 - val_accuracy: 0.8532\n",
      "Epoch 766/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0392 - accuracy: 0.9906 - val_loss: 0.5818 - val_accuracy: 0.8770\n",
      "Epoch 767/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0403 - accuracy: 0.9915 - val_loss: 0.5749 - val_accuracy: 0.8730\n",
      "Epoch 768/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0371 - accuracy: 0.9898 - val_loss: 0.5785 - val_accuracy: 0.8651\n",
      "Epoch 769/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0421 - accuracy: 0.9864 - val_loss: 0.5605 - val_accuracy: 0.8770\n",
      "Epoch 770/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0386 - accuracy: 0.9906 - val_loss: 0.5958 - val_accuracy: 0.8552\n",
      "Epoch 771/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0391 - accuracy: 0.9923 - val_loss: 0.5685 - val_accuracy: 0.8730\n",
      "Epoch 772/1000\n",
      "74/74 [==============================] - 2s 26ms/step - loss: 0.0391 - accuracy: 0.9923 - val_loss: 0.6283 - val_accuracy: 0.8611\n",
      "Epoch 773/1000\n",
      "74/74 [==============================] - 2s 29ms/step - loss: 0.0386 - accuracy: 0.9855 - val_loss: 0.6137 - val_accuracy: 0.8433\n",
      "Epoch 774/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0483 - accuracy: 0.9872 - val_loss: 0.5637 - val_accuracy: 0.8690\n",
      "Epoch 775/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0397 - accuracy: 0.9872 - val_loss: 0.5827 - val_accuracy: 0.8651\n",
      "Epoch 776/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0475 - accuracy: 0.9889 - val_loss: 0.5872 - val_accuracy: 0.8571\n",
      "Epoch 777/1000\n",
      "74/74 [==============================] - 2s 24ms/step - loss: 0.0369 - accuracy: 0.9923 - val_loss: 0.6405 - val_accuracy: 0.8413\n",
      "Epoch 778/1000\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0315 - accuracy: 0.9932 - val_loss: 0.6881 - val_accuracy: 0.8294\n",
      "Epoch 779/1000\n",
      "74/74 [==============================] - 2s 23ms/step - loss: 0.0418 - accuracy: 0.9889 - val_loss: 0.6365 - val_accuracy: 0.8532\n",
      "Epoch 780/1000\n",
      "74/74 [==============================] - 3s 34ms/step - loss: 0.0395 - accuracy: 0.9889 - val_loss: 0.6005 - val_accuracy: 0.8631\n",
      "Epoch 781/1000\n",
      "74/74 [==============================] - 3s 37ms/step - loss: 0.0358 - accuracy: 0.9932 - val_loss: 0.5524 - val_accuracy: 0.8750\n",
      "Epoch 782/1000\n",
      "74/74 [==============================] - 3s 45ms/step - loss: 0.0402 - accuracy: 0.9923 - val_loss: 0.5669 - val_accuracy: 0.8790\n",
      "Epoch 783/1000\n",
      "74/74 [==============================] - 2s 26ms/step - loss: 0.0372 - accuracy: 0.9898 - val_loss: 0.5655 - val_accuracy: 0.8770\n",
      "Epoch 784/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0469 - accuracy: 0.9855 - val_loss: 0.5645 - val_accuracy: 0.8690\n",
      "Epoch 785/1000\n",
      "74/74 [==============================] - 2s 26ms/step - loss: 0.0363 - accuracy: 0.9940 - val_loss: 0.6246 - val_accuracy: 0.8512\n",
      "Epoch 786/1000\n",
      "74/74 [==============================] - 2s 28ms/step - loss: 0.0432 - accuracy: 0.9881 - val_loss: 0.5939 - val_accuracy: 0.8690\n",
      "Epoch 787/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0353 - accuracy: 0.9898 - val_loss: 0.6335 - val_accuracy: 0.8671\n",
      "Epoch 788/1000\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0283 - accuracy: 0.9957 - val_loss: 0.5935 - val_accuracy: 0.8611\n",
      "Epoch 789/1000\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0325 - accuracy: 0.9932 - val_loss: 0.5767 - val_accuracy: 0.8750\n",
      "Epoch 790/1000\n",
      "74/74 [==============================] - 3s 35ms/step - loss: 0.0343 - accuracy: 0.9915 - val_loss: 0.5642 - val_accuracy: 0.8611\n",
      "Epoch 791/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0313 - accuracy: 0.9906 - val_loss: 0.5829 - val_accuracy: 0.8571\n",
      "Epoch 792/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0405 - accuracy: 0.9889 - val_loss: 0.6083 - val_accuracy: 0.8690\n",
      "Epoch 793/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0342 - accuracy: 0.9932 - val_loss: 0.6508 - val_accuracy: 0.8492\n",
      "Epoch 794/1000\n",
      "74/74 [==============================] - 2s 27ms/step - loss: 0.0421 - accuracy: 0.9889 - val_loss: 0.5637 - val_accuracy: 0.8710\n",
      "Epoch 795/1000\n",
      "74/74 [==============================] - 2s 24ms/step - loss: 0.0283 - accuracy: 0.9940 - val_loss: 0.6270 - val_accuracy: 0.8492\n",
      "Epoch 796/1000\n",
      "74/74 [==============================] - 2s 24ms/step - loss: 0.0427 - accuracy: 0.9915 - val_loss: 0.5798 - val_accuracy: 0.8611\n",
      "Epoch 797/1000\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0450 - accuracy: 0.9855 - val_loss: 0.5881 - val_accuracy: 0.8651\n",
      "Epoch 798/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0421 - accuracy: 0.9932 - val_loss: 0.5669 - val_accuracy: 0.8671\n",
      "Epoch 799/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0382 - accuracy: 0.9923 - val_loss: 0.6183 - val_accuracy: 0.8591\n",
      "Epoch 800/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0281 - accuracy: 0.9957 - val_loss: 0.6026 - val_accuracy: 0.8571\n",
      "Epoch 801/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0296 - accuracy: 0.9949 - val_loss: 0.6301 - val_accuracy: 0.8552\n",
      "Epoch 802/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0368 - accuracy: 0.9923 - val_loss: 0.6014 - val_accuracy: 0.8631\n",
      "Epoch 803/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0392 - accuracy: 0.9872 - val_loss: 0.5804 - val_accuracy: 0.8651\n",
      "Epoch 804/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0258 - accuracy: 0.9974 - val_loss: 0.5790 - val_accuracy: 0.8730\n",
      "Epoch 805/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0360 - accuracy: 0.9881 - val_loss: 0.5962 - val_accuracy: 0.8552\n",
      "Epoch 806/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0376 - accuracy: 0.9906 - val_loss: 0.5925 - val_accuracy: 0.8770\n",
      "Epoch 807/1000\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 0.0359 - accuracy: 0.9915 - val_loss: 0.6149 - val_accuracy: 0.8591\n",
      "Epoch 808/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0369 - accuracy: 0.9898 - val_loss: 0.5364 - val_accuracy: 0.8889\n",
      "Epoch 809/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0304 - accuracy: 0.9949 - val_loss: 0.6255 - val_accuracy: 0.8492\n",
      "Epoch 810/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0330 - accuracy: 0.9915 - val_loss: 0.5910 - val_accuracy: 0.8651\n",
      "Epoch 811/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0371 - accuracy: 0.9906 - val_loss: 0.6344 - val_accuracy: 0.8571\n",
      "Epoch 812/1000\n",
      "74/74 [==============================] - 2s 24ms/step - loss: 0.0284 - accuracy: 0.9957 - val_loss: 0.5964 - val_accuracy: 0.8750\n",
      "Epoch 813/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0438 - accuracy: 0.9864 - val_loss: 0.5750 - val_accuracy: 0.8710\n",
      "Epoch 814/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0340 - accuracy: 0.9889 - val_loss: 0.5663 - val_accuracy: 0.8810\n",
      "Epoch 815/1000\n",
      "74/74 [==============================] - 2s 26ms/step - loss: 0.0325 - accuracy: 0.9915 - val_loss: 0.5631 - val_accuracy: 0.8849\n",
      "Epoch 816/1000\n",
      "74/74 [==============================] - 2s 25ms/step - loss: 0.0433 - accuracy: 0.9864 - val_loss: 0.5780 - val_accuracy: 0.8710\n",
      "Epoch 817/1000\n",
      "74/74 [==============================] - 3s 37ms/step - loss: 0.0383 - accuracy: 0.9898 - val_loss: 0.5603 - val_accuracy: 0.8750\n",
      "Epoch 818/1000\n",
      "74/74 [==============================] - 3s 38ms/step - loss: 0.0277 - accuracy: 0.9940 - val_loss: 0.5897 - val_accuracy: 0.8611\n",
      "Epoch 819/1000\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0332 - accuracy: 0.9915 - val_loss: 0.6022 - val_accuracy: 0.8690\n",
      "Epoch 820/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0313 - accuracy: 0.9915 - val_loss: 0.6310 - val_accuracy: 0.8532\n",
      "Epoch 821/1000\n",
      "74/74 [==============================] - 3s 43ms/step - loss: 0.0335 - accuracy: 0.9915 - val_loss: 0.6306 - val_accuracy: 0.8552\n",
      "Epoch 822/1000\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0406 - accuracy: 0.9872 - val_loss: 0.5838 - val_accuracy: 0.8730\n",
      "Epoch 823/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0344 - accuracy: 0.9923 - val_loss: 0.6036 - val_accuracy: 0.8671\n",
      "Epoch 824/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0359 - accuracy: 0.9889 - val_loss: 0.6162 - val_accuracy: 0.8532\n",
      "Epoch 825/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0313 - accuracy: 0.9906 - val_loss: 0.6056 - val_accuracy: 0.8750\n",
      "Epoch 826/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0334 - accuracy: 0.9906 - val_loss: 0.5834 - val_accuracy: 0.8591\n",
      "Epoch 827/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0372 - accuracy: 0.9872 - val_loss: 0.6341 - val_accuracy: 0.8671\n",
      "Epoch 828/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0344 - accuracy: 0.9915 - val_loss: 0.5844 - val_accuracy: 0.8790\n",
      "Epoch 829/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0306 - accuracy: 0.9906 - val_loss: 0.6220 - val_accuracy: 0.8591\n",
      "Epoch 830/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0342 - accuracy: 0.9915 - val_loss: 0.5954 - val_accuracy: 0.8829\n",
      "Epoch 831/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0386 - accuracy: 0.9889 - val_loss: 0.6531 - val_accuracy: 0.8571\n",
      "Epoch 832/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0293 - accuracy: 0.9932 - val_loss: 0.6328 - val_accuracy: 0.8631\n",
      "Epoch 833/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0405 - accuracy: 0.9881 - val_loss: 0.5849 - val_accuracy: 0.8690\n",
      "Epoch 834/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0343 - accuracy: 0.9915 - val_loss: 0.5892 - val_accuracy: 0.8710\n",
      "Epoch 835/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0366 - accuracy: 0.9864 - val_loss: 0.6290 - val_accuracy: 0.8472\n",
      "Epoch 836/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0250 - accuracy: 0.9940 - val_loss: 0.6448 - val_accuracy: 0.8492\n",
      "Epoch 837/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0317 - accuracy: 0.9932 - val_loss: 0.6371 - val_accuracy: 0.8591\n",
      "Epoch 838/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0379 - accuracy: 0.9872 - val_loss: 0.5820 - val_accuracy: 0.8829\n",
      "Epoch 839/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0256 - accuracy: 0.9974 - val_loss: 0.6407 - val_accuracy: 0.8512\n",
      "Epoch 840/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0345 - accuracy: 0.9915 - val_loss: 0.6331 - val_accuracy: 0.8591\n",
      "Epoch 841/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0417 - accuracy: 0.9847 - val_loss: 0.6134 - val_accuracy: 0.8710\n",
      "Epoch 842/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0333 - accuracy: 0.9915 - val_loss: 0.6749 - val_accuracy: 0.8472\n",
      "Epoch 843/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0349 - accuracy: 0.9889 - val_loss: 0.6354 - val_accuracy: 0.8571\n",
      "Epoch 844/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0349 - accuracy: 0.9881 - val_loss: 0.5906 - val_accuracy: 0.8750\n",
      "Epoch 845/1000\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0297 - accuracy: 0.9915 - val_loss: 0.6066 - val_accuracy: 0.8750\n",
      "Epoch 846/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0344 - accuracy: 0.9932 - val_loss: 0.6520 - val_accuracy: 0.8571\n",
      "Epoch 847/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0324 - accuracy: 0.9932 - val_loss: 0.6677 - val_accuracy: 0.8492\n",
      "Epoch 848/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0326 - accuracy: 0.9889 - val_loss: 0.6236 - val_accuracy: 0.8651\n",
      "Epoch 849/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0267 - accuracy: 0.9957 - val_loss: 0.6383 - val_accuracy: 0.8690\n",
      "Epoch 850/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0297 - accuracy: 0.9915 - val_loss: 0.6177 - val_accuracy: 0.8671\n",
      "Epoch 851/1000\n",
      "74/74 [==============================] - 3s 38ms/step - loss: 0.0262 - accuracy: 0.9923 - val_loss: 0.6113 - val_accuracy: 0.8810\n",
      "Epoch 852/1000\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 0.0330 - accuracy: 0.9898 - val_loss: 0.6657 - val_accuracy: 0.8651\n",
      "Epoch 853/1000\n",
      "74/74 [==============================] - 2s 32ms/step - loss: 0.0285 - accuracy: 0.9940 - val_loss: 0.6550 - val_accuracy: 0.8611\n",
      "Epoch 854/1000\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0373 - accuracy: 0.9889 - val_loss: 0.6544 - val_accuracy: 0.8631\n",
      "Epoch 855/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0324 - accuracy: 0.9923 - val_loss: 0.5947 - val_accuracy: 0.8651\n",
      "Epoch 856/1000\n",
      "74/74 [==============================] - 2s 34ms/step - loss: 0.0330 - accuracy: 0.9915 - val_loss: 0.6949 - val_accuracy: 0.8452\n",
      "Epoch 857/1000\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0305 - accuracy: 0.9889 - val_loss: 0.6340 - val_accuracy: 0.8710\n",
      "Epoch 858/1000\n",
      "74/74 [==============================] - 2s 28ms/step - loss: 0.0261 - accuracy: 0.9940 - val_loss: 0.6325 - val_accuracy: 0.8651\n",
      "Epoch 859/1000\n",
      "74/74 [==============================] - 2s 34ms/step - loss: 0.0352 - accuracy: 0.9932 - val_loss: 0.7131 - val_accuracy: 0.8631\n",
      "Epoch 860/1000\n",
      "74/74 [==============================] - 2s 27ms/step - loss: 0.0328 - accuracy: 0.9932 - val_loss: 0.6037 - val_accuracy: 0.8611\n",
      "Epoch 861/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0251 - accuracy: 0.9940 - val_loss: 0.6044 - val_accuracy: 0.8651\n",
      "Epoch 862/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0291 - accuracy: 0.9923 - val_loss: 0.5969 - val_accuracy: 0.8690\n",
      "Epoch 863/1000\n",
      "74/74 [==============================] - 2s 23ms/step - loss: 0.0295 - accuracy: 0.9949 - val_loss: 0.5960 - val_accuracy: 0.8690\n",
      "Epoch 864/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0370 - accuracy: 0.9889 - val_loss: 0.6257 - val_accuracy: 0.8512\n",
      "Epoch 865/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 0.6124 - val_accuracy: 0.8611\n",
      "Epoch 866/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0285 - accuracy: 0.9923 - val_loss: 0.7273 - val_accuracy: 0.8512\n",
      "Epoch 867/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0274 - accuracy: 0.9932 - val_loss: 0.6318 - val_accuracy: 0.8750\n",
      "Epoch 868/1000\n",
      "74/74 [==============================] - 2s 27ms/step - loss: 0.0235 - accuracy: 0.9957 - val_loss: 0.6562 - val_accuracy: 0.8591\n",
      "Epoch 869/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0333 - accuracy: 0.9889 - val_loss: 0.6898 - val_accuracy: 0.8611\n",
      "Epoch 870/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0276 - accuracy: 0.9940 - val_loss: 0.6690 - val_accuracy: 0.8571\n",
      "Epoch 871/1000\n",
      "74/74 [==============================] - 2s 25ms/step - loss: 0.0351 - accuracy: 0.9889 - val_loss: 0.6621 - val_accuracy: 0.8611\n",
      "Epoch 872/1000\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0345 - accuracy: 0.9898 - val_loss: 0.6317 - val_accuracy: 0.8730\n",
      "Epoch 873/1000\n",
      "74/74 [==============================] - 1s 12ms/step - loss: 0.0308 - accuracy: 0.9940 - val_loss: 0.6490 - val_accuracy: 0.8611\n",
      "Epoch 874/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0303 - accuracy: 0.9889 - val_loss: 0.7282 - val_accuracy: 0.8532\n",
      "Epoch 875/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0243 - accuracy: 0.9940 - val_loss: 0.6144 - val_accuracy: 0.8651\n",
      "Epoch 876/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0270 - accuracy: 0.9957 - val_loss: 0.6105 - val_accuracy: 0.8651\n",
      "Epoch 877/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0247 - accuracy: 0.9940 - val_loss: 0.6105 - val_accuracy: 0.8690\n",
      "Epoch 878/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0325 - accuracy: 0.9889 - val_loss: 0.6191 - val_accuracy: 0.8571\n",
      "Epoch 879/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0341 - accuracy: 0.9898 - val_loss: 0.6752 - val_accuracy: 0.8413\n",
      "Epoch 880/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0345 - accuracy: 0.9881 - val_loss: 0.6025 - val_accuracy: 0.8671\n",
      "Epoch 881/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0306 - accuracy: 0.9915 - val_loss: 0.6067 - val_accuracy: 0.8889\n",
      "Epoch 882/1000\n",
      "74/74 [==============================] - 2s 23ms/step - loss: 0.0303 - accuracy: 0.9940 - val_loss: 0.6205 - val_accuracy: 0.8631\n",
      "Epoch 883/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0356 - accuracy: 0.9898 - val_loss: 0.6817 - val_accuracy: 0.8532\n",
      "Epoch 884/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0276 - accuracy: 0.9957 - val_loss: 0.5973 - val_accuracy: 0.8810\n",
      "Epoch 885/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0385 - accuracy: 0.9872 - val_loss: 0.6264 - val_accuracy: 0.8472\n",
      "Epoch 886/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0280 - accuracy: 0.9923 - val_loss: 0.6293 - val_accuracy: 0.8690\n",
      "Epoch 887/1000\n",
      "74/74 [==============================] - 3s 36ms/step - loss: 0.0283 - accuracy: 0.9949 - val_loss: 0.5944 - val_accuracy: 0.8770\n",
      "Epoch 888/1000\n",
      "74/74 [==============================] - 2s 26ms/step - loss: 0.0215 - accuracy: 0.9983 - val_loss: 0.6279 - val_accuracy: 0.8571\n",
      "Epoch 889/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0245 - accuracy: 0.9949 - val_loss: 0.6192 - val_accuracy: 0.8710\n",
      "Epoch 890/1000\n",
      "74/74 [==============================] - 3s 38ms/step - loss: 0.0262 - accuracy: 0.9906 - val_loss: 0.6120 - val_accuracy: 0.8591\n",
      "Epoch 891/1000\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.6020 - val_accuracy: 0.8651\n",
      "Epoch 892/1000\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0252 - accuracy: 0.9940 - val_loss: 0.6259 - val_accuracy: 0.8651\n",
      "Epoch 893/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0294 - accuracy: 0.9915 - val_loss: 0.6200 - val_accuracy: 0.8631\n",
      "Epoch 894/1000\n",
      "74/74 [==============================] - 3s 37ms/step - loss: 0.0278 - accuracy: 0.9923 - val_loss: 0.5857 - val_accuracy: 0.8690\n",
      "Epoch 895/1000\n",
      "74/74 [==============================] - 3s 47ms/step - loss: 0.0236 - accuracy: 0.9949 - val_loss: 0.6006 - val_accuracy: 0.8770\n",
      "Epoch 896/1000\n",
      "74/74 [==============================] - 3s 38ms/step - loss: 0.0355 - accuracy: 0.9915 - val_loss: 0.6711 - val_accuracy: 0.8472\n",
      "Epoch 897/1000\n",
      "74/74 [==============================] - 2s 23ms/step - loss: 0.0281 - accuracy: 0.9923 - val_loss: 0.6570 - val_accuracy: 0.8611\n",
      "Epoch 898/1000\n",
      "74/74 [==============================] - 1s 13ms/step - loss: 0.0295 - accuracy: 0.9923 - val_loss: 0.6451 - val_accuracy: 0.8690\n",
      "Epoch 899/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0317 - accuracy: 0.9932 - val_loss: 0.6938 - val_accuracy: 0.8571\n",
      "Epoch 900/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0313 - accuracy: 0.9915 - val_loss: 0.6372 - val_accuracy: 0.8690\n",
      "Epoch 901/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0317 - accuracy: 0.9923 - val_loss: 0.6142 - val_accuracy: 0.8730\n",
      "Epoch 902/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0267 - accuracy: 0.9932 - val_loss: 0.6521 - val_accuracy: 0.8611\n",
      "Epoch 903/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0241 - accuracy: 0.9966 - val_loss: 0.6317 - val_accuracy: 0.8770\n",
      "Epoch 904/1000\n",
      "74/74 [==============================] - 2s 24ms/step - loss: 0.0272 - accuracy: 0.9923 - val_loss: 0.6364 - val_accuracy: 0.8532\n",
      "Epoch 905/1000\n",
      "74/74 [==============================] - 2s 24ms/step - loss: 0.0301 - accuracy: 0.9898 - val_loss: 0.6430 - val_accuracy: 0.8730\n",
      "Epoch 906/1000\n",
      "74/74 [==============================] - 3s 35ms/step - loss: 0.0270 - accuracy: 0.9923 - val_loss: 0.5944 - val_accuracy: 0.8790\n",
      "Epoch 907/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0300 - accuracy: 0.9915 - val_loss: 0.5891 - val_accuracy: 0.8730\n",
      "Epoch 908/1000\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 0.0438 - accuracy: 0.9864 - val_loss: 0.6501 - val_accuracy: 0.8611\n",
      "Epoch 909/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0216 - accuracy: 0.9949 - val_loss: 0.6430 - val_accuracy: 0.8671\n",
      "Epoch 910/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0315 - accuracy: 0.9898 - val_loss: 0.6311 - val_accuracy: 0.8849\n",
      "Epoch 911/1000\n",
      "74/74 [==============================] - 2s 23ms/step - loss: 0.0317 - accuracy: 0.9898 - val_loss: 0.6147 - val_accuracy: 0.8611\n",
      "Epoch 912/1000\n",
      "74/74 [==============================] - 3s 43ms/step - loss: 0.0350 - accuracy: 0.9881 - val_loss: 0.6271 - val_accuracy: 0.8552\n",
      "Epoch 913/1000\n",
      "74/74 [==============================] - 4s 50ms/step - loss: 0.0337 - accuracy: 0.9915 - val_loss: 0.6270 - val_accuracy: 0.8750\n",
      "Epoch 914/1000\n",
      "74/74 [==============================] - 3s 39ms/step - loss: 0.0243 - accuracy: 0.9932 - val_loss: 0.6179 - val_accuracy: 0.8790\n",
      "Epoch 915/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0236 - accuracy: 0.9932 - val_loss: 0.6348 - val_accuracy: 0.8552\n",
      "Epoch 916/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0251 - accuracy: 0.9898 - val_loss: 0.7130 - val_accuracy: 0.8492\n",
      "Epoch 917/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0315 - accuracy: 0.9923 - val_loss: 0.6570 - val_accuracy: 0.8611\n",
      "Epoch 918/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0288 - accuracy: 0.9940 - val_loss: 0.6430 - val_accuracy: 0.8810\n",
      "Epoch 919/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0240 - accuracy: 0.9940 - val_loss: 0.6208 - val_accuracy: 0.8849\n",
      "Epoch 920/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0252 - accuracy: 0.9915 - val_loss: 0.6539 - val_accuracy: 0.8631\n",
      "Epoch 921/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0358 - accuracy: 0.9872 - val_loss: 0.5997 - val_accuracy: 0.8710\n",
      "Epoch 922/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0250 - accuracy: 0.9949 - val_loss: 0.6585 - val_accuracy: 0.8770\n",
      "Epoch 923/1000\n",
      "74/74 [==============================] - 1s 17ms/step - loss: 0.0281 - accuracy: 0.9923 - val_loss: 0.6374 - val_accuracy: 0.8631\n",
      "Epoch 924/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0280 - accuracy: 0.9932 - val_loss: 0.6165 - val_accuracy: 0.8770\n",
      "Epoch 925/1000\n",
      "74/74 [==============================] - 4s 51ms/step - loss: 0.0231 - accuracy: 0.9949 - val_loss: 0.6846 - val_accuracy: 0.8631\n",
      "Epoch 926/1000\n",
      "74/74 [==============================] - 3s 38ms/step - loss: 0.0275 - accuracy: 0.9915 - val_loss: 0.6435 - val_accuracy: 0.8571\n",
      "Epoch 927/1000\n",
      "74/74 [==============================] - 3s 42ms/step - loss: 0.0293 - accuracy: 0.9940 - val_loss: 0.6844 - val_accuracy: 0.8690\n",
      "Epoch 928/1000\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0264 - accuracy: 0.9932 - val_loss: 0.6221 - val_accuracy: 0.8790\n",
      "Epoch 929/1000\n",
      "74/74 [==============================] - 4s 51ms/step - loss: 0.0277 - accuracy: 0.9932 - val_loss: 0.6351 - val_accuracy: 0.8730\n",
      "Epoch 930/1000\n",
      "74/74 [==============================] - 3s 37ms/step - loss: 0.0285 - accuracy: 0.9923 - val_loss: 0.6498 - val_accuracy: 0.8770\n",
      "Epoch 931/1000\n",
      "74/74 [==============================] - 2s 28ms/step - loss: 0.0251 - accuracy: 0.9932 - val_loss: 0.6301 - val_accuracy: 0.8690\n",
      "Epoch 932/1000\n",
      "74/74 [==============================] - 3s 43ms/step - loss: 0.0280 - accuracy: 0.9923 - val_loss: 0.6488 - val_accuracy: 0.8651\n",
      "Epoch 933/1000\n",
      "74/74 [==============================] - 4s 55ms/step - loss: 0.0196 - accuracy: 0.9966 - val_loss: 0.6610 - val_accuracy: 0.8671\n",
      "Epoch 934/1000\n",
      "74/74 [==============================] - 3s 39ms/step - loss: 0.0230 - accuracy: 0.9974 - val_loss: 0.7166 - val_accuracy: 0.8532\n",
      "Epoch 935/1000\n",
      "74/74 [==============================] - 2s 27ms/step - loss: 0.0234 - accuracy: 0.9932 - val_loss: 0.6938 - val_accuracy: 0.8611\n",
      "Epoch 936/1000\n",
      "74/74 [==============================] - 3s 47ms/step - loss: 0.0300 - accuracy: 0.9915 - val_loss: 0.6160 - val_accuracy: 0.8810\n",
      "Epoch 937/1000\n",
      "74/74 [==============================] - 3s 39ms/step - loss: 0.0370 - accuracy: 0.9889 - val_loss: 0.7053 - val_accuracy: 0.8492\n",
      "Epoch 938/1000\n",
      "74/74 [==============================] - 3s 37ms/step - loss: 0.0200 - accuracy: 0.9949 - val_loss: 0.6123 - val_accuracy: 0.8790\n",
      "Epoch 939/1000\n",
      "74/74 [==============================] - 3s 37ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.6525 - val_accuracy: 0.8651\n",
      "Epoch 940/1000\n",
      "74/74 [==============================] - 3s 46ms/step - loss: 0.0255 - accuracy: 0.9940 - val_loss: 0.6805 - val_accuracy: 0.8433\n",
      "Epoch 941/1000\n",
      "74/74 [==============================] - 4s 58ms/step - loss: 0.0234 - accuracy: 0.9957 - val_loss: 0.6604 - val_accuracy: 0.8611\n",
      "Epoch 942/1000\n",
      "74/74 [==============================] - 3s 41ms/step - loss: 0.0237 - accuracy: 0.9957 - val_loss: 0.6182 - val_accuracy: 0.8750\n",
      "Epoch 943/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 0.7583 - val_accuracy: 0.8472\n",
      "Epoch 944/1000\n",
      "74/74 [==============================] - 2s 27ms/step - loss: 0.0196 - accuracy: 0.9957 - val_loss: 0.6640 - val_accuracy: 0.8710\n",
      "Epoch 945/1000\n",
      "74/74 [==============================] - 2s 23ms/step - loss: 0.0210 - accuracy: 0.9949 - val_loss: 0.6235 - val_accuracy: 0.8750\n",
      "Epoch 946/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.7182 - val_accuracy: 0.8512\n",
      "Epoch 947/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0251 - accuracy: 0.9932 - val_loss: 0.6684 - val_accuracy: 0.8710\n",
      "Epoch 948/1000\n",
      "74/74 [==============================] - 3s 36ms/step - loss: 0.0274 - accuracy: 0.9906 - val_loss: 0.6812 - val_accuracy: 0.8571\n",
      "Epoch 949/1000\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0200 - accuracy: 0.9957 - val_loss: 0.6938 - val_accuracy: 0.8571\n",
      "Epoch 950/1000\n",
      "74/74 [==============================] - 2s 23ms/step - loss: 0.0198 - accuracy: 0.9966 - val_loss: 0.7264 - val_accuracy: 0.8631\n",
      "Epoch 951/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.6521 - val_accuracy: 0.8671\n",
      "Epoch 952/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0406 - accuracy: 0.9881 - val_loss: 0.6711 - val_accuracy: 0.8671\n",
      "Epoch 953/1000\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0211 - accuracy: 0.9966 - val_loss: 0.6265 - val_accuracy: 0.8750\n",
      "Epoch 954/1000\n",
      "74/74 [==============================] - 3s 47ms/step - loss: 0.0260 - accuracy: 0.9923 - val_loss: 0.6940 - val_accuracy: 0.8591\n",
      "Epoch 955/1000\n",
      "74/74 [==============================] - 3s 35ms/step - loss: 0.0180 - accuracy: 0.9974 - val_loss: 0.6422 - val_accuracy: 0.8690\n",
      "Epoch 956/1000\n",
      "74/74 [==============================] - 2s 30ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.6421 - val_accuracy: 0.8651\n",
      "Epoch 957/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0230 - accuracy: 0.9949 - val_loss: 0.6358 - val_accuracy: 0.8611\n",
      "Epoch 958/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0203 - accuracy: 0.9923 - val_loss: 0.6202 - val_accuracy: 0.8671\n",
      "Epoch 959/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0277 - accuracy: 0.9932 - val_loss: 0.7026 - val_accuracy: 0.8532\n",
      "Epoch 960/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0204 - accuracy: 0.9974 - val_loss: 0.6498 - val_accuracy: 0.8710\n",
      "Epoch 961/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0230 - accuracy: 0.9940 - val_loss: 0.6808 - val_accuracy: 0.8611\n",
      "Epoch 962/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0237 - accuracy: 0.9940 - val_loss: 0.6703 - val_accuracy: 0.8690\n",
      "Epoch 963/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0196 - accuracy: 0.9966 - val_loss: 0.6623 - val_accuracy: 0.8690\n",
      "Epoch 964/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0267 - accuracy: 0.9932 - val_loss: 0.6933 - val_accuracy: 0.8690\n",
      "Epoch 965/1000\n",
      "74/74 [==============================] - 2s 26ms/step - loss: 0.0261 - accuracy: 0.9940 - val_loss: 0.6706 - val_accuracy: 0.8730\n",
      "Epoch 966/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0246 - accuracy: 0.9940 - val_loss: 0.6323 - val_accuracy: 0.8710\n",
      "Epoch 967/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0340 - accuracy: 0.9915 - val_loss: 0.7348 - val_accuracy: 0.8472\n",
      "Epoch 968/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0275 - accuracy: 0.9898 - val_loss: 0.6676 - val_accuracy: 0.8452\n",
      "Epoch 969/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0183 - accuracy: 0.9957 - val_loss: 0.6898 - val_accuracy: 0.8591\n",
      "Epoch 970/1000\n",
      "74/74 [==============================] - 2s 31ms/step - loss: 0.0191 - accuracy: 0.9974 - val_loss: 0.6371 - val_accuracy: 0.8790\n",
      "Epoch 971/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0223 - accuracy: 0.9932 - val_loss: 0.6283 - val_accuracy: 0.8591\n",
      "Epoch 972/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0234 - accuracy: 0.9940 - val_loss: 0.6911 - val_accuracy: 0.8571\n",
      "Epoch 973/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0194 - accuracy: 0.9957 - val_loss: 0.6828 - val_accuracy: 0.8591\n",
      "Epoch 974/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0258 - accuracy: 0.9923 - val_loss: 0.6461 - val_accuracy: 0.8651\n",
      "Epoch 975/1000\n",
      "74/74 [==============================] - 2s 24ms/step - loss: 0.0237 - accuracy: 0.9923 - val_loss: 0.6627 - val_accuracy: 0.8770\n",
      "Epoch 976/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 0.6515 - val_accuracy: 0.8730\n",
      "Epoch 977/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0227 - accuracy: 0.9949 - val_loss: 0.6110 - val_accuracy: 0.8671\n",
      "Epoch 978/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0266 - accuracy: 0.9923 - val_loss: 0.6357 - val_accuracy: 0.8671\n",
      "Epoch 979/1000\n",
      "74/74 [==============================] - 2s 22ms/step - loss: 0.0177 - accuracy: 0.9974 - val_loss: 0.6314 - val_accuracy: 0.8829\n",
      "Epoch 980/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 0.6276 - val_accuracy: 0.8829\n",
      "Epoch 981/1000\n",
      "74/74 [==============================] - 1s 20ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.7112 - val_accuracy: 0.8552\n",
      "Epoch 982/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0290 - accuracy: 0.9923 - val_loss: 0.6488 - val_accuracy: 0.8631\n",
      "Epoch 983/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.6752 - val_accuracy: 0.8631\n",
      "Epoch 984/1000\n",
      "74/74 [==============================] - 1s 14ms/step - loss: 0.0216 - accuracy: 0.9932 - val_loss: 0.7071 - val_accuracy: 0.8690\n",
      "Epoch 985/1000\n",
      "74/74 [==============================] - 4s 51ms/step - loss: 0.0176 - accuracy: 0.9966 - val_loss: 0.6992 - val_accuracy: 0.8611\n",
      "Epoch 986/1000\n",
      "74/74 [==============================] - 2s 26ms/step - loss: 0.0261 - accuracy: 0.9915 - val_loss: 0.6542 - val_accuracy: 0.8710\n",
      "Epoch 987/1000\n",
      "74/74 [==============================] - 3s 35ms/step - loss: 0.0216 - accuracy: 0.9966 - val_loss: 0.6470 - val_accuracy: 0.8750\n",
      "Epoch 988/1000\n",
      "74/74 [==============================] - 2s 25ms/step - loss: 0.0284 - accuracy: 0.9889 - val_loss: 0.6144 - val_accuracy: 0.8829\n",
      "Epoch 989/1000\n",
      "74/74 [==============================] - 2s 33ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 0.6304 - val_accuracy: 0.8611\n",
      "Epoch 990/1000\n",
      "74/74 [==============================] - 2s 24ms/step - loss: 0.0230 - accuracy: 0.9949 - val_loss: 0.6551 - val_accuracy: 0.8591\n",
      "Epoch 991/1000\n",
      "74/74 [==============================] - 1s 15ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.6671 - val_accuracy: 0.8690\n",
      "Epoch 992/1000\n",
      "74/74 [==============================] - 1s 16ms/step - loss: 0.0210 - accuracy: 0.9957 - val_loss: 0.7063 - val_accuracy: 0.8591\n",
      "Epoch 993/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0236 - accuracy: 0.9957 - val_loss: 0.6028 - val_accuracy: 0.8829\n",
      "Epoch 994/1000\n",
      "74/74 [==============================] - 2s 23ms/step - loss: 0.0256 - accuracy: 0.9906 - val_loss: 0.6431 - val_accuracy: 0.8690\n",
      "Epoch 995/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0226 - accuracy: 0.9957 - val_loss: 0.6266 - val_accuracy: 0.8690\n",
      "Epoch 996/1000\n",
      "74/74 [==============================] - 1s 18ms/step - loss: 0.0227 - accuracy: 0.9957 - val_loss: 0.6575 - val_accuracy: 0.8690\n",
      "Epoch 997/1000\n",
      "74/74 [==============================] - 2s 21ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.6775 - val_accuracy: 0.8690\n",
      "Epoch 998/1000\n",
      "74/74 [==============================] - 1s 19ms/step - loss: 0.0209 - accuracy: 0.9957 - val_loss: 0.6951 - val_accuracy: 0.8671\n",
      "Epoch 999/1000\n",
      "74/74 [==============================] - 3s 37ms/step - loss: 0.0231 - accuracy: 0.9940 - val_loss: 0.7074 - val_accuracy: 0.8710\n",
      "Epoch 1000/1000\n",
      "74/74 [==============================] - 2s 26ms/step - loss: 0.0173 - accuracy: 0.9966 - val_loss: 0.6616 - val_accuracy: 0.8611\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_traincnn, y_train, batch_size=16, epochs=1000, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"nn_jl_1.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-04 21:12:13.846315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 3013 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2022-03-04 21:12:13.849974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 3013 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "    import tensorflow as tf \n",
    "\n",
    "    if tf.test.gpu_device_name(): \n",
    "\n",
    "        print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "    else:\n",
    "\n",
    "       print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
