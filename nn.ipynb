{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.3\n",
    "x=np.load('loaded_data/ravdess_mfcc_x.npy') \n",
    "y=np.load('loaded_data/ravdess_mfcc_y.npy') \n",
    "x_train,x_test,temp_y_train,temp_y_test=train_test_split(np.array(x), y, test_size = test_size, random_state = 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn = np.expand_dims(x_train, axis=2)\n",
    "x_testcnn = np.expand_dims(x_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1008, 40, 1), (432, 40, 1))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_traincnn.shape, x_testcnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test,y_train = [],[]\n",
    "d={}\n",
    "for i in temp_y_test:\n",
    "    if i not in d:\n",
    "        d[i] = len(d)\n",
    "    y_test.append(d[i])\n",
    "for i in temp_y_train:\n",
    "    if i not in d:\n",
    "        d[i] = len(d)\n",
    "    y_train.append(d[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',\n",
    "                 input_shape=(40,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(10)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(d)))\n",
    "model.add(Activation('softmax'))\n",
    "opt = tf.keras.optimizers.RMSprop(lr=0.00005, rho=0.9, epsilon=None, decay=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_16 (Conv1D)          (None, 40, 128)           768       \n",
      "                                                                 \n",
      " activation_24 (Activation)  (None, 40, 128)           0         \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 40, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 4, 128)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 4, 128)            82048     \n",
      "                                                                 \n",
      " activation_25 (Activation)  (None, 4, 128)            0         \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 4, 128)            0         \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8)                 4104      \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86,920\n",
      "Trainable params: 86,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "63/63 [==============================] - 2s 13ms/step - loss: 11.0646 - accuracy: 0.1190 - val_loss: 2.6042 - val_accuracy: 0.1250\n",
      "Epoch 2/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 9.5155 - accuracy: 0.1270 - val_loss: 2.8576 - val_accuracy: 0.1227\n",
      "Epoch 3/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 8.3415 - accuracy: 0.1409 - val_loss: 2.8832 - val_accuracy: 0.2222\n",
      "Epoch 4/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 8.1284 - accuracy: 0.1359 - val_loss: 2.3720 - val_accuracy: 0.1782\n",
      "Epoch 5/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 7.4162 - accuracy: 0.1349 - val_loss: 2.2388 - val_accuracy: 0.1829\n",
      "Epoch 6/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 6.9382 - accuracy: 0.1528 - val_loss: 2.7401 - val_accuracy: 0.1620\n",
      "Epoch 7/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 6.4987 - accuracy: 0.1220 - val_loss: 2.0949 - val_accuracy: 0.2569\n",
      "Epoch 8/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 5.6919 - accuracy: 0.1597 - val_loss: 2.1974 - val_accuracy: 0.2315\n",
      "Epoch 9/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 5.1349 - accuracy: 0.1577 - val_loss: 1.9617 - val_accuracy: 0.2384\n",
      "Epoch 10/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 4.8020 - accuracy: 0.1597 - val_loss: 1.9845 - val_accuracy: 0.2269\n",
      "Epoch 11/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 4.4635 - accuracy: 0.1657 - val_loss: 2.1722 - val_accuracy: 0.2199\n",
      "Epoch 12/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 4.2340 - accuracy: 0.1518 - val_loss: 2.0242 - val_accuracy: 0.2546\n",
      "Epoch 13/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 3.7805 - accuracy: 0.1865 - val_loss: 1.9825 - val_accuracy: 0.2569\n",
      "Epoch 14/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 3.4444 - accuracy: 0.1657 - val_loss: 2.1478 - val_accuracy: 0.2153\n",
      "Epoch 15/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 3.1975 - accuracy: 0.1696 - val_loss: 1.9001 - val_accuracy: 0.3148\n",
      "Epoch 16/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.8826 - accuracy: 0.1895 - val_loss: 1.9203 - val_accuracy: 0.2639\n",
      "Epoch 17/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.7427 - accuracy: 0.1627 - val_loss: 1.9858 - val_accuracy: 0.2292\n",
      "Epoch 18/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 2.6337 - accuracy: 0.1935 - val_loss: 2.0893 - val_accuracy: 0.2199\n",
      "Epoch 19/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 2.4611 - accuracy: 0.1687 - val_loss: 1.9478 - val_accuracy: 0.2731\n",
      "Epoch 20/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 2.3192 - accuracy: 0.2044 - val_loss: 2.0317 - val_accuracy: 0.2361\n",
      "Epoch 21/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 2.3044 - accuracy: 0.1974 - val_loss: 1.9564 - val_accuracy: 0.2292\n",
      "Epoch 22/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.2254 - accuracy: 0.2123 - val_loss: 1.9611 - val_accuracy: 0.1968\n",
      "Epoch 23/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.1653 - accuracy: 0.1974 - val_loss: 1.9748 - val_accuracy: 0.1852\n",
      "Epoch 24/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.1577 - accuracy: 0.1895 - val_loss: 1.9699 - val_accuracy: 0.1551\n",
      "Epoch 25/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.0980 - accuracy: 0.1964 - val_loss: 1.9448 - val_accuracy: 0.3032\n",
      "Epoch 26/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 2.0947 - accuracy: 0.2093 - val_loss: 1.9531 - val_accuracy: 0.2685\n",
      "Epoch 27/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 2.0340 - accuracy: 0.2173 - val_loss: 1.9428 - val_accuracy: 0.2963\n",
      "Epoch 28/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.0091 - accuracy: 0.2262 - val_loss: 1.9403 - val_accuracy: 0.2801\n",
      "Epoch 29/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 2.0192 - accuracy: 0.2014 - val_loss: 1.9236 - val_accuracy: 0.2338\n",
      "Epoch 30/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 2.0261 - accuracy: 0.2133 - val_loss: 1.9471 - val_accuracy: 0.2708\n",
      "Epoch 31/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 2.0210 - accuracy: 0.2073 - val_loss: 1.9233 - val_accuracy: 0.2593\n",
      "Epoch 32/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 2.0584 - accuracy: 0.2004 - val_loss: 1.9354 - val_accuracy: 0.2315\n",
      "Epoch 33/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.9996 - accuracy: 0.2183 - val_loss: 1.9328 - val_accuracy: 0.2500\n",
      "Epoch 34/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 2.0246 - accuracy: 0.2183 - val_loss: 1.9180 - val_accuracy: 0.2639\n",
      "Epoch 35/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.9813 - accuracy: 0.2272 - val_loss: 1.9103 - val_accuracy: 0.2824\n",
      "Epoch 36/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 1.9801 - accuracy: 0.2411 - val_loss: 1.9084 - val_accuracy: 0.3171\n",
      "Epoch 37/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.9697 - accuracy: 0.2272 - val_loss: 1.9062 - val_accuracy: 0.3125\n",
      "Epoch 38/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.9959 - accuracy: 0.2173 - val_loss: 1.9016 - val_accuracy: 0.2639\n",
      "Epoch 39/1000\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 1.9732 - accuracy: 0.2232 - val_loss: 1.8915 - val_accuracy: 0.3032\n",
      "Epoch 40/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 1.9501 - accuracy: 0.2411 - val_loss: 1.8870 - val_accuracy: 0.2685\n",
      "Epoch 41/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.9538 - accuracy: 0.2431 - val_loss: 1.8903 - val_accuracy: 0.3056\n",
      "Epoch 42/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 1.9551 - accuracy: 0.2282 - val_loss: 1.8878 - val_accuracy: 0.2824\n",
      "Epoch 43/1000\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 1.9567 - accuracy: 0.2341 - val_loss: 1.8852 - val_accuracy: 0.2778\n",
      "Epoch 44/1000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.9562 - accuracy: 0.2242 - val_loss: 1.8695 - val_accuracy: 0.3102\n",
      "Epoch 45/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.9320 - accuracy: 0.2560 - val_loss: 1.8554 - val_accuracy: 0.3449\n",
      "Epoch 46/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.9374 - accuracy: 0.2579 - val_loss: 1.8543 - val_accuracy: 0.3356\n",
      "Epoch 47/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.9214 - accuracy: 0.2679 - val_loss: 1.8677 - val_accuracy: 0.2847\n",
      "Epoch 48/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.9185 - accuracy: 0.2579 - val_loss: 1.8371 - val_accuracy: 0.3264\n",
      "Epoch 49/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.9046 - accuracy: 0.2599 - val_loss: 1.8317 - val_accuracy: 0.3264\n",
      "Epoch 50/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.9074 - accuracy: 0.2669 - val_loss: 1.8337 - val_accuracy: 0.3009\n",
      "Epoch 51/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.8730 - accuracy: 0.2827 - val_loss: 1.8448 - val_accuracy: 0.3125\n",
      "Epoch 52/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.8983 - accuracy: 0.2510 - val_loss: 1.8153 - val_accuracy: 0.3079\n",
      "Epoch 53/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.8707 - accuracy: 0.2758 - val_loss: 1.8085 - val_accuracy: 0.3449\n",
      "Epoch 54/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.8804 - accuracy: 0.2827 - val_loss: 1.8250 - val_accuracy: 0.3218\n",
      "Epoch 55/1000\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.8670 - accuracy: 0.2748 - val_loss: 1.8108 - val_accuracy: 0.3218\n",
      "Epoch 56/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.8631 - accuracy: 0.2669 - val_loss: 1.8089 - val_accuracy: 0.3449\n",
      "Epoch 57/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.8471 - accuracy: 0.2827 - val_loss: 1.8054 - val_accuracy: 0.3519\n",
      "Epoch 58/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.8797 - accuracy: 0.2629 - val_loss: 1.7931 - val_accuracy: 0.3912\n",
      "Epoch 59/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.8685 - accuracy: 0.2768 - val_loss: 1.8037 - val_accuracy: 0.3657\n",
      "Epoch 60/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.8592 - accuracy: 0.2867 - val_loss: 1.7809 - val_accuracy: 0.3889\n",
      "Epoch 61/1000\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 1.8368 - accuracy: 0.2966 - val_loss: 1.7768 - val_accuracy: 0.3449\n",
      "Epoch 62/1000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.8611 - accuracy: 0.2897 - val_loss: 1.7830 - val_accuracy: 0.3495\n",
      "Epoch 63/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.8361 - accuracy: 0.3006 - val_loss: 1.7645 - val_accuracy: 0.3773\n",
      "Epoch 64/1000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.8277 - accuracy: 0.2946 - val_loss: 1.7730 - val_accuracy: 0.3819\n",
      "Epoch 65/1000\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 1.8404 - accuracy: 0.2550 - val_loss: 1.7764 - val_accuracy: 0.3542\n",
      "Epoch 66/1000\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 1.8474 - accuracy: 0.2956 - val_loss: 1.7659 - val_accuracy: 0.3681\n",
      "Epoch 67/1000\n",
      "63/63 [==============================] - 3s 45ms/step - loss: 1.8189 - accuracy: 0.2877 - val_loss: 1.7617 - val_accuracy: 0.3449\n",
      "Epoch 68/1000\n",
      "63/63 [==============================] - 2s 32ms/step - loss: 1.8086 - accuracy: 0.2907 - val_loss: 1.7691 - val_accuracy: 0.3843\n",
      "Epoch 69/1000\n",
      "63/63 [==============================] - 1s 21ms/step - loss: 1.8156 - accuracy: 0.3065 - val_loss: 1.7762 - val_accuracy: 0.3102\n",
      "Epoch 70/1000\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 1.8202 - accuracy: 0.2867 - val_loss: 1.7633 - val_accuracy: 0.3750\n",
      "Epoch 71/1000\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 1.7851 - accuracy: 0.3125 - val_loss: 1.7531 - val_accuracy: 0.3958\n",
      "Epoch 72/1000\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.7899 - accuracy: 0.3105 - val_loss: 1.7493 - val_accuracy: 0.3958\n",
      "Epoch 73/1000\n",
      "63/63 [==============================] - 1s 19ms/step - loss: 1.8075 - accuracy: 0.2887 - val_loss: 1.7611 - val_accuracy: 0.3750\n",
      "Epoch 74/1000\n",
      "63/63 [==============================] - 1s 20ms/step - loss: 1.7964 - accuracy: 0.3105 - val_loss: 1.7491 - val_accuracy: 0.3773\n",
      "Epoch 75/1000\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 1.7775 - accuracy: 0.3145 - val_loss: 1.7680 - val_accuracy: 0.3449\n",
      "Epoch 76/1000\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 1.7764 - accuracy: 0.3155 - val_loss: 1.7798 - val_accuracy: 0.3519\n",
      "Epoch 77/1000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.7855 - accuracy: 0.3046 - val_loss: 1.7256 - val_accuracy: 0.3565\n",
      "Epoch 78/1000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.7754 - accuracy: 0.3343 - val_loss: 1.7259 - val_accuracy: 0.3750\n",
      "Epoch 79/1000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.7858 - accuracy: 0.2996 - val_loss: 1.7277 - val_accuracy: 0.4005\n",
      "Epoch 80/1000\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.7738 - accuracy: 0.3264 - val_loss: 1.7234 - val_accuracy: 0.3981\n",
      "Epoch 81/1000\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.7605 - accuracy: 0.3313 - val_loss: 1.7049 - val_accuracy: 0.3981\n",
      "Epoch 82/1000\n",
      "63/63 [==============================] - 1s 18ms/step - loss: 1.7633 - accuracy: 0.3204 - val_loss: 1.7114 - val_accuracy: 0.3912\n",
      "Epoch 83/1000\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.7720 - accuracy: 0.3304 - val_loss: 1.7228 - val_accuracy: 0.3634\n",
      "Epoch 84/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.7589 - accuracy: 0.3075 - val_loss: 1.7222 - val_accuracy: 0.3542\n",
      "Epoch 85/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.7540 - accuracy: 0.3165 - val_loss: 1.7627 - val_accuracy: 0.3426\n",
      "Epoch 86/1000\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 1.7412 - accuracy: 0.3105 - val_loss: 1.7192 - val_accuracy: 0.4051\n",
      "Epoch 87/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.7355 - accuracy: 0.3363 - val_loss: 1.7180 - val_accuracy: 0.3843\n",
      "Epoch 88/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.7346 - accuracy: 0.3403 - val_loss: 1.7176 - val_accuracy: 0.3866\n",
      "Epoch 89/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.7317 - accuracy: 0.3373 - val_loss: 1.7108 - val_accuracy: 0.3912\n",
      "Epoch 90/1000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.7505 - accuracy: 0.3085 - val_loss: 1.7007 - val_accuracy: 0.4097\n",
      "Epoch 91/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.7703 - accuracy: 0.3105 - val_loss: 1.7012 - val_accuracy: 0.3773\n",
      "Epoch 92/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.7670 - accuracy: 0.2976 - val_loss: 1.7057 - val_accuracy: 0.3657\n",
      "Epoch 93/1000\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.6919 - accuracy: 0.3323 - val_loss: 1.6984 - val_accuracy: 0.4028\n",
      "Epoch 94/1000\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.7262 - accuracy: 0.3383 - val_loss: 1.6878 - val_accuracy: 0.4120\n",
      "Epoch 95/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.7312 - accuracy: 0.3244 - val_loss: 1.7007 - val_accuracy: 0.3611\n",
      "Epoch 96/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.7263 - accuracy: 0.3433 - val_loss: 1.6863 - val_accuracy: 0.3750\n",
      "Epoch 97/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.7552 - accuracy: 0.3304 - val_loss: 1.6941 - val_accuracy: 0.4144\n",
      "Epoch 98/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.7279 - accuracy: 0.3393 - val_loss: 1.7007 - val_accuracy: 0.3935\n",
      "Epoch 99/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.7285 - accuracy: 0.3373 - val_loss: 1.7116 - val_accuracy: 0.3588\n",
      "Epoch 100/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.7230 - accuracy: 0.3313 - val_loss: 1.6893 - val_accuracy: 0.3727\n",
      "Epoch 101/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6986 - accuracy: 0.3502 - val_loss: 1.6833 - val_accuracy: 0.3935\n",
      "Epoch 102/1000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.7368 - accuracy: 0.3264 - val_loss: 1.6839 - val_accuracy: 0.3773\n",
      "Epoch 103/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.7063 - accuracy: 0.3343 - val_loss: 1.6812 - val_accuracy: 0.4074\n",
      "Epoch 104/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.7100 - accuracy: 0.3313 - val_loss: 1.6686 - val_accuracy: 0.4097\n",
      "Epoch 105/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 1.6926 - accuracy: 0.3433 - val_loss: 1.6959 - val_accuracy: 0.3819\n",
      "Epoch 106/1000\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.7321 - accuracy: 0.3056 - val_loss: 1.6766 - val_accuracy: 0.3981\n",
      "Epoch 107/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.6721 - accuracy: 0.3562 - val_loss: 1.6637 - val_accuracy: 0.4190\n",
      "Epoch 108/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 1.7189 - accuracy: 0.3343 - val_loss: 1.6737 - val_accuracy: 0.4074\n",
      "Epoch 109/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.6943 - accuracy: 0.3472 - val_loss: 1.6823 - val_accuracy: 0.3657\n",
      "Epoch 110/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6759 - accuracy: 0.3770 - val_loss: 1.6899 - val_accuracy: 0.3681\n",
      "Epoch 111/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6799 - accuracy: 0.3423 - val_loss: 1.6716 - val_accuracy: 0.3819\n",
      "Epoch 112/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6776 - accuracy: 0.3353 - val_loss: 1.6538 - val_accuracy: 0.4329\n",
      "Epoch 113/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6693 - accuracy: 0.3621 - val_loss: 1.6546 - val_accuracy: 0.4190\n",
      "Epoch 114/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.7057 - accuracy: 0.3502 - val_loss: 1.6677 - val_accuracy: 0.4074\n",
      "Epoch 115/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.6627 - accuracy: 0.3621 - val_loss: 1.6449 - val_accuracy: 0.4190\n",
      "Epoch 116/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6628 - accuracy: 0.3601 - val_loss: 1.6444 - val_accuracy: 0.4352\n",
      "Epoch 117/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.6870 - accuracy: 0.3472 - val_loss: 1.6521 - val_accuracy: 0.4306\n",
      "Epoch 118/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.6678 - accuracy: 0.3452 - val_loss: 1.6715 - val_accuracy: 0.4190\n",
      "Epoch 119/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.6774 - accuracy: 0.3661 - val_loss: 1.6563 - val_accuracy: 0.3958\n",
      "Epoch 120/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6425 - accuracy: 0.3631 - val_loss: 1.6514 - val_accuracy: 0.4074\n",
      "Epoch 121/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.6740 - accuracy: 0.3552 - val_loss: 1.6527 - val_accuracy: 0.4120\n",
      "Epoch 122/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 1.6765 - accuracy: 0.3492 - val_loss: 1.6431 - val_accuracy: 0.4259\n",
      "Epoch 123/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6439 - accuracy: 0.3829 - val_loss: 1.6423 - val_accuracy: 0.3958\n",
      "Epoch 124/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 1.6890 - accuracy: 0.3542 - val_loss: 1.6511 - val_accuracy: 0.4213\n",
      "Epoch 125/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6549 - accuracy: 0.3571 - val_loss: 1.6629 - val_accuracy: 0.3681\n",
      "Epoch 126/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 1.6361 - accuracy: 0.3601 - val_loss: 1.6460 - val_accuracy: 0.4051\n",
      "Epoch 127/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 1.6594 - accuracy: 0.3502 - val_loss: 1.6412 - val_accuracy: 0.4190\n",
      "Epoch 128/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.6504 - accuracy: 0.3532 - val_loss: 1.6432 - val_accuracy: 0.4005\n",
      "Epoch 129/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6427 - accuracy: 0.3532 - val_loss: 1.6320 - val_accuracy: 0.3958\n",
      "Epoch 130/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6525 - accuracy: 0.3621 - val_loss: 1.6504 - val_accuracy: 0.4028\n",
      "Epoch 131/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6364 - accuracy: 0.3462 - val_loss: 1.6425 - val_accuracy: 0.4144\n",
      "Epoch 132/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 1.6446 - accuracy: 0.3651 - val_loss: 1.6577 - val_accuracy: 0.4213\n",
      "Epoch 133/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6374 - accuracy: 0.3839 - val_loss: 1.6528 - val_accuracy: 0.4213\n",
      "Epoch 134/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6424 - accuracy: 0.3919 - val_loss: 1.6530 - val_accuracy: 0.3981\n",
      "Epoch 135/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6376 - accuracy: 0.3690 - val_loss: 1.6592 - val_accuracy: 0.3889\n",
      "Epoch 136/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6245 - accuracy: 0.3671 - val_loss: 1.6472 - val_accuracy: 0.4051\n",
      "Epoch 137/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.6174 - accuracy: 0.3810 - val_loss: 1.6631 - val_accuracy: 0.3866\n",
      "Epoch 138/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.6371 - accuracy: 0.3532 - val_loss: 1.6363 - val_accuracy: 0.3912\n",
      "Epoch 139/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.6228 - accuracy: 0.3720 - val_loss: 1.6274 - val_accuracy: 0.4259\n",
      "Epoch 140/1000\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.6343 - accuracy: 0.3690 - val_loss: 1.6727 - val_accuracy: 0.3819\n",
      "Epoch 141/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6341 - accuracy: 0.3621 - val_loss: 1.6711 - val_accuracy: 0.4005\n",
      "Epoch 142/1000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.6219 - accuracy: 0.3710 - val_loss: 1.6214 - val_accuracy: 0.4074\n",
      "Epoch 143/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.6209 - accuracy: 0.3859 - val_loss: 1.6161 - val_accuracy: 0.4097\n",
      "Epoch 144/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.6199 - accuracy: 0.3750 - val_loss: 1.6387 - val_accuracy: 0.4028\n",
      "Epoch 145/1000\n",
      "63/63 [==============================] - 2s 25ms/step - loss: 1.6112 - accuracy: 0.3760 - val_loss: 1.6327 - val_accuracy: 0.4005\n",
      "Epoch 146/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.6055 - accuracy: 0.3770 - val_loss: 1.6537 - val_accuracy: 0.3773\n",
      "Epoch 147/1000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.6240 - accuracy: 0.3988 - val_loss: 1.6266 - val_accuracy: 0.4190\n",
      "Epoch 148/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6025 - accuracy: 0.3750 - val_loss: 1.6151 - val_accuracy: 0.3912\n",
      "Epoch 149/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.6327 - accuracy: 0.3700 - val_loss: 1.6537 - val_accuracy: 0.3750\n",
      "Epoch 150/1000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.6233 - accuracy: 0.3859 - val_loss: 1.6419 - val_accuracy: 0.4051\n",
      "Epoch 151/1000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.5991 - accuracy: 0.3810 - val_loss: 1.6276 - val_accuracy: 0.4028\n",
      "Epoch 152/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.6138 - accuracy: 0.3790 - val_loss: 1.6344 - val_accuracy: 0.4236\n",
      "Epoch 153/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.6123 - accuracy: 0.3829 - val_loss: 1.6226 - val_accuracy: 0.4190\n",
      "Epoch 154/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.6038 - accuracy: 0.3958 - val_loss: 1.6135 - val_accuracy: 0.4097\n",
      "Epoch 155/1000\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.5912 - accuracy: 0.3968 - val_loss: 1.5977 - val_accuracy: 0.4491\n",
      "Epoch 156/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.5913 - accuracy: 0.3889 - val_loss: 1.6295 - val_accuracy: 0.3981\n",
      "Epoch 157/1000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.5849 - accuracy: 0.3770 - val_loss: 1.5954 - val_accuracy: 0.4144\n",
      "Epoch 158/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.5809 - accuracy: 0.3879 - val_loss: 1.6016 - val_accuracy: 0.4236\n",
      "Epoch 159/1000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.5947 - accuracy: 0.3780 - val_loss: 1.6003 - val_accuracy: 0.4144\n",
      "Epoch 160/1000\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.6027 - accuracy: 0.3810 - val_loss: 1.6011 - val_accuracy: 0.4259\n",
      "Epoch 161/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.5831 - accuracy: 0.3998 - val_loss: 1.6098 - val_accuracy: 0.4190\n",
      "Epoch 162/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.5775 - accuracy: 0.3849 - val_loss: 1.6083 - val_accuracy: 0.4306\n",
      "Epoch 163/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.6088 - accuracy: 0.3929 - val_loss: 1.6019 - val_accuracy: 0.4306\n",
      "Epoch 164/1000\n",
      "63/63 [==============================] - 1s 14ms/step - loss: 1.5735 - accuracy: 0.4077 - val_loss: 1.6037 - val_accuracy: 0.4120\n",
      "Epoch 165/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 1.5932 - accuracy: 0.3750 - val_loss: 1.6103 - val_accuracy: 0.4051\n",
      "Epoch 166/1000\n",
      "63/63 [==============================] - 1s 12ms/step - loss: 1.5751 - accuracy: 0.4167 - val_loss: 1.6184 - val_accuracy: 0.3866\n",
      "Epoch 167/1000\n",
      "63/63 [==============================] - 1s 13ms/step - loss: 1.5781 - accuracy: 0.3909 - val_loss: 1.5996 - val_accuracy: 0.4282\n",
      "Epoch 168/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.5772 - accuracy: 0.3869 - val_loss: 1.6794 - val_accuracy: 0.3634\n",
      "Epoch 169/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.5646 - accuracy: 0.3929 - val_loss: 1.5950 - val_accuracy: 0.4259\n",
      "Epoch 170/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.5457 - accuracy: 0.4087 - val_loss: 1.6004 - val_accuracy: 0.4028\n",
      "Epoch 171/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.5336 - accuracy: 0.4117 - val_loss: 1.5790 - val_accuracy: 0.4282\n",
      "Epoch 172/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5688 - accuracy: 0.4028 - val_loss: 1.5767 - val_accuracy: 0.4306\n",
      "Epoch 173/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5842 - accuracy: 0.3829 - val_loss: 1.5866 - val_accuracy: 0.4329\n",
      "Epoch 174/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.5598 - accuracy: 0.3958 - val_loss: 1.5810 - val_accuracy: 0.4282\n",
      "Epoch 175/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5347 - accuracy: 0.4127 - val_loss: 1.6139 - val_accuracy: 0.4144\n",
      "Epoch 176/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5425 - accuracy: 0.4067 - val_loss: 1.5848 - val_accuracy: 0.4120\n",
      "Epoch 177/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5583 - accuracy: 0.4107 - val_loss: 1.5701 - val_accuracy: 0.4259\n",
      "Epoch 178/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.5318 - accuracy: 0.4058 - val_loss: 1.5669 - val_accuracy: 0.4421\n",
      "Epoch 179/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.5508 - accuracy: 0.4127 - val_loss: 1.6074 - val_accuracy: 0.3935\n",
      "Epoch 180/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5409 - accuracy: 0.4067 - val_loss: 1.5925 - val_accuracy: 0.4236\n",
      "Epoch 181/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.5410 - accuracy: 0.4077 - val_loss: 1.5875 - val_accuracy: 0.4236\n",
      "Epoch 182/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5658 - accuracy: 0.3909 - val_loss: 1.5893 - val_accuracy: 0.4259\n",
      "Epoch 183/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.5585 - accuracy: 0.4058 - val_loss: 1.6001 - val_accuracy: 0.4097\n",
      "Epoch 184/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5221 - accuracy: 0.4226 - val_loss: 1.5831 - val_accuracy: 0.4051\n",
      "Epoch 185/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5271 - accuracy: 0.4147 - val_loss: 1.5816 - val_accuracy: 0.4306\n",
      "Epoch 186/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.5230 - accuracy: 0.4107 - val_loss: 1.5789 - val_accuracy: 0.4213\n",
      "Epoch 187/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5368 - accuracy: 0.4216 - val_loss: 1.5848 - val_accuracy: 0.4236\n",
      "Epoch 188/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.5365 - accuracy: 0.4097 - val_loss: 1.5981 - val_accuracy: 0.4282\n",
      "Epoch 189/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.5338 - accuracy: 0.4157 - val_loss: 1.5692 - val_accuracy: 0.4352\n",
      "Epoch 190/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5236 - accuracy: 0.4167 - val_loss: 1.5652 - val_accuracy: 0.4144\n",
      "Epoch 191/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4892 - accuracy: 0.4435 - val_loss: 1.6045 - val_accuracy: 0.4074\n",
      "Epoch 192/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.5238 - accuracy: 0.4077 - val_loss: 1.5727 - val_accuracy: 0.4329\n",
      "Epoch 193/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5270 - accuracy: 0.4117 - val_loss: 1.5850 - val_accuracy: 0.4213\n",
      "Epoch 194/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5407 - accuracy: 0.4246 - val_loss: 1.5963 - val_accuracy: 0.3981\n",
      "Epoch 195/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5225 - accuracy: 0.4018 - val_loss: 1.5897 - val_accuracy: 0.4120\n",
      "Epoch 196/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.5291 - accuracy: 0.4177 - val_loss: 1.5562 - val_accuracy: 0.4329\n",
      "Epoch 197/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5288 - accuracy: 0.4107 - val_loss: 1.5676 - val_accuracy: 0.4282\n",
      "Epoch 198/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5179 - accuracy: 0.4246 - val_loss: 1.5446 - val_accuracy: 0.4421\n",
      "Epoch 199/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5092 - accuracy: 0.4256 - val_loss: 1.5473 - val_accuracy: 0.4329\n",
      "Epoch 200/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5040 - accuracy: 0.4325 - val_loss: 1.5447 - val_accuracy: 0.4398\n",
      "Epoch 201/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5080 - accuracy: 0.4296 - val_loss: 1.5540 - val_accuracy: 0.4236\n",
      "Epoch 202/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.4991 - accuracy: 0.4335 - val_loss: 1.5656 - val_accuracy: 0.4259\n",
      "Epoch 203/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.4908 - accuracy: 0.4415 - val_loss: 1.5402 - val_accuracy: 0.4468\n",
      "Epoch 204/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.4702 - accuracy: 0.4435 - val_loss: 1.5428 - val_accuracy: 0.4444\n",
      "Epoch 205/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5148 - accuracy: 0.4276 - val_loss: 1.5707 - val_accuracy: 0.4028\n",
      "Epoch 206/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5014 - accuracy: 0.4187 - val_loss: 1.5383 - val_accuracy: 0.4398\n",
      "Epoch 207/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4813 - accuracy: 0.4246 - val_loss: 1.5554 - val_accuracy: 0.4259\n",
      "Epoch 208/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.5002 - accuracy: 0.4534 - val_loss: 1.5628 - val_accuracy: 0.4282\n",
      "Epoch 209/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4943 - accuracy: 0.4315 - val_loss: 1.5594 - val_accuracy: 0.4352\n",
      "Epoch 210/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4674 - accuracy: 0.4524 - val_loss: 1.5467 - val_accuracy: 0.4375\n",
      "Epoch 211/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4986 - accuracy: 0.4315 - val_loss: 1.5364 - val_accuracy: 0.4444\n",
      "Epoch 212/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4616 - accuracy: 0.4444 - val_loss: 1.5461 - val_accuracy: 0.4259\n",
      "Epoch 213/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4791 - accuracy: 0.4246 - val_loss: 1.5707 - val_accuracy: 0.4074\n",
      "Epoch 214/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4650 - accuracy: 0.4484 - val_loss: 1.5347 - val_accuracy: 0.4444\n",
      "Epoch 215/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4869 - accuracy: 0.4306 - val_loss: 1.5356 - val_accuracy: 0.4398\n",
      "Epoch 216/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4823 - accuracy: 0.4325 - val_loss: 1.5360 - val_accuracy: 0.4282\n",
      "Epoch 217/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4798 - accuracy: 0.4375 - val_loss: 1.5261 - val_accuracy: 0.4329\n",
      "Epoch 218/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4993 - accuracy: 0.4286 - val_loss: 1.5479 - val_accuracy: 0.4329\n",
      "Epoch 219/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.4873 - accuracy: 0.4315 - val_loss: 1.5223 - val_accuracy: 0.4468\n",
      "Epoch 220/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4853 - accuracy: 0.4226 - val_loss: 1.5229 - val_accuracy: 0.4468\n",
      "Epoch 221/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.4851 - accuracy: 0.4286 - val_loss: 1.5796 - val_accuracy: 0.4167\n",
      "Epoch 222/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.4644 - accuracy: 0.4524 - val_loss: 1.5238 - val_accuracy: 0.4537\n",
      "Epoch 223/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4665 - accuracy: 0.4395 - val_loss: 1.5461 - val_accuracy: 0.4375\n",
      "Epoch 224/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4721 - accuracy: 0.4395 - val_loss: 1.5491 - val_accuracy: 0.4213\n",
      "Epoch 225/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4741 - accuracy: 0.4484 - val_loss: 1.5327 - val_accuracy: 0.4213\n",
      "Epoch 226/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.4381 - accuracy: 0.4544 - val_loss: 1.5516 - val_accuracy: 0.4213\n",
      "Epoch 227/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4611 - accuracy: 0.4494 - val_loss: 1.5431 - val_accuracy: 0.4329\n",
      "Epoch 228/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4835 - accuracy: 0.4325 - val_loss: 1.5309 - val_accuracy: 0.4329\n",
      "Epoch 229/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.4579 - accuracy: 0.4415 - val_loss: 1.5300 - val_accuracy: 0.4398\n",
      "Epoch 230/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.4477 - accuracy: 0.4613 - val_loss: 1.5847 - val_accuracy: 0.4167\n",
      "Epoch 231/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.4499 - accuracy: 0.4474 - val_loss: 1.5770 - val_accuracy: 0.4120\n",
      "Epoch 232/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4488 - accuracy: 0.4593 - val_loss: 1.5480 - val_accuracy: 0.4190\n",
      "Epoch 233/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4236 - accuracy: 0.4702 - val_loss: 1.5270 - val_accuracy: 0.4329\n",
      "Epoch 234/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4651 - accuracy: 0.4573 - val_loss: 1.5268 - val_accuracy: 0.4375\n",
      "Epoch 235/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4634 - accuracy: 0.4563 - val_loss: 1.5352 - val_accuracy: 0.4236\n",
      "Epoch 236/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4719 - accuracy: 0.4375 - val_loss: 1.5463 - val_accuracy: 0.4120\n",
      "Epoch 237/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4473 - accuracy: 0.4554 - val_loss: 1.5849 - val_accuracy: 0.4005\n",
      "Epoch 238/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.4525 - accuracy: 0.4425 - val_loss: 1.5629 - val_accuracy: 0.4167\n",
      "Epoch 239/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4470 - accuracy: 0.4474 - val_loss: 1.5337 - val_accuracy: 0.4468\n",
      "Epoch 240/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.4296 - accuracy: 0.4514 - val_loss: 1.5333 - val_accuracy: 0.4421\n",
      "Epoch 241/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4475 - accuracy: 0.4673 - val_loss: 1.5301 - val_accuracy: 0.4514\n",
      "Epoch 242/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4507 - accuracy: 0.4464 - val_loss: 1.5210 - val_accuracy: 0.4375\n",
      "Epoch 243/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4334 - accuracy: 0.4563 - val_loss: 1.5214 - val_accuracy: 0.4306\n",
      "Epoch 244/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.4672 - accuracy: 0.4544 - val_loss: 1.5421 - val_accuracy: 0.4190\n",
      "Epoch 245/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.4365 - accuracy: 0.4742 - val_loss: 1.5139 - val_accuracy: 0.4421\n",
      "Epoch 246/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4341 - accuracy: 0.4544 - val_loss: 1.5359 - val_accuracy: 0.4375\n",
      "Epoch 247/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.4128 - accuracy: 0.4623 - val_loss: 1.5212 - val_accuracy: 0.4282\n",
      "Epoch 248/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4399 - accuracy: 0.4544 - val_loss: 1.5128 - val_accuracy: 0.4375\n",
      "Epoch 249/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4126 - accuracy: 0.4861 - val_loss: 1.5251 - val_accuracy: 0.4236\n",
      "Epoch 250/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4354 - accuracy: 0.4365 - val_loss: 1.5189 - val_accuracy: 0.4167\n",
      "Epoch 251/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.4332 - accuracy: 0.4643 - val_loss: 1.5486 - val_accuracy: 0.4259\n",
      "Epoch 252/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4368 - accuracy: 0.4583 - val_loss: 1.5226 - val_accuracy: 0.4259\n",
      "Epoch 253/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4122 - accuracy: 0.4593 - val_loss: 1.4981 - val_accuracy: 0.4352\n",
      "Epoch 254/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.4126 - accuracy: 0.4712 - val_loss: 1.5087 - val_accuracy: 0.4282\n",
      "Epoch 255/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4472 - accuracy: 0.4464 - val_loss: 1.5132 - val_accuracy: 0.4514\n",
      "Epoch 256/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.4048 - accuracy: 0.4722 - val_loss: 1.5427 - val_accuracy: 0.4190\n",
      "Epoch 257/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4120 - accuracy: 0.4633 - val_loss: 1.4977 - val_accuracy: 0.4606\n",
      "Epoch 258/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4222 - accuracy: 0.4663 - val_loss: 1.5290 - val_accuracy: 0.4259\n",
      "Epoch 259/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.4046 - accuracy: 0.4603 - val_loss: 1.5010 - val_accuracy: 0.4398\n",
      "Epoch 260/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.4213 - accuracy: 0.4643 - val_loss: 1.4892 - val_accuracy: 0.4514\n",
      "Epoch 261/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4122 - accuracy: 0.4722 - val_loss: 1.5083 - val_accuracy: 0.4583\n",
      "Epoch 262/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.4104 - accuracy: 0.4692 - val_loss: 1.5099 - val_accuracy: 0.4190\n",
      "Epoch 263/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3904 - accuracy: 0.4931 - val_loss: 1.5088 - val_accuracy: 0.4352\n",
      "Epoch 264/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4189 - accuracy: 0.4752 - val_loss: 1.4898 - val_accuracy: 0.4537\n",
      "Epoch 265/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4045 - accuracy: 0.4484 - val_loss: 1.5117 - val_accuracy: 0.4306\n",
      "Epoch 266/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.4098 - accuracy: 0.4514 - val_loss: 1.5133 - val_accuracy: 0.4352\n",
      "Epoch 267/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4054 - accuracy: 0.4623 - val_loss: 1.5146 - val_accuracy: 0.4444\n",
      "Epoch 268/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3871 - accuracy: 0.4742 - val_loss: 1.5259 - val_accuracy: 0.4144\n",
      "Epoch 269/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3870 - accuracy: 0.4841 - val_loss: 1.5207 - val_accuracy: 0.4352\n",
      "Epoch 270/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.4047 - accuracy: 0.4802 - val_loss: 1.5162 - val_accuracy: 0.4398\n",
      "Epoch 271/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3907 - accuracy: 0.4960 - val_loss: 1.4864 - val_accuracy: 0.4444\n",
      "Epoch 272/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.4049 - accuracy: 0.4812 - val_loss: 1.5792 - val_accuracy: 0.4236\n",
      "Epoch 273/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4025 - accuracy: 0.4762 - val_loss: 1.4996 - val_accuracy: 0.4398\n",
      "Epoch 274/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.3925 - accuracy: 0.4643 - val_loss: 1.5130 - val_accuracy: 0.4329\n",
      "Epoch 275/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3883 - accuracy: 0.4911 - val_loss: 1.5103 - val_accuracy: 0.4468\n",
      "Epoch 276/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3913 - accuracy: 0.4683 - val_loss: 1.5052 - val_accuracy: 0.4491\n",
      "Epoch 277/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3843 - accuracy: 0.4831 - val_loss: 1.5252 - val_accuracy: 0.4306\n",
      "Epoch 278/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.3956 - accuracy: 0.4702 - val_loss: 1.4720 - val_accuracy: 0.4653\n",
      "Epoch 279/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.3798 - accuracy: 0.4970 - val_loss: 1.4708 - val_accuracy: 0.4676\n",
      "Epoch 280/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3965 - accuracy: 0.4772 - val_loss: 1.4953 - val_accuracy: 0.4514\n",
      "Epoch 281/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3710 - accuracy: 0.4831 - val_loss: 1.5647 - val_accuracy: 0.4213\n",
      "Epoch 282/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.3808 - accuracy: 0.4643 - val_loss: 1.4815 - val_accuracy: 0.4653\n",
      "Epoch 283/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.3598 - accuracy: 0.4831 - val_loss: 1.5224 - val_accuracy: 0.4236\n",
      "Epoch 284/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.3610 - accuracy: 0.4851 - val_loss: 1.4968 - val_accuracy: 0.4398\n",
      "Epoch 285/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.3821 - accuracy: 0.4812 - val_loss: 1.4845 - val_accuracy: 0.4537\n",
      "Epoch 286/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.3869 - accuracy: 0.4861 - val_loss: 1.4884 - val_accuracy: 0.4537\n",
      "Epoch 287/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3604 - accuracy: 0.4911 - val_loss: 1.5060 - val_accuracy: 0.4444\n",
      "Epoch 288/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3421 - accuracy: 0.4851 - val_loss: 1.4956 - val_accuracy: 0.4444\n",
      "Epoch 289/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.3661 - accuracy: 0.5000 - val_loss: 1.5142 - val_accuracy: 0.4375\n",
      "Epoch 290/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.3670 - accuracy: 0.4871 - val_loss: 1.5820 - val_accuracy: 0.4051\n",
      "Epoch 291/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3765 - accuracy: 0.4792 - val_loss: 1.4803 - val_accuracy: 0.4421\n",
      "Epoch 292/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.3543 - accuracy: 0.5129 - val_loss: 1.4871 - val_accuracy: 0.4560\n",
      "Epoch 293/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3489 - accuracy: 0.4812 - val_loss: 1.4879 - val_accuracy: 0.4398\n",
      "Epoch 294/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3572 - accuracy: 0.5030 - val_loss: 1.4757 - val_accuracy: 0.4537\n",
      "Epoch 295/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.3569 - accuracy: 0.4802 - val_loss: 1.4723 - val_accuracy: 0.4653\n",
      "Epoch 296/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3613 - accuracy: 0.4891 - val_loss: 1.4674 - val_accuracy: 0.4745\n",
      "Epoch 297/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3670 - accuracy: 0.5079 - val_loss: 1.4927 - val_accuracy: 0.4560\n",
      "Epoch 298/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3490 - accuracy: 0.5010 - val_loss: 1.4743 - val_accuracy: 0.4514\n",
      "Epoch 299/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3382 - accuracy: 0.5040 - val_loss: 1.4743 - val_accuracy: 0.4537\n",
      "Epoch 300/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3745 - accuracy: 0.4901 - val_loss: 1.4811 - val_accuracy: 0.4421\n",
      "Epoch 301/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3672 - accuracy: 0.4821 - val_loss: 1.4803 - val_accuracy: 0.4491\n",
      "Epoch 302/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3622 - accuracy: 0.4950 - val_loss: 1.4632 - val_accuracy: 0.4583\n",
      "Epoch 303/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3563 - accuracy: 0.4881 - val_loss: 1.4632 - val_accuracy: 0.4537\n",
      "Epoch 304/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3621 - accuracy: 0.4940 - val_loss: 1.4829 - val_accuracy: 0.4468\n",
      "Epoch 305/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3400 - accuracy: 0.4792 - val_loss: 1.5013 - val_accuracy: 0.4375\n",
      "Epoch 306/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3389 - accuracy: 0.5030 - val_loss: 1.4822 - val_accuracy: 0.4444\n",
      "Epoch 307/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.3379 - accuracy: 0.4831 - val_loss: 1.4702 - val_accuracy: 0.4444\n",
      "Epoch 308/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3324 - accuracy: 0.4980 - val_loss: 1.5029 - val_accuracy: 0.4236\n",
      "Epoch 309/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3478 - accuracy: 0.4950 - val_loss: 1.4877 - val_accuracy: 0.4421\n",
      "Epoch 310/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3367 - accuracy: 0.5050 - val_loss: 1.4739 - val_accuracy: 0.4514\n",
      "Epoch 311/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3269 - accuracy: 0.5139 - val_loss: 1.4850 - val_accuracy: 0.4514\n",
      "Epoch 312/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3261 - accuracy: 0.5109 - val_loss: 1.4708 - val_accuracy: 0.4583\n",
      "Epoch 313/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.3333 - accuracy: 0.5089 - val_loss: 1.4743 - val_accuracy: 0.4560\n",
      "Epoch 314/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3442 - accuracy: 0.4940 - val_loss: 1.4780 - val_accuracy: 0.4583\n",
      "Epoch 315/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3369 - accuracy: 0.5030 - val_loss: 1.5035 - val_accuracy: 0.4236\n",
      "Epoch 316/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3138 - accuracy: 0.4911 - val_loss: 1.4586 - val_accuracy: 0.4606\n",
      "Epoch 317/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.3223 - accuracy: 0.5169 - val_loss: 1.4622 - val_accuracy: 0.4583\n",
      "Epoch 318/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3327 - accuracy: 0.5069 - val_loss: 1.4675 - val_accuracy: 0.4491\n",
      "Epoch 319/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.3217 - accuracy: 0.5030 - val_loss: 1.4762 - val_accuracy: 0.4375\n",
      "Epoch 320/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3335 - accuracy: 0.4960 - val_loss: 1.4660 - val_accuracy: 0.4514\n",
      "Epoch 321/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3321 - accuracy: 0.5040 - val_loss: 1.4716 - val_accuracy: 0.4722\n",
      "Epoch 322/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3121 - accuracy: 0.5020 - val_loss: 1.4610 - val_accuracy: 0.4606\n",
      "Epoch 323/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3199 - accuracy: 0.5169 - val_loss: 1.4823 - val_accuracy: 0.4676\n",
      "Epoch 324/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3158 - accuracy: 0.5079 - val_loss: 1.4544 - val_accuracy: 0.4838\n",
      "Epoch 325/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3237 - accuracy: 0.5020 - val_loss: 1.4532 - val_accuracy: 0.4653\n",
      "Epoch 326/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3085 - accuracy: 0.5298 - val_loss: 1.4608 - val_accuracy: 0.4630\n",
      "Epoch 327/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2827 - accuracy: 0.5159 - val_loss: 1.4595 - val_accuracy: 0.4537\n",
      "Epoch 328/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3046 - accuracy: 0.5099 - val_loss: 1.4848 - val_accuracy: 0.4560\n",
      "Epoch 329/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2929 - accuracy: 0.5079 - val_loss: 1.4701 - val_accuracy: 0.4653\n",
      "Epoch 330/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3099 - accuracy: 0.5198 - val_loss: 1.4605 - val_accuracy: 0.4606\n",
      "Epoch 331/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.3164 - accuracy: 0.5208 - val_loss: 1.5039 - val_accuracy: 0.4375\n",
      "Epoch 332/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.3373 - accuracy: 0.4950 - val_loss: 1.4799 - val_accuracy: 0.4653\n",
      "Epoch 333/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2851 - accuracy: 0.5040 - val_loss: 1.4589 - val_accuracy: 0.4583\n",
      "Epoch 334/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3094 - accuracy: 0.5198 - val_loss: 1.4664 - val_accuracy: 0.4630\n",
      "Epoch 335/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3091 - accuracy: 0.5149 - val_loss: 1.4975 - val_accuracy: 0.4491\n",
      "Epoch 336/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3036 - accuracy: 0.5089 - val_loss: 1.4574 - val_accuracy: 0.4491\n",
      "Epoch 337/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3210 - accuracy: 0.5179 - val_loss: 1.5100 - val_accuracy: 0.4282\n",
      "Epoch 338/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3007 - accuracy: 0.5050 - val_loss: 1.4511 - val_accuracy: 0.4606\n",
      "Epoch 339/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2980 - accuracy: 0.5119 - val_loss: 1.4558 - val_accuracy: 0.4468\n",
      "Epoch 340/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3044 - accuracy: 0.4980 - val_loss: 1.4359 - val_accuracy: 0.4606\n",
      "Epoch 341/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2868 - accuracy: 0.5169 - val_loss: 1.5112 - val_accuracy: 0.4213\n",
      "Epoch 342/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3036 - accuracy: 0.5169 - val_loss: 1.4764 - val_accuracy: 0.4583\n",
      "Epoch 343/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.2855 - accuracy: 0.5377 - val_loss: 1.4753 - val_accuracy: 0.4421\n",
      "Epoch 344/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.3005 - accuracy: 0.5000 - val_loss: 1.4993 - val_accuracy: 0.4213\n",
      "Epoch 345/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3054 - accuracy: 0.5198 - val_loss: 1.4824 - val_accuracy: 0.4444\n",
      "Epoch 346/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.2714 - accuracy: 0.5298 - val_loss: 1.4327 - val_accuracy: 0.4792\n",
      "Epoch 347/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2760 - accuracy: 0.5268 - val_loss: 1.4722 - val_accuracy: 0.4537\n",
      "Epoch 348/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2902 - accuracy: 0.5218 - val_loss: 1.4576 - val_accuracy: 0.4491\n",
      "Epoch 349/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2858 - accuracy: 0.5010 - val_loss: 1.4434 - val_accuracy: 0.4699\n",
      "Epoch 350/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2797 - accuracy: 0.5337 - val_loss: 1.4374 - val_accuracy: 0.4560\n",
      "Epoch 351/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.3008 - accuracy: 0.5159 - val_loss: 1.4529 - val_accuracy: 0.4606\n",
      "Epoch 352/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3054 - accuracy: 0.5089 - val_loss: 1.4453 - val_accuracy: 0.4653\n",
      "Epoch 353/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2680 - accuracy: 0.5238 - val_loss: 1.4300 - val_accuracy: 0.4560\n",
      "Epoch 354/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2745 - accuracy: 0.5308 - val_loss: 1.4380 - val_accuracy: 0.4653\n",
      "Epoch 355/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2647 - accuracy: 0.5188 - val_loss: 1.4394 - val_accuracy: 0.4676\n",
      "Epoch 356/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.2508 - accuracy: 0.5288 - val_loss: 1.4707 - val_accuracy: 0.4514\n",
      "Epoch 357/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2685 - accuracy: 0.5268 - val_loss: 1.4862 - val_accuracy: 0.4560\n",
      "Epoch 358/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2540 - accuracy: 0.5278 - val_loss: 1.4307 - val_accuracy: 0.4653\n",
      "Epoch 359/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2510 - accuracy: 0.5337 - val_loss: 1.4590 - val_accuracy: 0.4676\n",
      "Epoch 360/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2511 - accuracy: 0.5298 - val_loss: 1.4442 - val_accuracy: 0.4630\n",
      "Epoch 361/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2467 - accuracy: 0.5387 - val_loss: 1.4734 - val_accuracy: 0.4606\n",
      "Epoch 362/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2629 - accuracy: 0.5298 - val_loss: 1.4264 - val_accuracy: 0.4745\n",
      "Epoch 363/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.2701 - accuracy: 0.5417 - val_loss: 1.4239 - val_accuracy: 0.4769\n",
      "Epoch 364/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.2681 - accuracy: 0.5347 - val_loss: 1.4494 - val_accuracy: 0.4537\n",
      "Epoch 365/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.2721 - accuracy: 0.5268 - val_loss: 1.4547 - val_accuracy: 0.4653\n",
      "Epoch 366/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.2593 - accuracy: 0.5268 - val_loss: 1.4406 - val_accuracy: 0.4699\n",
      "Epoch 367/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.2573 - accuracy: 0.5248 - val_loss: 1.4339 - val_accuracy: 0.4699\n",
      "Epoch 368/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2572 - accuracy: 0.5317 - val_loss: 1.4344 - val_accuracy: 0.4699\n",
      "Epoch 369/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2647 - accuracy: 0.5327 - val_loss: 1.4244 - val_accuracy: 0.4838\n",
      "Epoch 370/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.2530 - accuracy: 0.5456 - val_loss: 1.4441 - val_accuracy: 0.4583\n",
      "Epoch 371/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.2384 - accuracy: 0.5407 - val_loss: 1.4098 - val_accuracy: 0.4792\n",
      "Epoch 372/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2285 - accuracy: 0.5615 - val_loss: 1.4304 - val_accuracy: 0.4838\n",
      "Epoch 373/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2396 - accuracy: 0.5298 - val_loss: 1.4223 - val_accuracy: 0.4699\n",
      "Epoch 374/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2342 - accuracy: 0.5496 - val_loss: 1.4565 - val_accuracy: 0.4722\n",
      "Epoch 375/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2395 - accuracy: 0.5437 - val_loss: 1.4659 - val_accuracy: 0.4676\n",
      "Epoch 376/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2496 - accuracy: 0.5347 - val_loss: 1.4285 - val_accuracy: 0.4745\n",
      "Epoch 377/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2367 - accuracy: 0.5387 - val_loss: 1.4366 - val_accuracy: 0.4606\n",
      "Epoch 378/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2489 - accuracy: 0.5298 - val_loss: 1.4563 - val_accuracy: 0.4583\n",
      "Epoch 379/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2570 - accuracy: 0.5387 - val_loss: 1.4255 - val_accuracy: 0.4630\n",
      "Epoch 380/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2331 - accuracy: 0.5496 - val_loss: 1.4451 - val_accuracy: 0.4653\n",
      "Epoch 381/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.2270 - accuracy: 0.5466 - val_loss: 1.4539 - val_accuracy: 0.4491\n",
      "Epoch 382/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.2553 - accuracy: 0.5258 - val_loss: 1.4550 - val_accuracy: 0.4491\n",
      "Epoch 383/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2367 - accuracy: 0.5556 - val_loss: 1.4864 - val_accuracy: 0.4398\n",
      "Epoch 384/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2204 - accuracy: 0.5575 - val_loss: 1.4412 - val_accuracy: 0.4676\n",
      "Epoch 385/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2450 - accuracy: 0.5446 - val_loss: 1.5097 - val_accuracy: 0.4468\n",
      "Epoch 386/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2349 - accuracy: 0.5298 - val_loss: 1.4255 - val_accuracy: 0.4884\n",
      "Epoch 387/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2599 - accuracy: 0.5367 - val_loss: 1.4472 - val_accuracy: 0.4606\n",
      "Epoch 388/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.2435 - accuracy: 0.5417 - val_loss: 1.4778 - val_accuracy: 0.4537\n",
      "Epoch 389/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2037 - accuracy: 0.5546 - val_loss: 1.4326 - val_accuracy: 0.4745\n",
      "Epoch 390/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2363 - accuracy: 0.5387 - val_loss: 1.4290 - val_accuracy: 0.4722\n",
      "Epoch 391/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.2289 - accuracy: 0.5546 - val_loss: 1.4381 - val_accuracy: 0.4792\n",
      "Epoch 392/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2369 - accuracy: 0.5456 - val_loss: 1.4189 - val_accuracy: 0.4792\n",
      "Epoch 393/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2163 - accuracy: 0.5496 - val_loss: 1.4151 - val_accuracy: 0.4838\n",
      "Epoch 394/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.2420 - accuracy: 0.5427 - val_loss: 1.4233 - val_accuracy: 0.4722\n",
      "Epoch 395/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2336 - accuracy: 0.5427 - val_loss: 1.4194 - val_accuracy: 0.4815\n",
      "Epoch 396/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2315 - accuracy: 0.5317 - val_loss: 1.4140 - val_accuracy: 0.4630\n",
      "Epoch 397/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2269 - accuracy: 0.5456 - val_loss: 1.4026 - val_accuracy: 0.4792\n",
      "Epoch 398/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2364 - accuracy: 0.5387 - val_loss: 1.4899 - val_accuracy: 0.4537\n",
      "Epoch 399/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2314 - accuracy: 0.5476 - val_loss: 1.4494 - val_accuracy: 0.4699\n",
      "Epoch 400/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2147 - accuracy: 0.5625 - val_loss: 1.4233 - val_accuracy: 0.4769\n",
      "Epoch 401/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2052 - accuracy: 0.5536 - val_loss: 1.4295 - val_accuracy: 0.4653\n",
      "Epoch 402/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.1952 - accuracy: 0.5407 - val_loss: 1.4722 - val_accuracy: 0.4606\n",
      "Epoch 403/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2073 - accuracy: 0.5536 - val_loss: 1.4292 - val_accuracy: 0.4769\n",
      "Epoch 404/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2135 - accuracy: 0.5397 - val_loss: 1.4259 - val_accuracy: 0.4676\n",
      "Epoch 405/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2162 - accuracy: 0.5575 - val_loss: 1.4251 - val_accuracy: 0.4769\n",
      "Epoch 406/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.2042 - accuracy: 0.5714 - val_loss: 1.4245 - val_accuracy: 0.4769\n",
      "Epoch 407/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2077 - accuracy: 0.5506 - val_loss: 1.4184 - val_accuracy: 0.4699\n",
      "Epoch 408/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2146 - accuracy: 0.5635 - val_loss: 1.4036 - val_accuracy: 0.4792\n",
      "Epoch 409/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1970 - accuracy: 0.5605 - val_loss: 1.4212 - val_accuracy: 0.4606\n",
      "Epoch 410/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2163 - accuracy: 0.5367 - val_loss: 1.4165 - val_accuracy: 0.4884\n",
      "Epoch 411/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1704 - accuracy: 0.5556 - val_loss: 1.4417 - val_accuracy: 0.4907\n",
      "Epoch 412/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.1994 - accuracy: 0.5526 - val_loss: 1.4246 - val_accuracy: 0.4722\n",
      "Epoch 413/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2083 - accuracy: 0.5417 - val_loss: 1.4365 - val_accuracy: 0.4745\n",
      "Epoch 414/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1836 - accuracy: 0.5625 - val_loss: 1.4249 - val_accuracy: 0.4676\n",
      "Epoch 415/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2133 - accuracy: 0.5347 - val_loss: 1.4142 - val_accuracy: 0.4861\n",
      "Epoch 416/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1974 - accuracy: 0.5704 - val_loss: 1.4069 - val_accuracy: 0.4653\n",
      "Epoch 417/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1808 - accuracy: 0.5734 - val_loss: 1.4186 - val_accuracy: 0.4884\n",
      "Epoch 418/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1901 - accuracy: 0.5575 - val_loss: 1.4020 - val_accuracy: 0.4583\n",
      "Epoch 419/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1918 - accuracy: 0.5585 - val_loss: 1.4082 - val_accuracy: 0.4769\n",
      "Epoch 420/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1972 - accuracy: 0.5704 - val_loss: 1.3906 - val_accuracy: 0.4792\n",
      "Epoch 421/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1897 - accuracy: 0.5714 - val_loss: 1.3976 - val_accuracy: 0.4861\n",
      "Epoch 422/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.1891 - accuracy: 0.5595 - val_loss: 1.4083 - val_accuracy: 0.4745\n",
      "Epoch 423/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1751 - accuracy: 0.5615 - val_loss: 1.4219 - val_accuracy: 0.4606\n",
      "Epoch 424/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1880 - accuracy: 0.5734 - val_loss: 1.4457 - val_accuracy: 0.4583\n",
      "Epoch 425/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1984 - accuracy: 0.5605 - val_loss: 1.4499 - val_accuracy: 0.4722\n",
      "Epoch 426/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1639 - accuracy: 0.5754 - val_loss: 1.4167 - val_accuracy: 0.4884\n",
      "Epoch 427/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1860 - accuracy: 0.5615 - val_loss: 1.3986 - val_accuracy: 0.4699\n",
      "Epoch 428/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1757 - accuracy: 0.5813 - val_loss: 1.4114 - val_accuracy: 0.4815\n",
      "Epoch 429/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1802 - accuracy: 0.5625 - val_loss: 1.4014 - val_accuracy: 0.4931\n",
      "Epoch 430/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1787 - accuracy: 0.5734 - val_loss: 1.4192 - val_accuracy: 0.4745\n",
      "Epoch 431/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1740 - accuracy: 0.5585 - val_loss: 1.4129 - val_accuracy: 0.4722\n",
      "Epoch 432/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1579 - accuracy: 0.5516 - val_loss: 1.3905 - val_accuracy: 0.4792\n",
      "Epoch 433/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1889 - accuracy: 0.5556 - val_loss: 1.4155 - val_accuracy: 0.4954\n",
      "Epoch 434/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1725 - accuracy: 0.5575 - val_loss: 1.3854 - val_accuracy: 0.5000\n",
      "Epoch 435/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1469 - accuracy: 0.5754 - val_loss: 1.4086 - val_accuracy: 0.4861\n",
      "Epoch 436/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.1780 - accuracy: 0.5744 - val_loss: 1.4111 - val_accuracy: 0.4699\n",
      "Epoch 437/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1782 - accuracy: 0.5784 - val_loss: 1.3919 - val_accuracy: 0.4815\n",
      "Epoch 438/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1396 - accuracy: 0.5744 - val_loss: 1.4259 - val_accuracy: 0.4699\n",
      "Epoch 439/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1613 - accuracy: 0.5704 - val_loss: 1.4129 - val_accuracy: 0.4861\n",
      "Epoch 440/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1725 - accuracy: 0.5655 - val_loss: 1.4113 - val_accuracy: 0.4769\n",
      "Epoch 441/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1742 - accuracy: 0.5615 - val_loss: 1.4610 - val_accuracy: 0.4769\n",
      "Epoch 442/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1377 - accuracy: 0.5784 - val_loss: 1.4206 - val_accuracy: 0.4583\n",
      "Epoch 443/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1518 - accuracy: 0.5685 - val_loss: 1.3849 - val_accuracy: 0.4931\n",
      "Epoch 444/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1518 - accuracy: 0.5853 - val_loss: 1.3841 - val_accuracy: 0.4861\n",
      "Epoch 445/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1471 - accuracy: 0.5774 - val_loss: 1.4036 - val_accuracy: 0.4907\n",
      "Epoch 446/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.1649 - accuracy: 0.5873 - val_loss: 1.4338 - val_accuracy: 0.4560\n",
      "Epoch 447/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1618 - accuracy: 0.5863 - val_loss: 1.3844 - val_accuracy: 0.5046\n",
      "Epoch 448/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1538 - accuracy: 0.5724 - val_loss: 1.4014 - val_accuracy: 0.4931\n",
      "Epoch 449/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1482 - accuracy: 0.5665 - val_loss: 1.5176 - val_accuracy: 0.4329\n",
      "Epoch 450/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1554 - accuracy: 0.5754 - val_loss: 1.4313 - val_accuracy: 0.4630\n",
      "Epoch 451/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1625 - accuracy: 0.5744 - val_loss: 1.4423 - val_accuracy: 0.4583\n",
      "Epoch 452/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1615 - accuracy: 0.5804 - val_loss: 1.3931 - val_accuracy: 0.4954\n",
      "Epoch 453/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1426 - accuracy: 0.5913 - val_loss: 1.3908 - val_accuracy: 0.4861\n",
      "Epoch 454/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1399 - accuracy: 0.5913 - val_loss: 1.3902 - val_accuracy: 0.4907\n",
      "Epoch 455/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1566 - accuracy: 0.5675 - val_loss: 1.4093 - val_accuracy: 0.4792\n",
      "Epoch 456/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1378 - accuracy: 0.5972 - val_loss: 1.4293 - val_accuracy: 0.4537\n",
      "Epoch 457/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1545 - accuracy: 0.5704 - val_loss: 1.4146 - val_accuracy: 0.4792\n",
      "Epoch 458/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1328 - accuracy: 0.5744 - val_loss: 1.3966 - val_accuracy: 0.4792\n",
      "Epoch 459/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1651 - accuracy: 0.5694 - val_loss: 1.4053 - val_accuracy: 0.4907\n",
      "Epoch 460/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1443 - accuracy: 0.5754 - val_loss: 1.4106 - val_accuracy: 0.4884\n",
      "Epoch 461/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.1499 - accuracy: 0.5863 - val_loss: 1.3741 - val_accuracy: 0.5023\n",
      "Epoch 462/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.1357 - accuracy: 0.5823 - val_loss: 1.4515 - val_accuracy: 0.4699\n",
      "Epoch 463/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1469 - accuracy: 0.5595 - val_loss: 1.4231 - val_accuracy: 0.4884\n",
      "Epoch 464/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1334 - accuracy: 0.5942 - val_loss: 1.4174 - val_accuracy: 0.4769\n",
      "Epoch 465/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1121 - accuracy: 0.5685 - val_loss: 1.4192 - val_accuracy: 0.4606\n",
      "Epoch 466/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1388 - accuracy: 0.5575 - val_loss: 1.4047 - val_accuracy: 0.4792\n",
      "Epoch 467/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1171 - accuracy: 0.5962 - val_loss: 1.4077 - val_accuracy: 0.4861\n",
      "Epoch 468/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1113 - accuracy: 0.6071 - val_loss: 1.4480 - val_accuracy: 0.4699\n",
      "Epoch 469/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.1485 - accuracy: 0.5843 - val_loss: 1.3709 - val_accuracy: 0.5046\n",
      "Epoch 470/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1220 - accuracy: 0.5913 - val_loss: 1.3817 - val_accuracy: 0.5208\n",
      "Epoch 471/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1255 - accuracy: 0.5903 - val_loss: 1.3968 - val_accuracy: 0.4977\n",
      "Epoch 472/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1529 - accuracy: 0.5823 - val_loss: 1.3809 - val_accuracy: 0.4977\n",
      "Epoch 473/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1247 - accuracy: 0.5903 - val_loss: 1.3921 - val_accuracy: 0.5116\n",
      "Epoch 474/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1529 - accuracy: 0.5734 - val_loss: 1.3884 - val_accuracy: 0.4861\n",
      "Epoch 475/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1215 - accuracy: 0.5754 - val_loss: 1.3757 - val_accuracy: 0.5046\n",
      "Epoch 476/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.0820 - accuracy: 0.6002 - val_loss: 1.4331 - val_accuracy: 0.4792\n",
      "Epoch 477/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1123 - accuracy: 0.6042 - val_loss: 1.3986 - val_accuracy: 0.4884\n",
      "Epoch 478/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1185 - accuracy: 0.5853 - val_loss: 1.4196 - val_accuracy: 0.4653\n",
      "Epoch 479/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1125 - accuracy: 0.5972 - val_loss: 1.4078 - val_accuracy: 0.4815\n",
      "Epoch 480/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1154 - accuracy: 0.5833 - val_loss: 1.3849 - val_accuracy: 0.5000\n",
      "Epoch 481/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1068 - accuracy: 0.5823 - val_loss: 1.4186 - val_accuracy: 0.5000\n",
      "Epoch 482/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1006 - accuracy: 0.6042 - val_loss: 1.3707 - val_accuracy: 0.4745\n",
      "Epoch 483/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.1142 - accuracy: 0.5853 - val_loss: 1.3893 - val_accuracy: 0.4977\n",
      "Epoch 484/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1114 - accuracy: 0.6081 - val_loss: 1.3907 - val_accuracy: 0.4792\n",
      "Epoch 485/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.1136 - accuracy: 0.6101 - val_loss: 1.4078 - val_accuracy: 0.4907\n",
      "Epoch 486/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1155 - accuracy: 0.5665 - val_loss: 1.3786 - val_accuracy: 0.4907\n",
      "Epoch 487/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1001 - accuracy: 0.5823 - val_loss: 1.3778 - val_accuracy: 0.4954\n",
      "Epoch 488/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.0867 - accuracy: 0.5972 - val_loss: 1.4331 - val_accuracy: 0.4977\n",
      "Epoch 489/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1050 - accuracy: 0.6111 - val_loss: 1.3941 - val_accuracy: 0.4792\n",
      "Epoch 490/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0886 - accuracy: 0.6022 - val_loss: 1.4728 - val_accuracy: 0.4699\n",
      "Epoch 491/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1249 - accuracy: 0.5774 - val_loss: 1.4731 - val_accuracy: 0.4444\n",
      "Epoch 492/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1107 - accuracy: 0.5982 - val_loss: 1.4306 - val_accuracy: 0.4815\n",
      "Epoch 493/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1084 - accuracy: 0.6091 - val_loss: 1.3833 - val_accuracy: 0.5093\n",
      "Epoch 494/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1220 - accuracy: 0.6101 - val_loss: 1.3709 - val_accuracy: 0.5139\n",
      "Epoch 495/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0922 - accuracy: 0.5913 - val_loss: 1.3745 - val_accuracy: 0.5023\n",
      "Epoch 496/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.0794 - accuracy: 0.6131 - val_loss: 1.3717 - val_accuracy: 0.5000\n",
      "Epoch 497/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1011 - accuracy: 0.6002 - val_loss: 1.4180 - val_accuracy: 0.4699\n",
      "Epoch 498/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0952 - accuracy: 0.6071 - val_loss: 1.3836 - val_accuracy: 0.4884\n",
      "Epoch 499/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1073 - accuracy: 0.6052 - val_loss: 1.4175 - val_accuracy: 0.4722\n",
      "Epoch 500/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0956 - accuracy: 0.5923 - val_loss: 1.4015 - val_accuracy: 0.4745\n",
      "Epoch 501/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0852 - accuracy: 0.6002 - val_loss: 1.3806 - val_accuracy: 0.4977\n",
      "Epoch 502/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.1058 - accuracy: 0.5744 - val_loss: 1.3787 - val_accuracy: 0.4907\n",
      "Epoch 503/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0895 - accuracy: 0.6062 - val_loss: 1.4252 - val_accuracy: 0.4745\n",
      "Epoch 504/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0967 - accuracy: 0.5833 - val_loss: 1.3784 - val_accuracy: 0.4977\n",
      "Epoch 505/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0949 - accuracy: 0.6052 - val_loss: 1.4263 - val_accuracy: 0.4769\n",
      "Epoch 506/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0890 - accuracy: 0.5982 - val_loss: 1.3832 - val_accuracy: 0.5046\n",
      "Epoch 507/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0855 - accuracy: 0.6091 - val_loss: 1.4019 - val_accuracy: 0.5023\n",
      "Epoch 508/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0931 - accuracy: 0.6121 - val_loss: 1.3667 - val_accuracy: 0.5139\n",
      "Epoch 509/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0667 - accuracy: 0.6081 - val_loss: 1.3725 - val_accuracy: 0.5069\n",
      "Epoch 510/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0717 - accuracy: 0.6032 - val_loss: 1.3970 - val_accuracy: 0.5023\n",
      "Epoch 511/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.0753 - accuracy: 0.6042 - val_loss: 1.4123 - val_accuracy: 0.4745\n",
      "Epoch 512/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0702 - accuracy: 0.6171 - val_loss: 1.3949 - val_accuracy: 0.4792\n",
      "Epoch 513/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0918 - accuracy: 0.5833 - val_loss: 1.3632 - val_accuracy: 0.5139\n",
      "Epoch 514/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0822 - accuracy: 0.6032 - val_loss: 1.3901 - val_accuracy: 0.4884\n",
      "Epoch 515/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0595 - accuracy: 0.6190 - val_loss: 1.4147 - val_accuracy: 0.4931\n",
      "Epoch 516/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0776 - accuracy: 0.6042 - val_loss: 1.3491 - val_accuracy: 0.5093\n",
      "Epoch 517/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0615 - accuracy: 0.6151 - val_loss: 1.3767 - val_accuracy: 0.4815\n",
      "Epoch 518/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.0801 - accuracy: 0.6062 - val_loss: 1.4182 - val_accuracy: 0.4583\n",
      "Epoch 519/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0783 - accuracy: 0.5972 - val_loss: 1.4023 - val_accuracy: 0.4931\n",
      "Epoch 520/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0674 - accuracy: 0.6131 - val_loss: 1.3549 - val_accuracy: 0.4977\n",
      "Epoch 521/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0993 - accuracy: 0.6012 - val_loss: 1.3733 - val_accuracy: 0.5278\n",
      "Epoch 522/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0621 - accuracy: 0.6389 - val_loss: 1.3732 - val_accuracy: 0.5255\n",
      "Epoch 523/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0569 - accuracy: 0.6220 - val_loss: 1.3609 - val_accuracy: 0.5139\n",
      "Epoch 524/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0765 - accuracy: 0.6012 - val_loss: 1.3906 - val_accuracy: 0.4838\n",
      "Epoch 525/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0803 - accuracy: 0.6052 - val_loss: 1.4226 - val_accuracy: 0.4815\n",
      "Epoch 526/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.0592 - accuracy: 0.6062 - val_loss: 1.4056 - val_accuracy: 0.4931\n",
      "Epoch 527/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0707 - accuracy: 0.6161 - val_loss: 1.3489 - val_accuracy: 0.5046\n",
      "Epoch 528/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0722 - accuracy: 0.6131 - val_loss: 1.3753 - val_accuracy: 0.4907\n",
      "Epoch 529/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0457 - accuracy: 0.6121 - val_loss: 1.4076 - val_accuracy: 0.5046\n",
      "Epoch 530/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.0673 - accuracy: 0.5982 - val_loss: 1.3409 - val_accuracy: 0.5116\n",
      "Epoch 531/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0489 - accuracy: 0.6121 - val_loss: 1.3825 - val_accuracy: 0.5093\n",
      "Epoch 532/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0775 - accuracy: 0.6141 - val_loss: 1.3776 - val_accuracy: 0.4954\n",
      "Epoch 533/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0673 - accuracy: 0.6012 - val_loss: 1.3305 - val_accuracy: 0.5278\n",
      "Epoch 534/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0694 - accuracy: 0.6052 - val_loss: 1.3655 - val_accuracy: 0.4954\n",
      "Epoch 535/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0580 - accuracy: 0.6220 - val_loss: 1.4007 - val_accuracy: 0.4861\n",
      "Epoch 536/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0536 - accuracy: 0.5952 - val_loss: 1.3676 - val_accuracy: 0.5023\n",
      "Epoch 537/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 1.0343 - accuracy: 0.6181 - val_loss: 1.3525 - val_accuracy: 0.5185\n",
      "Epoch 538/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.0484 - accuracy: 0.6161 - val_loss: 1.3608 - val_accuracy: 0.5046\n",
      "Epoch 539/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0512 - accuracy: 0.6200 - val_loss: 1.3744 - val_accuracy: 0.4815\n",
      "Epoch 540/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0512 - accuracy: 0.6002 - val_loss: 1.3403 - val_accuracy: 0.5116\n",
      "Epoch 541/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0362 - accuracy: 0.6151 - val_loss: 1.3625 - val_accuracy: 0.5093\n",
      "Epoch 542/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.0701 - accuracy: 0.6141 - val_loss: 1.3608 - val_accuracy: 0.5093\n",
      "Epoch 543/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0461 - accuracy: 0.6121 - val_loss: 1.3901 - val_accuracy: 0.4722\n",
      "Epoch 544/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0403 - accuracy: 0.6171 - val_loss: 1.3887 - val_accuracy: 0.5116\n",
      "Epoch 545/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0422 - accuracy: 0.6240 - val_loss: 1.3535 - val_accuracy: 0.5255\n",
      "Epoch 546/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.0749 - accuracy: 0.6111 - val_loss: 1.3551 - val_accuracy: 0.5116\n",
      "Epoch 547/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0658 - accuracy: 0.6002 - val_loss: 1.3939 - val_accuracy: 0.4815\n",
      "Epoch 548/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0535 - accuracy: 0.6111 - val_loss: 1.3536 - val_accuracy: 0.4861\n",
      "Epoch 549/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0558 - accuracy: 0.6181 - val_loss: 1.3445 - val_accuracy: 0.5185\n",
      "Epoch 550/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0707 - accuracy: 0.6210 - val_loss: 1.4053 - val_accuracy: 0.4722\n",
      "Epoch 551/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.0458 - accuracy: 0.6171 - val_loss: 1.3791 - val_accuracy: 0.4884\n",
      "Epoch 552/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0284 - accuracy: 0.6171 - val_loss: 1.3460 - val_accuracy: 0.5139\n",
      "Epoch 553/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0507 - accuracy: 0.6260 - val_loss: 1.3673 - val_accuracy: 0.5208\n",
      "Epoch 554/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0266 - accuracy: 0.6349 - val_loss: 1.3655 - val_accuracy: 0.4954\n",
      "Epoch 555/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0207 - accuracy: 0.6369 - val_loss: 1.3843 - val_accuracy: 0.4931\n",
      "Epoch 556/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0204 - accuracy: 0.6111 - val_loss: 1.3591 - val_accuracy: 0.4931\n",
      "Epoch 557/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0350 - accuracy: 0.6141 - val_loss: 1.3698 - val_accuracy: 0.4884\n",
      "Epoch 558/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.0018 - accuracy: 0.6349 - val_loss: 1.3599 - val_accuracy: 0.5069\n",
      "Epoch 559/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.0054 - accuracy: 0.6488 - val_loss: 1.3460 - val_accuracy: 0.5185\n",
      "Epoch 560/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0366 - accuracy: 0.6210 - val_loss: 1.4023 - val_accuracy: 0.4931\n",
      "Epoch 561/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0223 - accuracy: 0.6528 - val_loss: 1.3646 - val_accuracy: 0.5093\n",
      "Epoch 562/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0304 - accuracy: 0.6290 - val_loss: 1.3756 - val_accuracy: 0.5046\n",
      "Epoch 563/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0206 - accuracy: 0.6290 - val_loss: 1.3497 - val_accuracy: 0.5046\n",
      "Epoch 564/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0255 - accuracy: 0.6240 - val_loss: 1.3584 - val_accuracy: 0.5185\n",
      "Epoch 565/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0173 - accuracy: 0.6508 - val_loss: 1.3961 - val_accuracy: 0.4861\n",
      "Epoch 566/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0108 - accuracy: 0.6210 - val_loss: 1.3476 - val_accuracy: 0.4977\n",
      "Epoch 567/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0006 - accuracy: 0.6270 - val_loss: 1.3782 - val_accuracy: 0.4838\n",
      "Epoch 568/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0263 - accuracy: 0.6260 - val_loss: 1.3809 - val_accuracy: 0.4722\n",
      "Epoch 569/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0173 - accuracy: 0.6379 - val_loss: 1.3533 - val_accuracy: 0.5208\n",
      "Epoch 570/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0093 - accuracy: 0.6310 - val_loss: 1.3366 - val_accuracy: 0.5208\n",
      "Epoch 571/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.0183 - accuracy: 0.6339 - val_loss: 1.3514 - val_accuracy: 0.5139\n",
      "Epoch 572/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0071 - accuracy: 0.6349 - val_loss: 1.3987 - val_accuracy: 0.5023\n",
      "Epoch 573/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0099 - accuracy: 0.6260 - val_loss: 1.3344 - val_accuracy: 0.5301\n",
      "Epoch 574/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0258 - accuracy: 0.6280 - val_loss: 1.3724 - val_accuracy: 0.5139\n",
      "Epoch 575/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0113 - accuracy: 0.6369 - val_loss: 1.3641 - val_accuracy: 0.4954\n",
      "Epoch 576/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0011 - accuracy: 0.6359 - val_loss: 1.3730 - val_accuracy: 0.4931\n",
      "Epoch 577/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0034 - accuracy: 0.6349 - val_loss: 1.3722 - val_accuracy: 0.4977\n",
      "Epoch 578/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0169 - accuracy: 0.6409 - val_loss: 1.3847 - val_accuracy: 0.5162\n",
      "Epoch 579/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0191 - accuracy: 0.6300 - val_loss: 1.3618 - val_accuracy: 0.5093\n",
      "Epoch 580/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.9986 - accuracy: 0.6458 - val_loss: 1.3840 - val_accuracy: 0.5000\n",
      "Epoch 581/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9983 - accuracy: 0.6250 - val_loss: 1.3774 - val_accuracy: 0.5000\n",
      "Epoch 582/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0438 - accuracy: 0.5992 - val_loss: 1.3732 - val_accuracy: 0.4931\n",
      "Epoch 583/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0141 - accuracy: 0.6310 - val_loss: 1.3472 - val_accuracy: 0.5255\n",
      "Epoch 584/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9880 - accuracy: 0.6429 - val_loss: 1.3263 - val_accuracy: 0.5185\n",
      "Epoch 585/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0168 - accuracy: 0.6369 - val_loss: 1.3325 - val_accuracy: 0.5278\n",
      "Epoch 586/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0090 - accuracy: 0.6270 - val_loss: 1.3579 - val_accuracy: 0.4884\n",
      "Epoch 587/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 1.0081 - accuracy: 0.6230 - val_loss: 1.3624 - val_accuracy: 0.4931\n",
      "Epoch 588/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0207 - accuracy: 0.6339 - val_loss: 1.3297 - val_accuracy: 0.5185\n",
      "Epoch 589/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0216 - accuracy: 0.6210 - val_loss: 1.3569 - val_accuracy: 0.5301\n",
      "Epoch 590/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0187 - accuracy: 0.6419 - val_loss: 1.3654 - val_accuracy: 0.5231\n",
      "Epoch 591/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0213 - accuracy: 0.6310 - val_loss: 1.3812 - val_accuracy: 0.4792\n",
      "Epoch 592/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9951 - accuracy: 0.6488 - val_loss: 1.3623 - val_accuracy: 0.4861\n",
      "Epoch 593/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0189 - accuracy: 0.6389 - val_loss: 1.3356 - val_accuracy: 0.5370\n",
      "Epoch 594/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.9977 - accuracy: 0.6478 - val_loss: 1.3362 - val_accuracy: 0.5255\n",
      "Epoch 595/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0013 - accuracy: 0.6468 - val_loss: 1.3624 - val_accuracy: 0.4954\n",
      "Epoch 596/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0029 - accuracy: 0.6498 - val_loss: 1.3424 - val_accuracy: 0.5208\n",
      "Epoch 597/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9942 - accuracy: 0.6429 - val_loss: 1.3470 - val_accuracy: 0.5069\n",
      "Epoch 598/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0029 - accuracy: 0.6379 - val_loss: 1.3624 - val_accuracy: 0.4838\n",
      "Epoch 599/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0040 - accuracy: 0.6369 - val_loss: 1.3765 - val_accuracy: 0.4954\n",
      "Epoch 600/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9823 - accuracy: 0.6538 - val_loss: 1.3275 - val_accuracy: 0.5208\n",
      "Epoch 601/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9905 - accuracy: 0.6181 - val_loss: 1.3623 - val_accuracy: 0.5046\n",
      "Epoch 602/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9977 - accuracy: 0.6319 - val_loss: 1.3243 - val_accuracy: 0.5208\n",
      "Epoch 603/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9814 - accuracy: 0.6310 - val_loss: 1.3556 - val_accuracy: 0.4954\n",
      "Epoch 604/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.0000 - accuracy: 0.6379 - val_loss: 1.3415 - val_accuracy: 0.5347\n",
      "Epoch 605/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.9959 - accuracy: 0.6528 - val_loss: 1.3568 - val_accuracy: 0.5139\n",
      "Epoch 606/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.9861 - accuracy: 0.6617 - val_loss: 1.3372 - val_accuracy: 0.5208\n",
      "Epoch 607/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9782 - accuracy: 0.6359 - val_loss: 1.3389 - val_accuracy: 0.5231\n",
      "Epoch 608/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9662 - accuracy: 0.6349 - val_loss: 1.3407 - val_accuracy: 0.5255\n",
      "Epoch 609/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9697 - accuracy: 0.6409 - val_loss: 1.4654 - val_accuracy: 0.4722\n",
      "Epoch 610/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0116 - accuracy: 0.6359 - val_loss: 1.3621 - val_accuracy: 0.5185\n",
      "Epoch 611/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.9937 - accuracy: 0.6280 - val_loss: 1.3650 - val_accuracy: 0.5208\n",
      "Epoch 612/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9811 - accuracy: 0.6349 - val_loss: 1.3506 - val_accuracy: 0.4861\n",
      "Epoch 613/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9907 - accuracy: 0.6508 - val_loss: 1.3709 - val_accuracy: 0.5023\n",
      "Epoch 614/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9972 - accuracy: 0.6280 - val_loss: 1.3233 - val_accuracy: 0.5255\n",
      "Epoch 615/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9537 - accuracy: 0.6488 - val_loss: 1.3626 - val_accuracy: 0.5093\n",
      "Epoch 616/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9640 - accuracy: 0.6558 - val_loss: 1.3569 - val_accuracy: 0.5208\n",
      "Epoch 617/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9510 - accuracy: 0.6558 - val_loss: 1.3860 - val_accuracy: 0.4838\n",
      "Epoch 618/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9705 - accuracy: 0.6538 - val_loss: 1.4504 - val_accuracy: 0.4560\n",
      "Epoch 619/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9924 - accuracy: 0.6448 - val_loss: 1.3835 - val_accuracy: 0.5069\n",
      "Epoch 620/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9756 - accuracy: 0.6399 - val_loss: 1.3527 - val_accuracy: 0.5046\n",
      "Epoch 621/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.9656 - accuracy: 0.6389 - val_loss: 1.3639 - val_accuracy: 0.5162\n",
      "Epoch 622/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9742 - accuracy: 0.6488 - val_loss: 1.3340 - val_accuracy: 0.5093\n",
      "Epoch 623/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9379 - accuracy: 0.6538 - val_loss: 1.4171 - val_accuracy: 0.4583\n",
      "Epoch 624/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9795 - accuracy: 0.6448 - val_loss: 1.3606 - val_accuracy: 0.5046\n",
      "Epoch 625/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.9543 - accuracy: 0.6458 - val_loss: 1.3328 - val_accuracy: 0.5116\n",
      "Epoch 626/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9695 - accuracy: 0.6369 - val_loss: 1.3396 - val_accuracy: 0.5162\n",
      "Epoch 627/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9700 - accuracy: 0.6458 - val_loss: 1.3709 - val_accuracy: 0.4861\n",
      "Epoch 628/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9455 - accuracy: 0.6667 - val_loss: 1.3927 - val_accuracy: 0.4653\n",
      "Epoch 629/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.9413 - accuracy: 0.6617 - val_loss: 1.3338 - val_accuracy: 0.5139\n",
      "Epoch 630/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9613 - accuracy: 0.6647 - val_loss: 1.3391 - val_accuracy: 0.5324\n",
      "Epoch 631/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9630 - accuracy: 0.6518 - val_loss: 1.3123 - val_accuracy: 0.5394\n",
      "Epoch 632/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9473 - accuracy: 0.6558 - val_loss: 1.3434 - val_accuracy: 0.5255\n",
      "Epoch 633/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9740 - accuracy: 0.6290 - val_loss: 1.3368 - val_accuracy: 0.5162\n",
      "Epoch 634/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9383 - accuracy: 0.6528 - val_loss: 1.3569 - val_accuracy: 0.4977\n",
      "Epoch 635/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.9499 - accuracy: 0.6637 - val_loss: 1.3127 - val_accuracy: 0.5347\n",
      "Epoch 636/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9263 - accuracy: 0.6577 - val_loss: 1.3122 - val_accuracy: 0.5324\n",
      "Epoch 637/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9304 - accuracy: 0.6786 - val_loss: 1.3807 - val_accuracy: 0.5255\n",
      "Epoch 638/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9433 - accuracy: 0.6687 - val_loss: 1.3600 - val_accuracy: 0.5185\n",
      "Epoch 639/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9691 - accuracy: 0.6359 - val_loss: 1.3525 - val_accuracy: 0.5208\n",
      "Epoch 640/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9587 - accuracy: 0.6528 - val_loss: 1.3329 - val_accuracy: 0.5347\n",
      "Epoch 641/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.9499 - accuracy: 0.6637 - val_loss: 1.3516 - val_accuracy: 0.5255\n",
      "Epoch 642/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9001 - accuracy: 0.6915 - val_loss: 1.3446 - val_accuracy: 0.5046\n",
      "Epoch 643/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9387 - accuracy: 0.6726 - val_loss: 1.3238 - val_accuracy: 0.5069\n",
      "Epoch 644/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9303 - accuracy: 0.6587 - val_loss: 1.3243 - val_accuracy: 0.5278\n",
      "Epoch 645/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9359 - accuracy: 0.6627 - val_loss: 1.3388 - val_accuracy: 0.5255\n",
      "Epoch 646/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.9497 - accuracy: 0.6567 - val_loss: 1.3715 - val_accuracy: 0.5069\n",
      "Epoch 647/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9301 - accuracy: 0.6746 - val_loss: 1.3383 - val_accuracy: 0.5278\n",
      "Epoch 648/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9304 - accuracy: 0.6706 - val_loss: 1.3148 - val_accuracy: 0.5162\n",
      "Epoch 649/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9433 - accuracy: 0.6617 - val_loss: 1.3055 - val_accuracy: 0.5185\n",
      "Epoch 650/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.9097 - accuracy: 0.6786 - val_loss: 1.3264 - val_accuracy: 0.5069\n",
      "Epoch 651/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9563 - accuracy: 0.6607 - val_loss: 1.3236 - val_accuracy: 0.5208\n",
      "Epoch 652/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9371 - accuracy: 0.6677 - val_loss: 1.3190 - val_accuracy: 0.5255\n",
      "Epoch 653/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9484 - accuracy: 0.6597 - val_loss: 1.3107 - val_accuracy: 0.5301\n",
      "Epoch 654/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9360 - accuracy: 0.6577 - val_loss: 1.3484 - val_accuracy: 0.5093\n",
      "Epoch 655/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9275 - accuracy: 0.6647 - val_loss: 1.3010 - val_accuracy: 0.5463\n",
      "Epoch 656/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.9418 - accuracy: 0.6696 - val_loss: 1.3576 - val_accuracy: 0.5046\n",
      "Epoch 657/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9270 - accuracy: 0.6577 - val_loss: 1.3261 - val_accuracy: 0.5370\n",
      "Epoch 658/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9313 - accuracy: 0.6607 - val_loss: 1.3369 - val_accuracy: 0.5231\n",
      "Epoch 659/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.9230 - accuracy: 0.6815 - val_loss: 1.3524 - val_accuracy: 0.5139\n",
      "Epoch 660/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9477 - accuracy: 0.6438 - val_loss: 1.3402 - val_accuracy: 0.5370\n",
      "Epoch 661/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9140 - accuracy: 0.6647 - val_loss: 1.3597 - val_accuracy: 0.5116\n",
      "Epoch 662/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.9231 - accuracy: 0.6746 - val_loss: 1.3219 - val_accuracy: 0.5324\n",
      "Epoch 663/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9125 - accuracy: 0.6865 - val_loss: 1.3117 - val_accuracy: 0.5278\n",
      "Epoch 664/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9195 - accuracy: 0.6687 - val_loss: 1.3601 - val_accuracy: 0.5023\n",
      "Epoch 665/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9205 - accuracy: 0.6726 - val_loss: 1.3457 - val_accuracy: 0.5255\n",
      "Epoch 666/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9193 - accuracy: 0.6617 - val_loss: 1.3750 - val_accuracy: 0.5139\n",
      "Epoch 667/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.9310 - accuracy: 0.6508 - val_loss: 1.2978 - val_accuracy: 0.5278\n",
      "Epoch 668/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9177 - accuracy: 0.6726 - val_loss: 1.3382 - val_accuracy: 0.5255\n",
      "Epoch 669/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9353 - accuracy: 0.6468 - val_loss: 1.3131 - val_accuracy: 0.5417\n",
      "Epoch 670/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8925 - accuracy: 0.6865 - val_loss: 1.3202 - val_accuracy: 0.5162\n",
      "Epoch 671/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9270 - accuracy: 0.6627 - val_loss: 1.3341 - val_accuracy: 0.5208\n",
      "Epoch 672/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9083 - accuracy: 0.6736 - val_loss: 1.3286 - val_accuracy: 0.5347\n",
      "Epoch 673/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9062 - accuracy: 0.6657 - val_loss: 1.3288 - val_accuracy: 0.5116\n",
      "Epoch 674/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8932 - accuracy: 0.6647 - val_loss: 1.2976 - val_accuracy: 0.5486\n",
      "Epoch 675/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8770 - accuracy: 0.6954 - val_loss: 1.3102 - val_accuracy: 0.5394\n",
      "Epoch 676/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8913 - accuracy: 0.6815 - val_loss: 1.3609 - val_accuracy: 0.5093\n",
      "Epoch 677/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8827 - accuracy: 0.6677 - val_loss: 1.3492 - val_accuracy: 0.5370\n",
      "Epoch 678/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8866 - accuracy: 0.6855 - val_loss: 1.3468 - val_accuracy: 0.5301\n",
      "Epoch 679/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8839 - accuracy: 0.6865 - val_loss: 1.3158 - val_accuracy: 0.5347\n",
      "Epoch 680/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.8826 - accuracy: 0.6855 - val_loss: 1.3362 - val_accuracy: 0.5278\n",
      "Epoch 681/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9242 - accuracy: 0.6567 - val_loss: 1.2943 - val_accuracy: 0.5370\n",
      "Epoch 682/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.9104 - accuracy: 0.6865 - val_loss: 1.3539 - val_accuracy: 0.5046\n",
      "Epoch 683/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9136 - accuracy: 0.6845 - val_loss: 1.3307 - val_accuracy: 0.5278\n",
      "Epoch 684/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9025 - accuracy: 0.6716 - val_loss: 1.3231 - val_accuracy: 0.5255\n",
      "Epoch 685/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9014 - accuracy: 0.6647 - val_loss: 1.3151 - val_accuracy: 0.5208\n",
      "Epoch 686/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8847 - accuracy: 0.6895 - val_loss: 1.3203 - val_accuracy: 0.5231\n",
      "Epoch 687/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9178 - accuracy: 0.6696 - val_loss: 1.3171 - val_accuracy: 0.5208\n",
      "Epoch 688/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.9077 - accuracy: 0.6766 - val_loss: 1.3338 - val_accuracy: 0.5000\n",
      "Epoch 689/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8806 - accuracy: 0.6835 - val_loss: 1.3040 - val_accuracy: 0.5231\n",
      "Epoch 690/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8828 - accuracy: 0.6766 - val_loss: 1.3234 - val_accuracy: 0.5255\n",
      "Epoch 691/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.8835 - accuracy: 0.6865 - val_loss: 1.3253 - val_accuracy: 0.5185\n",
      "Epoch 692/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9002 - accuracy: 0.6726 - val_loss: 1.3491 - val_accuracy: 0.5231\n",
      "Epoch 693/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8947 - accuracy: 0.6736 - val_loss: 1.2844 - val_accuracy: 0.5463\n",
      "Epoch 694/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9067 - accuracy: 0.6736 - val_loss: 1.2849 - val_accuracy: 0.5463\n",
      "Epoch 695/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.8633 - accuracy: 0.6855 - val_loss: 1.2886 - val_accuracy: 0.5509\n",
      "Epoch 696/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8924 - accuracy: 0.6796 - val_loss: 1.3420 - val_accuracy: 0.5231\n",
      "Epoch 697/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8636 - accuracy: 0.7004 - val_loss: 1.3085 - val_accuracy: 0.5185\n",
      "Epoch 698/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.8756 - accuracy: 0.6815 - val_loss: 1.3105 - val_accuracy: 0.5255\n",
      "Epoch 699/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9025 - accuracy: 0.6766 - val_loss: 1.3153 - val_accuracy: 0.5301\n",
      "Epoch 700/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8795 - accuracy: 0.6885 - val_loss: 1.2945 - val_accuracy: 0.5417\n",
      "Epoch 701/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8934 - accuracy: 0.6696 - val_loss: 1.3490 - val_accuracy: 0.5255\n",
      "Epoch 702/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8679 - accuracy: 0.6895 - val_loss: 1.3028 - val_accuracy: 0.5532\n",
      "Epoch 703/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8946 - accuracy: 0.6766 - val_loss: 1.3268 - val_accuracy: 0.5231\n",
      "Epoch 704/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.8812 - accuracy: 0.6806 - val_loss: 1.3072 - val_accuracy: 0.5370\n",
      "Epoch 705/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.8905 - accuracy: 0.6865 - val_loss: 1.2859 - val_accuracy: 0.5394\n",
      "Epoch 706/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8880 - accuracy: 0.6696 - val_loss: 1.3194 - val_accuracy: 0.5208\n",
      "Epoch 707/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8912 - accuracy: 0.6736 - val_loss: 1.2944 - val_accuracy: 0.5347\n",
      "Epoch 708/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8683 - accuracy: 0.7044 - val_loss: 1.3714 - val_accuracy: 0.5000\n",
      "Epoch 709/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.8889 - accuracy: 0.6766 - val_loss: 1.3708 - val_accuracy: 0.5231\n",
      "Epoch 710/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.9047 - accuracy: 0.6716 - val_loss: 1.3211 - val_accuracy: 0.5463\n",
      "Epoch 711/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8684 - accuracy: 0.6776 - val_loss: 1.3135 - val_accuracy: 0.5139\n",
      "Epoch 712/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8927 - accuracy: 0.6925 - val_loss: 1.3094 - val_accuracy: 0.5486\n",
      "Epoch 713/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8781 - accuracy: 0.6825 - val_loss: 1.3233 - val_accuracy: 0.5255\n",
      "Epoch 714/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8730 - accuracy: 0.6865 - val_loss: 1.2870 - val_accuracy: 0.5370\n",
      "Epoch 715/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8800 - accuracy: 0.6944 - val_loss: 1.3169 - val_accuracy: 0.5231\n",
      "Epoch 716/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8648 - accuracy: 0.6835 - val_loss: 1.3054 - val_accuracy: 0.5301\n",
      "Epoch 717/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8623 - accuracy: 0.7093 - val_loss: 1.2867 - val_accuracy: 0.5185\n",
      "Epoch 718/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8721 - accuracy: 0.6796 - val_loss: 1.3003 - val_accuracy: 0.5324\n",
      "Epoch 719/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.8739 - accuracy: 0.6905 - val_loss: 1.3145 - val_accuracy: 0.5301\n",
      "Epoch 720/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8822 - accuracy: 0.6677 - val_loss: 1.3160 - val_accuracy: 0.5347\n",
      "Epoch 721/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8967 - accuracy: 0.6766 - val_loss: 1.3389 - val_accuracy: 0.5417\n",
      "Epoch 722/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8610 - accuracy: 0.6925 - val_loss: 1.3136 - val_accuracy: 0.5347\n",
      "Epoch 723/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.8857 - accuracy: 0.6716 - val_loss: 1.3052 - val_accuracy: 0.5486\n",
      "Epoch 724/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8597 - accuracy: 0.6984 - val_loss: 1.3208 - val_accuracy: 0.5324\n",
      "Epoch 725/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8500 - accuracy: 0.7093 - val_loss: 1.2822 - val_accuracy: 0.5417\n",
      "Epoch 726/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8489 - accuracy: 0.7113 - val_loss: 1.3304 - val_accuracy: 0.5463\n",
      "Epoch 727/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8694 - accuracy: 0.6915 - val_loss: 1.3123 - val_accuracy: 0.5301\n",
      "Epoch 728/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.8559 - accuracy: 0.6925 - val_loss: 1.2855 - val_accuracy: 0.5509\n",
      "Epoch 729/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8667 - accuracy: 0.6825 - val_loss: 1.3067 - val_accuracy: 0.5417\n",
      "Epoch 730/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8667 - accuracy: 0.6845 - val_loss: 1.3211 - val_accuracy: 0.5417\n",
      "Epoch 731/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8517 - accuracy: 0.6806 - val_loss: 1.2994 - val_accuracy: 0.5463\n",
      "Epoch 732/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8600 - accuracy: 0.6925 - val_loss: 1.3022 - val_accuracy: 0.5255\n",
      "Epoch 733/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8466 - accuracy: 0.7004 - val_loss: 1.3187 - val_accuracy: 0.5208\n",
      "Epoch 734/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8713 - accuracy: 0.6766 - val_loss: 1.3077 - val_accuracy: 0.5231\n",
      "Epoch 735/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8306 - accuracy: 0.7202 - val_loss: 1.3253 - val_accuracy: 0.5394\n",
      "Epoch 736/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8279 - accuracy: 0.7103 - val_loss: 1.3472 - val_accuracy: 0.5370\n",
      "Epoch 737/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8753 - accuracy: 0.6706 - val_loss: 1.3435 - val_accuracy: 0.5023\n",
      "Epoch 738/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8348 - accuracy: 0.7024 - val_loss: 1.3286 - val_accuracy: 0.5231\n",
      "Epoch 739/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8382 - accuracy: 0.6915 - val_loss: 1.2959 - val_accuracy: 0.5625\n",
      "Epoch 740/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.8562 - accuracy: 0.7054 - val_loss: 1.3307 - val_accuracy: 0.5000\n",
      "Epoch 741/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8469 - accuracy: 0.6994 - val_loss: 1.3309 - val_accuracy: 0.5162\n",
      "Epoch 742/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8554 - accuracy: 0.6796 - val_loss: 1.3070 - val_accuracy: 0.5370\n",
      "Epoch 743/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8504 - accuracy: 0.6964 - val_loss: 1.3275 - val_accuracy: 0.5532\n",
      "Epoch 744/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.8509 - accuracy: 0.6766 - val_loss: 1.3394 - val_accuracy: 0.5162\n",
      "Epoch 745/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8399 - accuracy: 0.7054 - val_loss: 1.3114 - val_accuracy: 0.5324\n",
      "Epoch 746/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8300 - accuracy: 0.7083 - val_loss: 1.2964 - val_accuracy: 0.5579\n",
      "Epoch 747/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8187 - accuracy: 0.7044 - val_loss: 1.3561 - val_accuracy: 0.5093\n",
      "Epoch 748/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8271 - accuracy: 0.7123 - val_loss: 1.3080 - val_accuracy: 0.5486\n",
      "Epoch 749/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8475 - accuracy: 0.6905 - val_loss: 1.3384 - val_accuracy: 0.5509\n",
      "Epoch 750/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8492 - accuracy: 0.6845 - val_loss: 1.3208 - val_accuracy: 0.5463\n",
      "Epoch 751/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8209 - accuracy: 0.7173 - val_loss: 1.3318 - val_accuracy: 0.5069\n",
      "Epoch 752/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8162 - accuracy: 0.7133 - val_loss: 1.3550 - val_accuracy: 0.5116\n",
      "Epoch 753/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.8617 - accuracy: 0.6954 - val_loss: 1.2716 - val_accuracy: 0.5394\n",
      "Epoch 754/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.8217 - accuracy: 0.7063 - val_loss: 1.3107 - val_accuracy: 0.5556\n",
      "Epoch 755/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8140 - accuracy: 0.7232 - val_loss: 1.2955 - val_accuracy: 0.5394\n",
      "Epoch 756/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8542 - accuracy: 0.6855 - val_loss: 1.3046 - val_accuracy: 0.5509\n",
      "Epoch 757/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8468 - accuracy: 0.7024 - val_loss: 1.3102 - val_accuracy: 0.5324\n",
      "Epoch 758/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8292 - accuracy: 0.7034 - val_loss: 1.2879 - val_accuracy: 0.5741\n",
      "Epoch 759/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8421 - accuracy: 0.7054 - val_loss: 1.2809 - val_accuracy: 0.5347\n",
      "Epoch 760/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.8372 - accuracy: 0.7054 - val_loss: 1.3113 - val_accuracy: 0.5486\n",
      "Epoch 761/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8066 - accuracy: 0.7103 - val_loss: 1.3080 - val_accuracy: 0.5231\n",
      "Epoch 762/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8227 - accuracy: 0.6935 - val_loss: 1.3724 - val_accuracy: 0.4838\n",
      "Epoch 763/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8262 - accuracy: 0.7004 - val_loss: 1.3260 - val_accuracy: 0.5208\n",
      "Epoch 764/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8200 - accuracy: 0.7093 - val_loss: 1.2854 - val_accuracy: 0.5486\n",
      "Epoch 765/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8251 - accuracy: 0.7034 - val_loss: 1.3604 - val_accuracy: 0.5231\n",
      "Epoch 766/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8309 - accuracy: 0.7014 - val_loss: 1.2851 - val_accuracy: 0.5394\n",
      "Epoch 767/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.8193 - accuracy: 0.7014 - val_loss: 1.3326 - val_accuracy: 0.5440\n",
      "Epoch 768/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8533 - accuracy: 0.7113 - val_loss: 1.3193 - val_accuracy: 0.5278\n",
      "Epoch 769/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8174 - accuracy: 0.7024 - val_loss: 1.2877 - val_accuracy: 0.5486\n",
      "Epoch 770/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8131 - accuracy: 0.7093 - val_loss: 1.2770 - val_accuracy: 0.5625\n",
      "Epoch 771/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8407 - accuracy: 0.6855 - val_loss: 1.3151 - val_accuracy: 0.5556\n",
      "Epoch 772/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8424 - accuracy: 0.6974 - val_loss: 1.3324 - val_accuracy: 0.5255\n",
      "Epoch 773/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8380 - accuracy: 0.7054 - val_loss: 1.3152 - val_accuracy: 0.5231\n",
      "Epoch 774/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8026 - accuracy: 0.7183 - val_loss: 1.3060 - val_accuracy: 0.5671\n",
      "Epoch 775/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8200 - accuracy: 0.7044 - val_loss: 1.3353 - val_accuracy: 0.5231\n",
      "Epoch 776/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8113 - accuracy: 0.7173 - val_loss: 1.2889 - val_accuracy: 0.5509\n",
      "Epoch 777/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8305 - accuracy: 0.7093 - val_loss: 1.3074 - val_accuracy: 0.5440\n",
      "Epoch 778/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8055 - accuracy: 0.6935 - val_loss: 1.2761 - val_accuracy: 0.5486\n",
      "Epoch 779/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8085 - accuracy: 0.7212 - val_loss: 1.2874 - val_accuracy: 0.5417\n",
      "Epoch 780/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.8132 - accuracy: 0.7163 - val_loss: 1.3387 - val_accuracy: 0.5162\n",
      "Epoch 781/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7934 - accuracy: 0.7192 - val_loss: 1.3627 - val_accuracy: 0.5069\n",
      "Epoch 782/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8064 - accuracy: 0.7222 - val_loss: 1.3452 - val_accuracy: 0.5440\n",
      "Epoch 783/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7944 - accuracy: 0.7312 - val_loss: 1.3201 - val_accuracy: 0.5231\n",
      "Epoch 784/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7906 - accuracy: 0.7192 - val_loss: 1.3083 - val_accuracy: 0.5671\n",
      "Epoch 785/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.7888 - accuracy: 0.7173 - val_loss: 1.2991 - val_accuracy: 0.5394\n",
      "Epoch 786/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8023 - accuracy: 0.7272 - val_loss: 1.2938 - val_accuracy: 0.5301\n",
      "Epoch 787/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8191 - accuracy: 0.7063 - val_loss: 1.3217 - val_accuracy: 0.5231\n",
      "Epoch 788/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8222 - accuracy: 0.7123 - val_loss: 1.3099 - val_accuracy: 0.5625\n",
      "Epoch 789/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7876 - accuracy: 0.7232 - val_loss: 1.2926 - val_accuracy: 0.5625\n",
      "Epoch 790/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.7999 - accuracy: 0.7262 - val_loss: 1.2882 - val_accuracy: 0.5579\n",
      "Epoch 791/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7820 - accuracy: 0.7103 - val_loss: 1.3472 - val_accuracy: 0.5162\n",
      "Epoch 792/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7904 - accuracy: 0.7252 - val_loss: 1.3013 - val_accuracy: 0.5532\n",
      "Epoch 793/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.8030 - accuracy: 0.7183 - val_loss: 1.3402 - val_accuracy: 0.5324\n",
      "Epoch 794/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8084 - accuracy: 0.6925 - val_loss: 1.3071 - val_accuracy: 0.5231\n",
      "Epoch 795/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.8171 - accuracy: 0.7123 - val_loss: 1.3449 - val_accuracy: 0.5208\n",
      "Epoch 796/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8092 - accuracy: 0.7044 - val_loss: 1.3078 - val_accuracy: 0.5394\n",
      "Epoch 797/1000\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.8064 - accuracy: 0.7173 - val_loss: 1.2804 - val_accuracy: 0.5417\n",
      "Epoch 798/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8022 - accuracy: 0.7163 - val_loss: 1.3100 - val_accuracy: 0.5301\n",
      "Epoch 799/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7943 - accuracy: 0.7222 - val_loss: 1.2964 - val_accuracy: 0.5324\n",
      "Epoch 800/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.7882 - accuracy: 0.7192 - val_loss: 1.2810 - val_accuracy: 0.5370\n",
      "Epoch 801/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7842 - accuracy: 0.7381 - val_loss: 1.2657 - val_accuracy: 0.5648\n",
      "Epoch 802/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7800 - accuracy: 0.7034 - val_loss: 1.2774 - val_accuracy: 0.5532\n",
      "Epoch 803/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7964 - accuracy: 0.6984 - val_loss: 1.2715 - val_accuracy: 0.5579\n",
      "Epoch 804/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.7883 - accuracy: 0.7133 - val_loss: 1.2934 - val_accuracy: 0.5278\n",
      "Epoch 805/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7845 - accuracy: 0.7282 - val_loss: 1.2935 - val_accuracy: 0.5440\n",
      "Epoch 806/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8111 - accuracy: 0.7014 - val_loss: 1.2812 - val_accuracy: 0.5347\n",
      "Epoch 807/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7713 - accuracy: 0.7292 - val_loss: 1.3172 - val_accuracy: 0.5301\n",
      "Epoch 808/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7738 - accuracy: 0.7252 - val_loss: 1.3207 - val_accuracy: 0.5231\n",
      "Epoch 809/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8048 - accuracy: 0.7163 - val_loss: 1.2958 - val_accuracy: 0.5556\n",
      "Epoch 810/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7739 - accuracy: 0.7153 - val_loss: 1.3038 - val_accuracy: 0.5440\n",
      "Epoch 811/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7775 - accuracy: 0.7341 - val_loss: 1.3253 - val_accuracy: 0.5532\n",
      "Epoch 812/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8031 - accuracy: 0.7063 - val_loss: 1.3160 - val_accuracy: 0.5486\n",
      "Epoch 813/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7765 - accuracy: 0.7153 - val_loss: 1.2955 - val_accuracy: 0.5509\n",
      "Epoch 814/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7733 - accuracy: 0.7192 - val_loss: 1.3080 - val_accuracy: 0.5440\n",
      "Epoch 815/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.7871 - accuracy: 0.7123 - val_loss: 1.3035 - val_accuracy: 0.5394\n",
      "Epoch 816/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7773 - accuracy: 0.7262 - val_loss: 1.3107 - val_accuracy: 0.5648\n",
      "Epoch 817/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.7995 - accuracy: 0.7093 - val_loss: 1.2914 - val_accuracy: 0.5347\n",
      "Epoch 818/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7653 - accuracy: 0.7302 - val_loss: 1.2845 - val_accuracy: 0.5463\n",
      "Epoch 819/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7958 - accuracy: 0.7232 - val_loss: 1.2953 - val_accuracy: 0.5440\n",
      "Epoch 820/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7712 - accuracy: 0.7252 - val_loss: 1.3381 - val_accuracy: 0.5231\n",
      "Epoch 821/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7822 - accuracy: 0.7292 - val_loss: 1.2742 - val_accuracy: 0.5602\n",
      "Epoch 822/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7652 - accuracy: 0.7242 - val_loss: 1.2779 - val_accuracy: 0.5347\n",
      "Epoch 823/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7737 - accuracy: 0.7331 - val_loss: 1.3207 - val_accuracy: 0.5347\n",
      "Epoch 824/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7902 - accuracy: 0.7242 - val_loss: 1.3357 - val_accuracy: 0.5162\n",
      "Epoch 825/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7551 - accuracy: 0.7331 - val_loss: 1.2845 - val_accuracy: 0.5324\n",
      "Epoch 826/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7857 - accuracy: 0.7163 - val_loss: 1.3320 - val_accuracy: 0.5324\n",
      "Epoch 827/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7541 - accuracy: 0.7232 - val_loss: 1.3072 - val_accuracy: 0.5579\n",
      "Epoch 828/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7821 - accuracy: 0.7153 - val_loss: 1.2756 - val_accuracy: 0.5602\n",
      "Epoch 829/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7811 - accuracy: 0.7153 - val_loss: 1.2740 - val_accuracy: 0.5625\n",
      "Epoch 830/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7622 - accuracy: 0.7262 - val_loss: 1.3082 - val_accuracy: 0.5324\n",
      "Epoch 831/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7608 - accuracy: 0.7302 - val_loss: 1.3318 - val_accuracy: 0.5347\n",
      "Epoch 832/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.7674 - accuracy: 0.7361 - val_loss: 1.2953 - val_accuracy: 0.5440\n",
      "Epoch 833/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7511 - accuracy: 0.7341 - val_loss: 1.3018 - val_accuracy: 0.5394\n",
      "Epoch 834/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7718 - accuracy: 0.7371 - val_loss: 1.2961 - val_accuracy: 0.5324\n",
      "Epoch 835/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7688 - accuracy: 0.7173 - val_loss: 1.3009 - val_accuracy: 0.5347\n",
      "Epoch 836/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7635 - accuracy: 0.7302 - val_loss: 1.2788 - val_accuracy: 0.5509\n",
      "Epoch 837/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.7598 - accuracy: 0.7222 - val_loss: 1.2688 - val_accuracy: 0.5579\n",
      "Epoch 838/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7433 - accuracy: 0.7321 - val_loss: 1.3050 - val_accuracy: 0.5602\n",
      "Epoch 839/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7372 - accuracy: 0.7391 - val_loss: 1.2903 - val_accuracy: 0.5417\n",
      "Epoch 840/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7367 - accuracy: 0.7480 - val_loss: 1.2943 - val_accuracy: 0.5509\n",
      "Epoch 841/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7384 - accuracy: 0.7460 - val_loss: 1.3020 - val_accuracy: 0.5556\n",
      "Epoch 842/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.7545 - accuracy: 0.7242 - val_loss: 1.3043 - val_accuracy: 0.5602\n",
      "Epoch 843/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7571 - accuracy: 0.7371 - val_loss: 1.2871 - val_accuracy: 0.5579\n",
      "Epoch 844/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7588 - accuracy: 0.7401 - val_loss: 1.2710 - val_accuracy: 0.5648\n",
      "Epoch 845/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7551 - accuracy: 0.7520 - val_loss: 1.2678 - val_accuracy: 0.5532\n",
      "Epoch 846/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.7546 - accuracy: 0.7341 - val_loss: 1.3320 - val_accuracy: 0.5278\n",
      "Epoch 847/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7610 - accuracy: 0.7361 - val_loss: 1.2869 - val_accuracy: 0.5556\n",
      "Epoch 848/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.7573 - accuracy: 0.7302 - val_loss: 1.2769 - val_accuracy: 0.5602\n",
      "Epoch 849/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7307 - accuracy: 0.7391 - val_loss: 1.3486 - val_accuracy: 0.5532\n",
      "Epoch 850/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7319 - accuracy: 0.7381 - val_loss: 1.2718 - val_accuracy: 0.5648\n",
      "Epoch 851/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7529 - accuracy: 0.7470 - val_loss: 1.3291 - val_accuracy: 0.5440\n",
      "Epoch 852/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.7497 - accuracy: 0.7292 - val_loss: 1.2766 - val_accuracy: 0.5440\n",
      "Epoch 853/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7546 - accuracy: 0.7381 - val_loss: 1.2984 - val_accuracy: 0.5579\n",
      "Epoch 854/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7742 - accuracy: 0.7331 - val_loss: 1.2922 - val_accuracy: 0.5648\n",
      "Epoch 855/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7508 - accuracy: 0.7371 - val_loss: 1.2731 - val_accuracy: 0.5532\n",
      "Epoch 856/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7502 - accuracy: 0.7371 - val_loss: 1.2895 - val_accuracy: 0.5509\n",
      "Epoch 857/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7570 - accuracy: 0.7381 - val_loss: 1.3093 - val_accuracy: 0.5324\n",
      "Epoch 858/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7503 - accuracy: 0.7421 - val_loss: 1.2710 - val_accuracy: 0.5602\n",
      "Epoch 859/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7754 - accuracy: 0.7153 - val_loss: 1.3223 - val_accuracy: 0.5440\n",
      "Epoch 860/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7216 - accuracy: 0.7510 - val_loss: 1.3046 - val_accuracy: 0.5417\n",
      "Epoch 861/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7354 - accuracy: 0.7321 - val_loss: 1.2743 - val_accuracy: 0.5648\n",
      "Epoch 862/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.7236 - accuracy: 0.7371 - val_loss: 1.3039 - val_accuracy: 0.5394\n",
      "Epoch 863/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7292 - accuracy: 0.7550 - val_loss: 1.3217 - val_accuracy: 0.5394\n",
      "Epoch 864/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7357 - accuracy: 0.7282 - val_loss: 1.2956 - val_accuracy: 0.5602\n",
      "Epoch 865/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7301 - accuracy: 0.7351 - val_loss: 1.2677 - val_accuracy: 0.5463\n",
      "Epoch 866/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7454 - accuracy: 0.7153 - val_loss: 1.3024 - val_accuracy: 0.5625\n",
      "Epoch 867/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7394 - accuracy: 0.7361 - val_loss: 1.2734 - val_accuracy: 0.5694\n",
      "Epoch 868/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7390 - accuracy: 0.7401 - val_loss: 1.2729 - val_accuracy: 0.5694\n",
      "Epoch 869/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7447 - accuracy: 0.7460 - val_loss: 1.2886 - val_accuracy: 0.5417\n",
      "Epoch 870/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7293 - accuracy: 0.7470 - val_loss: 1.2724 - val_accuracy: 0.5694\n",
      "Epoch 871/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7112 - accuracy: 0.7450 - val_loss: 1.2918 - val_accuracy: 0.5347\n",
      "Epoch 872/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7612 - accuracy: 0.7262 - val_loss: 1.2791 - val_accuracy: 0.5509\n",
      "Epoch 873/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7356 - accuracy: 0.7351 - val_loss: 1.2646 - val_accuracy: 0.5741\n",
      "Epoch 874/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7185 - accuracy: 0.7520 - val_loss: 1.3071 - val_accuracy: 0.5532\n",
      "Epoch 875/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6974 - accuracy: 0.7480 - val_loss: 1.2727 - val_accuracy: 0.5556\n",
      "Epoch 876/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7306 - accuracy: 0.7351 - val_loss: 1.2899 - val_accuracy: 0.5486\n",
      "Epoch 877/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7251 - accuracy: 0.7232 - val_loss: 1.3063 - val_accuracy: 0.5556\n",
      "Epoch 878/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7474 - accuracy: 0.7321 - val_loss: 1.2834 - val_accuracy: 0.5625\n",
      "Epoch 879/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6983 - accuracy: 0.7450 - val_loss: 1.2890 - val_accuracy: 0.5394\n",
      "Epoch 880/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.7309 - accuracy: 0.7331 - val_loss: 1.2721 - val_accuracy: 0.5810\n",
      "Epoch 881/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7409 - accuracy: 0.7302 - val_loss: 1.2749 - val_accuracy: 0.5417\n",
      "Epoch 882/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7068 - accuracy: 0.7450 - val_loss: 1.3020 - val_accuracy: 0.5579\n",
      "Epoch 883/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7481 - accuracy: 0.7252 - val_loss: 1.3016 - val_accuracy: 0.5648\n",
      "Epoch 884/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7066 - accuracy: 0.7490 - val_loss: 1.2907 - val_accuracy: 0.5579\n",
      "Epoch 885/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.6930 - accuracy: 0.7540 - val_loss: 1.3564 - val_accuracy: 0.5417\n",
      "Epoch 886/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7107 - accuracy: 0.7560 - val_loss: 1.2631 - val_accuracy: 0.5532\n",
      "Epoch 887/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7183 - accuracy: 0.7262 - val_loss: 1.2642 - val_accuracy: 0.5625\n",
      "Epoch 888/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7201 - accuracy: 0.7381 - val_loss: 1.2946 - val_accuracy: 0.5625\n",
      "Epoch 889/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.7100 - accuracy: 0.7440 - val_loss: 1.3276 - val_accuracy: 0.5394\n",
      "Epoch 890/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6946 - accuracy: 0.7540 - val_loss: 1.2735 - val_accuracy: 0.5556\n",
      "Epoch 891/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7038 - accuracy: 0.7480 - val_loss: 1.3261 - val_accuracy: 0.5486\n",
      "Epoch 892/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.7082 - accuracy: 0.7500 - val_loss: 1.2825 - val_accuracy: 0.5579\n",
      "Epoch 893/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7312 - accuracy: 0.7401 - val_loss: 1.2981 - val_accuracy: 0.5625\n",
      "Epoch 894/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7249 - accuracy: 0.7440 - val_loss: 1.2923 - val_accuracy: 0.5417\n",
      "Epoch 895/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7474 - accuracy: 0.7361 - val_loss: 1.2538 - val_accuracy: 0.5694\n",
      "Epoch 896/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.7164 - accuracy: 0.7470 - val_loss: 1.2414 - val_accuracy: 0.5764\n",
      "Epoch 897/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7132 - accuracy: 0.7401 - val_loss: 1.2977 - val_accuracy: 0.5417\n",
      "Epoch 898/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6905 - accuracy: 0.7688 - val_loss: 1.3072 - val_accuracy: 0.5579\n",
      "Epoch 899/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7220 - accuracy: 0.7431 - val_loss: 1.2804 - val_accuracy: 0.5556\n",
      "Epoch 900/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.6987 - accuracy: 0.7540 - val_loss: 1.2872 - val_accuracy: 0.5648\n",
      "Epoch 901/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7413 - accuracy: 0.7252 - val_loss: 1.3035 - val_accuracy: 0.5347\n",
      "Epoch 902/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6764 - accuracy: 0.7649 - val_loss: 1.3047 - val_accuracy: 0.5625\n",
      "Epoch 903/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7114 - accuracy: 0.7450 - val_loss: 1.3215 - val_accuracy: 0.5532\n",
      "Epoch 904/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6850 - accuracy: 0.7579 - val_loss: 1.3006 - val_accuracy: 0.5486\n",
      "Epoch 905/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7249 - accuracy: 0.7421 - val_loss: 1.2960 - val_accuracy: 0.5509\n",
      "Epoch 906/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7130 - accuracy: 0.7510 - val_loss: 1.3000 - val_accuracy: 0.5463\n",
      "Epoch 907/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7027 - accuracy: 0.7550 - val_loss: 1.3423 - val_accuracy: 0.5347\n",
      "Epoch 908/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7134 - accuracy: 0.7520 - val_loss: 1.2609 - val_accuracy: 0.5648\n",
      "Epoch 909/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.6955 - accuracy: 0.7510 - val_loss: 1.2899 - val_accuracy: 0.5741\n",
      "Epoch 910/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7242 - accuracy: 0.7272 - val_loss: 1.3435 - val_accuracy: 0.5347\n",
      "Epoch 911/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6649 - accuracy: 0.7619 - val_loss: 1.2624 - val_accuracy: 0.5671\n",
      "Epoch 912/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.7490 - val_loss: 1.2870 - val_accuracy: 0.5787\n",
      "Epoch 913/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.7059 - accuracy: 0.7540 - val_loss: 1.3133 - val_accuracy: 0.5417\n",
      "Epoch 914/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6959 - accuracy: 0.7550 - val_loss: 1.3213 - val_accuracy: 0.5463\n",
      "Epoch 915/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6857 - accuracy: 0.7599 - val_loss: 1.2759 - val_accuracy: 0.5648\n",
      "Epoch 916/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7102 - accuracy: 0.7550 - val_loss: 1.3321 - val_accuracy: 0.5532\n",
      "Epoch 917/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7061 - accuracy: 0.7440 - val_loss: 1.2798 - val_accuracy: 0.5764\n",
      "Epoch 918/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.6945 - accuracy: 0.7530 - val_loss: 1.2882 - val_accuracy: 0.5394\n",
      "Epoch 919/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6885 - accuracy: 0.7450 - val_loss: 1.3375 - val_accuracy: 0.5278\n",
      "Epoch 920/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6949 - accuracy: 0.7490 - val_loss: 1.2925 - val_accuracy: 0.5486\n",
      "Epoch 921/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6783 - accuracy: 0.7599 - val_loss: 1.3294 - val_accuracy: 0.5440\n",
      "Epoch 922/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.6848 - accuracy: 0.7609 - val_loss: 1.2460 - val_accuracy: 0.5718\n",
      "Epoch 923/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6733 - accuracy: 0.7579 - val_loss: 1.2649 - val_accuracy: 0.5741\n",
      "Epoch 924/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6709 - accuracy: 0.7669 - val_loss: 1.2944 - val_accuracy: 0.5556\n",
      "Epoch 925/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6999 - accuracy: 0.7560 - val_loss: 1.2662 - val_accuracy: 0.5602\n",
      "Epoch 926/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.6826 - accuracy: 0.7738 - val_loss: 1.2785 - val_accuracy: 0.5579\n",
      "Epoch 927/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6821 - accuracy: 0.7550 - val_loss: 1.2883 - val_accuracy: 0.5625\n",
      "Epoch 928/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7117 - accuracy: 0.7480 - val_loss: 1.2967 - val_accuracy: 0.5486\n",
      "Epoch 929/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6717 - accuracy: 0.7698 - val_loss: 1.2901 - val_accuracy: 0.5532\n",
      "Epoch 930/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6737 - accuracy: 0.7440 - val_loss: 1.2877 - val_accuracy: 0.5810\n",
      "Epoch 931/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.6780 - accuracy: 0.7490 - val_loss: 1.2602 - val_accuracy: 0.5741\n",
      "Epoch 932/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6696 - accuracy: 0.7619 - val_loss: 1.3618 - val_accuracy: 0.5671\n",
      "Epoch 933/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6790 - accuracy: 0.7569 - val_loss: 1.2890 - val_accuracy: 0.5856\n",
      "Epoch 934/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6869 - accuracy: 0.7569 - val_loss: 1.2950 - val_accuracy: 0.5324\n",
      "Epoch 935/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6820 - accuracy: 0.7540 - val_loss: 1.3197 - val_accuracy: 0.5440\n",
      "Epoch 936/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6825 - accuracy: 0.7520 - val_loss: 1.2751 - val_accuracy: 0.5625\n",
      "Epoch 937/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6619 - accuracy: 0.7778 - val_loss: 1.2923 - val_accuracy: 0.5602\n",
      "Epoch 938/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6673 - accuracy: 0.7550 - val_loss: 1.3101 - val_accuracy: 0.5417\n",
      "Epoch 939/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7144 - accuracy: 0.7431 - val_loss: 1.2762 - val_accuracy: 0.5532\n",
      "Epoch 940/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.6967 - accuracy: 0.7540 - val_loss: 1.2713 - val_accuracy: 0.5833\n",
      "Epoch 941/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6548 - accuracy: 0.7768 - val_loss: 1.2540 - val_accuracy: 0.5671\n",
      "Epoch 942/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6599 - accuracy: 0.7857 - val_loss: 1.3164 - val_accuracy: 0.5625\n",
      "Epoch 943/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.7111 - accuracy: 0.7629 - val_loss: 1.3275 - val_accuracy: 0.5602\n",
      "Epoch 944/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6953 - accuracy: 0.7520 - val_loss: 1.3468 - val_accuracy: 0.5417\n",
      "Epoch 945/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6952 - accuracy: 0.7450 - val_loss: 1.2870 - val_accuracy: 0.5625\n",
      "Epoch 946/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.7024 - accuracy: 0.7510 - val_loss: 1.2744 - val_accuracy: 0.5556\n",
      "Epoch 947/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6593 - accuracy: 0.7540 - val_loss: 1.2691 - val_accuracy: 0.5810\n",
      "Epoch 948/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6601 - accuracy: 0.7629 - val_loss: 1.3430 - val_accuracy: 0.5417\n",
      "Epoch 949/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6761 - accuracy: 0.7619 - val_loss: 1.3368 - val_accuracy: 0.5648\n",
      "Epoch 950/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6718 - accuracy: 0.7778 - val_loss: 1.2945 - val_accuracy: 0.5532\n",
      "Epoch 951/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6572 - accuracy: 0.7609 - val_loss: 1.3017 - val_accuracy: 0.5579\n",
      "Epoch 952/1000\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.6476 - accuracy: 0.7917 - val_loss: 1.2807 - val_accuracy: 0.5671\n",
      "Epoch 953/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6722 - accuracy: 0.7550 - val_loss: 1.3069 - val_accuracy: 0.5556\n",
      "Epoch 954/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6889 - accuracy: 0.7619 - val_loss: 1.2784 - val_accuracy: 0.5718\n",
      "Epoch 955/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.6503 - accuracy: 0.7589 - val_loss: 1.2682 - val_accuracy: 0.5694\n",
      "Epoch 956/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6917 - accuracy: 0.7569 - val_loss: 1.2971 - val_accuracy: 0.5579\n",
      "Epoch 957/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6509 - accuracy: 0.7679 - val_loss: 1.2546 - val_accuracy: 0.5787\n",
      "Epoch 958/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6348 - accuracy: 0.7857 - val_loss: 1.2581 - val_accuracy: 0.5764\n",
      "Epoch 959/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6851 - accuracy: 0.7540 - val_loss: 1.3193 - val_accuracy: 0.5347\n",
      "Epoch 960/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6351 - accuracy: 0.7887 - val_loss: 1.2685 - val_accuracy: 0.5648\n",
      "Epoch 961/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6484 - accuracy: 0.7758 - val_loss: 1.2974 - val_accuracy: 0.5463\n",
      "Epoch 962/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6883 - accuracy: 0.7708 - val_loss: 1.2880 - val_accuracy: 0.5486\n",
      "Epoch 963/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6675 - accuracy: 0.7470 - val_loss: 1.2904 - val_accuracy: 0.5694\n",
      "Epoch 964/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6598 - accuracy: 0.7589 - val_loss: 1.2961 - val_accuracy: 0.5486\n",
      "Epoch 965/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6644 - accuracy: 0.7639 - val_loss: 1.2721 - val_accuracy: 0.5694\n",
      "Epoch 966/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6534 - accuracy: 0.7540 - val_loss: 1.2911 - val_accuracy: 0.5440\n",
      "Epoch 967/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6767 - accuracy: 0.7639 - val_loss: 1.2684 - val_accuracy: 0.5532\n",
      "Epoch 968/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6462 - accuracy: 0.7619 - val_loss: 1.3033 - val_accuracy: 0.5463\n",
      "Epoch 969/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6598 - accuracy: 0.7758 - val_loss: 1.2950 - val_accuracy: 0.5532\n",
      "Epoch 970/1000\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.6528 - accuracy: 0.7659 - val_loss: 1.3004 - val_accuracy: 0.5463\n",
      "Epoch 971/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6028 - accuracy: 0.8016 - val_loss: 1.2990 - val_accuracy: 0.5579\n",
      "Epoch 972/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.6510 - accuracy: 0.7659 - val_loss: 1.2939 - val_accuracy: 0.5787\n",
      "Epoch 973/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6741 - accuracy: 0.7669 - val_loss: 1.3298 - val_accuracy: 0.5255\n",
      "Epoch 974/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6672 - accuracy: 0.7738 - val_loss: 1.2723 - val_accuracy: 0.5417\n",
      "Epoch 975/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6639 - accuracy: 0.7768 - val_loss: 1.2793 - val_accuracy: 0.5787\n",
      "Epoch 976/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6400 - accuracy: 0.7639 - val_loss: 1.2750 - val_accuracy: 0.5694\n",
      "Epoch 977/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6506 - accuracy: 0.7728 - val_loss: 1.2787 - val_accuracy: 0.5532\n",
      "Epoch 978/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6469 - accuracy: 0.7679 - val_loss: 1.2999 - val_accuracy: 0.5671\n",
      "Epoch 979/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6343 - accuracy: 0.7768 - val_loss: 1.3450 - val_accuracy: 0.5486\n",
      "Epoch 980/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6487 - accuracy: 0.7708 - val_loss: 1.2603 - val_accuracy: 0.5880\n",
      "Epoch 981/1000\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.6385 - accuracy: 0.7817 - val_loss: 1.2697 - val_accuracy: 0.5741\n",
      "Epoch 982/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6298 - accuracy: 0.7817 - val_loss: 1.2916 - val_accuracy: 0.5486\n",
      "Epoch 983/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6401 - accuracy: 0.7718 - val_loss: 1.2634 - val_accuracy: 0.5648\n",
      "Epoch 984/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6463 - accuracy: 0.7718 - val_loss: 1.2802 - val_accuracy: 0.5532\n",
      "Epoch 985/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6342 - accuracy: 0.7738 - val_loss: 1.2669 - val_accuracy: 0.5625\n",
      "Epoch 986/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6389 - accuracy: 0.7768 - val_loss: 1.2613 - val_accuracy: 0.5556\n",
      "Epoch 987/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6315 - accuracy: 0.7778 - val_loss: 1.3092 - val_accuracy: 0.5671\n",
      "Epoch 988/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6316 - accuracy: 0.7817 - val_loss: 1.2826 - val_accuracy: 0.5579\n",
      "Epoch 989/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6284 - accuracy: 0.7669 - val_loss: 1.3215 - val_accuracy: 0.5833\n",
      "Epoch 990/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.6691 - accuracy: 0.7579 - val_loss: 1.2768 - val_accuracy: 0.5718\n",
      "Epoch 991/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6581 - accuracy: 0.7669 - val_loss: 1.2940 - val_accuracy: 0.5556\n",
      "Epoch 992/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6196 - accuracy: 0.7788 - val_loss: 1.2787 - val_accuracy: 0.5694\n",
      "Epoch 993/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6741 - accuracy: 0.7669 - val_loss: 1.3044 - val_accuracy: 0.5440\n",
      "Epoch 994/1000\n",
      "63/63 [==============================] - 0s 8ms/step - loss: 0.6529 - accuracy: 0.7768 - val_loss: 1.2842 - val_accuracy: 0.5694\n",
      "Epoch 995/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6331 - accuracy: 0.7768 - val_loss: 1.2844 - val_accuracy: 0.5602\n",
      "Epoch 996/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6486 - accuracy: 0.7639 - val_loss: 1.2916 - val_accuracy: 0.5602\n",
      "Epoch 997/1000\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6549 - accuracy: 0.7698 - val_loss: 1.2497 - val_accuracy: 0.5856\n",
      "Epoch 998/1000\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6473 - accuracy: 0.7748 - val_loss: 1.2577 - val_accuracy: 0.5880\n",
      "Epoch 999/1000\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.6335 - accuracy: 0.7778 - val_loss: 1.2946 - val_accuracy: 0.5486\n",
      "Epoch 1000/1000\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6284 - accuracy: 0.7619 - val_loss: 1.3050 - val_accuracy: 0.5625\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_traincnn, y_train, batch_size=16, epochs=1000, validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"nn ravdess mfcc 1.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-04 21:12:13.846315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 3013 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2022-03-04 21:12:13.849974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 3013 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "    import tensorflow as tf \n",
    "\n",
    "    if tf.test.gpu_device_name(): \n",
    "\n",
    "        print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "    else:\n",
    "\n",
    "       print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
