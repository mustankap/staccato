{
	"cells": [
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {
				"colab": {},
				"colab_type": "code",
				"id": "kZTfgUu51RCX"
			},
			"outputs": [],
			"source": [
				"#Import All Important Libraries\n",
				"import librosa\n",
				"from pydub import AudioSegment\n",
				"import subprocess\n",
				"import soundfile\n",
				"import os, glob, pickle\n",
				"import numpy as np\n",
				"import matplotlib.pyplot as plt\n",
				"from sklearn.model_selection import train_test_split\n",
				"from sklearn.neural_network import MLPClassifier\n",
				"from pathlib import Path\n",
				"from sklearn.metrics import accuracy_score, confusion_matrix"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 18,
			"metadata": {},
			"outputs": [],
			"source": [
				"# import shutil\n",
				"# for folder in glob.glob('./Datasets/Actor_*'):\n",
				"#     for file in glob.glob(folder + '/*.wav'):\n",
				"#         file1 = file[20:]\n",
				"#         # shutil.copy(file, './Datasets/Data/' + file1)\n",
				"#         bashCommand = f\"cp -f {file} ./Datasets/Data/{file1}\"\n",
				"#         process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 30,
			"metadata": {
				"colab": {},
				"colab_type": "code",
				"id": "dvGpG07E_3Uo"
			},
			"outputs": [],
			"source": [
				"#function for extracting mfcc, chroma, and mel features from sound file\n",
				"def extract_feature(file_name, mfcc, chroma, mel):\n",
				"    with soundfile.SoundFile(file_name) as sound_file:\n",
				"        X = sound_file.read(dtype=\"float32\")\n",
				"        sample_rate=sound_file.samplerate\n",
				"        result=np.array([])\n",
				"        if mfcc:\n",
				"            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
				"            result=np.hstack((result, mfccs))\n",
				"        if chroma:\n",
				"            stft=np.abs(librosa.stft(X))\n",
				"            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
				"            result=np.hstack((result, chroma))\n",
				"        if mel:\n",
				"            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
				"            result=np.hstack((result, mel))\n",
				"    return result"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 31,
			"metadata": {
				"colab": {},
				"colab_type": "code",
				"id": "p-UIAg03Xis1"
			},
			"outputs": [],
			"source": [
				"#Define the motions dictionary\n",
				"emotions = {\n",
				"    '01':'neutral',\n",
				"    '02':'calm',\n",
				"    '03':'happy',\n",
				"    '04':'sad',\n",
				"    '05':'angry',\n",
				"    '06':'fearful',\n",
				"    '07':'disgust',\n",
				"    '08':'surprised'\n",
				"}\n",
				"\n",
				"#Emotions we want to observe\n",
				"observed_emotions = ['calm', 'happy', 'fearful', 'disgust']"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 36,
			"metadata": {
				"colab": {},
				"colab_type": "code",
				"id": "154OQUcVZ4tt"
			},
			"outputs": [],
			"source": [
				"#Load the data and extract features for each sound file\n",
				"def load_data(test_size = 0.2):\n",
				"    x, y = [], []\n",
				"    for folder in glob.glob('./Datasets/Actor_*'):\n",
				"        # print(0)\n",
				"        print(folder)\n",
				"        for file in glob.glob(folder + '/*.wav'):\n",
				"            # print(file)\n",
				"            file_name = os.path.basename(file)\n",
				"            emotion = emotions[file_name.split('-')[2]]\n",
				"            if emotion not in observed_emotions:\n",
				"                continue\n",
				"            feature = extract_feature(file, mfcc = True, chroma = True, mel = True)\n",
				"            x.append(feature)\n",
				"            y.append(emotion)\n",
				"    return train_test_split(np.array(x), y, test_size = test_size, random_state = 9)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 37,
			"metadata": {
				"colab": {
					"base_uri": "https://localhost:8080/",
					"height": 425
				},
				"colab_type": "code",
				"id": "J2f0qX1PjBU0",
				"outputId": "ea97dc04-3154-479b-918f-51a83cbbf2f3"
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"./Datasets/Actor_20\n"
					]
				},
				{
					"ename": "ParameterError",
					"evalue": "Invalid shape for monophonic audio: ndim=2, shape=(209809, 2)",
					"output_type": "error",
					"traceback": [
						"\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
						"\u001b[0;31mParameterError\u001b[0m                            Traceback (most recent call last)",
						"\u001b[0;32m/tmp/ipykernel_22402/1719200704.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
						"\u001b[0;32m/tmp/ipykernel_22402/804332266.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(test_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0memotion\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobserved_emotions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmfcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchroma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
						"\u001b[0;32m/tmp/ipykernel_22402/2313474146.py\u001b[0m in \u001b[0;36mextract_feature\u001b[0;34m(file_name, mfcc, chroma, mel)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmfcc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mmfccs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmfccs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchroma\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
						"\u001b[0;32m~/RUiN/apps/miniconda3/lib/python3.9/site-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmfcc\u001b[0;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mS\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1851\u001b[0;31m         \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpower_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m     \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdct_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_mfcc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
						"\u001b[0;32m~/RUiN/apps/miniconda3/lib/python3.9/site-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \"\"\"\n\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m     S, n_fft = _spectrogram(\n\u001b[0m\u001b[1;32m   1996\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0mS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
						"\u001b[0;32m~/RUiN/apps/miniconda3/lib/python3.9/site-packages/librosa/core/spectrum.py\u001b[0m in \u001b[0;36m_spectrogram\u001b[0;34m(y, S, n_fft, hop_length, power, win_length, window, center, pad_mode)\u001b[0m\n\u001b[1;32m   2510\u001b[0m         S = (\n\u001b[1;32m   2511\u001b[0m             np.abs(\n\u001b[0;32m-> 2512\u001b[0;31m                 stft(\n\u001b[0m\u001b[1;32m   2513\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2514\u001b[0m                     \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
						"\u001b[0;32m~/RUiN/apps/miniconda3/lib/python3.9/site-packages/librosa/core/spectrum.py\u001b[0m in \u001b[0;36mstft\u001b[0;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;31m# Check audio is valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;31m# Pad the time series so that frames are centered\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
						"\u001b[0;32m~/RUiN/apps/miniconda3/lib/python3.9/site-packages/librosa/util/utils.py\u001b[0m in \u001b[0;36mvalid_audio\u001b[0;34m(y, mono)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmono\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         raise ParameterError(\n\u001b[0m\u001b[1;32m    294\u001b[0m             \u001b[0;34m\"Invalid shape for monophonic audio: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;34m\"ndim={:d}, shape={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
						"\u001b[0;31mParameterError\u001b[0m: Invalid shape for monophonic audio: ndim=2, shape=(209809, 2)"
					]
				}
			],
			"source": [
				"x_train,x_test,y_train,y_test=load_data(test_size=0.3)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"colab": {
					"base_uri": "https://localhost:8080/",
					"height": 51
				},
				"colab_type": "code",
				"id": "HpN02uwkpekV",
				"outputId": "78905251-85ce-4d73-92aa-ce7e334840e3"
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"(386, 166)\n",
						"Features extracted: 180\n"
					]
				}
			],
			"source": [
				"#Shape of train and test set and Number of features extracted\n",
				"print((x_train.shape[0], x_test.shape[0]))\n",
				"print(f'Features extracted: {x_train.shape[1]}')"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"colab": {},
				"colab_type": "code",
				"id": "ZXwY7HVDuuTv"
			},
			"outputs": [],
			"source": [
				"#Initialise Multi Layer Perceptron Classifier\n",
				"model = MLPClassifier(alpha = 0.01, batch_size = 256, epsilon = 1e-08, hidden_layer_sizes = (1000,), learning_rate = 'adaptive', max_iter = 500)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": []
				}
			],
			"source": [
				"history"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"colab": {},
				"colab_type": "code",
				"id": "glTuS50TwN0I"
			},
			"outputs": [],
			"source": [
				"#Predict for the test set\n",
				"y_pred = model.predict(x_test)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"colab": {
					"base_uri": "https://localhost:8080/",
					"height": 34
				},
				"colab_type": "code",
				"id": "qqVnMdQmwUXG",
				"outputId": "20d90e48-b15b-47f3-ff7c-62151a3dff82"
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": []
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": []
				},
				{
					"name": "stdout",
					"output_type": "stream",
					"text": []
				}
			],
			"source": [
				"loss_plot=model.loss_curve_\n",
				"plt.plot(loss_plot)\n",
				"plt.show()"
			]
		}
	],
	"metadata": {
		"colab": {
			"collapsed_sections": [],
			"name": "Speech Emotion Recognition Notebook.ipynb",
			"provenance": []
		},
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.9.7"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 1
}
