# Staccato (final year project)
[![Python 3.6](https://img.shields.io/badge/python-3.6-yellow.svg)](https://www.python.org/downloads/release/python-360/)

## Audio system using DRL
By studying numerous vocal and speech patterns, this project proposes an automated technique to recognizing human emotions. Voice and speech pattern analysis can aid improve conversational and persuasion skills, particularly in contexts or applications where direct face-to-face human involvement is neither possible or desirable. This research presents approaches for predicting emotions accurately in a voice sample. To avoid overfitting and provide realistic sound, additive white Gaussian noise is used. The Mel spectrogram is used in this research to extract features. Multilayer Perceptron, 1D-CNN, 2D-CNN, and transformer-based parallel CNN were utilized, yielding 77 percent, 86 percent, 83 percent, and 90 percent accuracy, respectively.

